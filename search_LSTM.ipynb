{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "import pandas as pd\n",
    "import FinanceDataReader as fdr\n",
    "import datetime\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import argparse\n",
    "from copy import deepcopy \n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "import seaborn as sns \n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_set(filename):\n",
    "    dir_path = './data_set'\n",
    "    \n",
    "    with open(join(dir_path, filename), 'r') as f:\n",
    "        results = json.load(f)\n",
    "        \n",
    "    return results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = load_data_set('my_data_set.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(sym):\n",
    "    file_path = \"./stockData/\"\n",
    "    csv_path = os.path.join(file_path, f\"{sym}.csv\")\n",
    "    df = pd.read_csv(csv_path, parse_dates=True, index_col = ['Date'])\n",
    "    df.drop('Symbol', axis=1, inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Min_Max_Scaler(dataframe):\n",
    "    d_min = np.min(dataframe, 0)\n",
    "    d_max = np.max(dataframe, 0)\n",
    "\n",
    "    numerator = dataframe - d_min\n",
    "    denominator = d_max - d_min\n",
    "\n",
    "    df = numerator / (denominator + 1e-7)\n",
    "\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StockDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, data, x_frames, y_frames, start, end):\n",
    "        self.x_frames = x_frames\n",
    "        self.y_frames = y_frames\n",
    "\n",
    "        self.start = start\n",
    "        self.end = end\n",
    "\n",
    "        self.data = data.loc[self.start : self.end]\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data) - (self.x_frames + self.y_frames) + 1\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        idx += self.x_frames\n",
    "        data = self.data.iloc[idx-self.x_frames:idx+self.y_frames]\n",
    "        data = data[['Close','Open', 'High', 'Low', 'Volume', 'Change']]\n",
    "        data = data.values\n",
    "        X = data[:self.x_frames]\n",
    "        y = data[self.x_frames:]\n",
    "        \n",
    "        return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, num_layers, batch_size, dropout, use_bn):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.input_dim = input_dim \n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.batch_size = batch_size\n",
    "        self.dropout = dropout\n",
    "        self.use_bn = use_bn \n",
    "        \n",
    "        self.lstm = nn.LSTM(self.input_dim, self.hidden_dim, self.num_layers)\n",
    "        self.hidden = self.init_hidden()\n",
    "        self.regressor = self.make_regressor()\n",
    "        \n",
    "    def init_hidden(self):\n",
    "        return (torch.zeros(self.num_layers, self.batch_size, self.hidden_dim),\n",
    "                torch.zeros(self.num_layers, self.batch_size, self.hidden_dim))\n",
    "    \n",
    "    def make_regressor(self):\n",
    "        layers = []\n",
    "        if self.use_bn:\n",
    "            layers.append(nn.BatchNorm1d(self.hidden_dim))\n",
    "        layers.append(nn.Dropout(self.dropout))\n",
    "        \n",
    "        layers.append(nn.Linear(self.hidden_dim, self.hidden_dim // 2))\n",
    "        layers.append(nn.ReLU())\n",
    "        layers.append(nn.Linear(self.hidden_dim // 2, self.output_dim))\n",
    "        regressor = nn.Sequential(*layers)\n",
    "        return regressor\n",
    "    \n",
    "    def forward(self, x):\n",
    "        lstm_out, self.hidden = self.lstm(x, self.hidden)\n",
    "        y_pred = self.regressor(lstm_out[-1].view(self.batch_size, -1))\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metric(y_pred, y_true):\n",
    "    perc_y_pred = (y_pred.detach().numpy())\n",
    "    perc_y_true = (y_true.detach().numpy())\n",
    "    mae = mean_absolute_error(perc_y_true, perc_y_pred, multioutput='raw_values')\n",
    "    return mae*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, partition, optimizer, loss_fn, args):\n",
    "\n",
    "    model.train()\n",
    "    model.zero_grad()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    train_acc = 0.0\n",
    "    train_loss = 0.0\n",
    "    \n",
    "    length = 0\n",
    "    \n",
    "    for i in range(len(partition['train'])):\n",
    "        length += len(partition['train'][i])\n",
    "    \n",
    "    for _ in range(70):\n",
    "        for i in range(len(partition['train'])):\n",
    "            X, y = next(iter(partition['train'][i]))\n",
    "\n",
    "            X = X.to(args.device)\n",
    "            y = y.to(args.device)\n",
    "\n",
    "            X = X.transpose(0, 1).float()\n",
    "            y_true = y[:, :, 0].float()\n",
    "\n",
    "            model.zero_grad()\n",
    "            optimizer.zero_grad()\n",
    "            model.hidden = [hidden.to(args.device) for hidden in model.init_hidden()]\n",
    "\n",
    "\n",
    "            y_pred = model(X)\n",
    "            loss = loss_fn(y_pred.view(-1), y_true.view(-1))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss += loss.item()\n",
    "            train_acc += metric(y_pred, y_true)[0]\n",
    "\n",
    "    train_loss = train_loss / length\n",
    "    train_acc = train_acc / length\n",
    "    return model, train_loss, train_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, partition, loss_fn, args):\n",
    "    \n",
    "    model.eval()\n",
    "\n",
    "    val_acc = 0.0\n",
    "    val_loss = 0.0\n",
    "    \n",
    "    length = 0\n",
    "    for i in range(len(partition['val'])):\n",
    "        length += len(partition['val'][i])\n",
    "        \n",
    "    with torch.no_grad():\n",
    "        for _ in range(3):\n",
    "            for i in range(len(partition['val'])):\n",
    "                X, y = next(iter(partition['val'][i]))        \n",
    "                X = X.to(args.device)\n",
    "                y = y.to(args.device)\n",
    "\n",
    "                X = X.transpose(0, 1).float()\n",
    "                y_true = y[:, :, 0].float()\n",
    "\n",
    "                model.hidden = [hidden.to(args.device) for hidden in model.init_hidden()]\n",
    "\n",
    "                y_pred = model(X)\n",
    "\n",
    "                loss = loss_fn(y_pred.view(-1), y_true.view(-1))\n",
    "                \n",
    "                val_loss += loss.item()\n",
    "                val_acc += metric(y_pred, y_true)[0]\n",
    "\n",
    "    val_loss = val_loss / length\n",
    "    val_acc = val_acc / length\n",
    "    return val_loss, val_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def experiment(partition, args):\n",
    "    hash_key = hashlib.sha1(str(vars(args)).encode()).hexdigest()[:6]\n",
    "\n",
    "    model = LSTM(args.input_dim, args.hid_dim, args.y_frames, args.n_layers, args.batch_size, args.dropout, args.use_bn)\n",
    "    model.to(args.device)\n",
    "\n",
    "    loss_fn = torch.nn.MSELoss()\n",
    "\n",
    "    loss_fn = nn.MSELoss()\n",
    "    if args.optim == 'SGD':\n",
    "        optimizer = optim.RMSprop(model.parameters(), lr=args.lr, weight_decay=args.l2)\n",
    "    elif args.optim == 'RMSprop':\n",
    "        optimizer = optim.RMSprop(model.parameters(), lr=args.lr, weight_decay=args.l2)\n",
    "    elif args.optim == 'Adam':\n",
    "        optimizer = optim.Adam(model.parameters(), lr=args.lr, weight_decay=args.l2)\n",
    "    else:\n",
    "        raise ValueError('In-valid optimizer choice. Choose one of SGD, RMSprop, Adam')\n",
    "    \n",
    "    # ===== List for epoch-wise data ====== #\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    train_accs = []\n",
    "    val_accs = []\n",
    "    # ===================================== #\n",
    "\n",
    "    for epoch in range(args.epoch):  # loop over the dataset multiple times\n",
    "        \n",
    "        start = time.time()\n",
    "        model, train_loss, train_acc = train(model, partition, optimizer, loss_fn, args)\n",
    "\n",
    "        val_loss, val_acc = validate(model, partition, loss_fn, args)\n",
    "\n",
    "        end = time.time()\n",
    "\n",
    "        print('Epoch {}, Acc(train/val): {:2.2f}/{:2.2f}, Loss(train/val) {:2.2f}/{:2.2f}. Took {:2.2f} sec'\n",
    "              .format(epoch+1, train_acc, val_acc, train_loss*10, val_loss*10, end-start))\n",
    "        \n",
    "        # ====== Add Epoch Data ====== #\n",
    "        train_losses.append(train_loss)\n",
    "        val_losses.append(val_loss)\n",
    "        train_accs.append(train_acc)\n",
    "        val_accs.append(val_acc)\n",
    "        # ============================ #\n",
    "\n",
    "    # ======= Add Result to Dictionary ======= #\n",
    "    result = {}\n",
    "    result['train_losses'] = [x for x in train_losses]\n",
    "    result['val_losses'] = [x for x in val_losses]\n",
    "    result['train_accs'] = [x for x in train_accs]\n",
    "    result['val_accs'] = [x for x in val_accs]\n",
    "    result['train_acc'] = train_acc\n",
    "    result['val_acc'] = val_acc\n",
    "    \n",
    "    return model, vars(args), result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hashlib\n",
    "import json\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "\n",
    "def save_exp_result(setting, result):\n",
    "    exp_name = setting['exp_name']\n",
    "\n",
    "    hash_key = hashlib.sha1(str(setting).encode()).hexdigest()[:6]\n",
    "    \n",
    "    filepath = './results'\n",
    "    if not os.path.isdir(filepath):\n",
    "        os.mkdir(filepath)\n",
    "\n",
    "    filename = './results/{}-{}.json'.format(exp_name, hash_key)\n",
    "    result.update(setting)\n",
    "    with open(filename, 'w') as f:\n",
    "        json.dump(result, f)\n",
    "\n",
    "    \n",
    "def load_exp_result(exp_name):\n",
    "    dir_path = './results'\n",
    "    filenames = [f for f in listdir(dir_path) if isfile(join(dir_path, f)) if '.json' in f]\n",
    "    list_result = []\n",
    "    for filename in filenames:\n",
    "        if exp_name in filename:\n",
    "            with open(join(dir_path, filename), 'r') as infile:\n",
    "                results = json.load(infile)\n",
    "                list_result.append(results)\n",
    "    df = pd.DataFrame(list_result)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "# ====== Random Seed Initialization ====== #\n",
    "seed = 666\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "args = parser.parse_args(\"\")\n",
    "args.exp_name = \"exp1_lr\"\n",
    "args.device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "print(args.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====== Data Loading ====== #\n",
    "# args.symbol = 'AAPL'\n",
    "args.batch_size = 16\n",
    "args.x_frames = 5\n",
    "args.y_frames = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_list=[]\n",
    "\n",
    "for sym in result[0]:\n",
    "    df = get_data(sym)\n",
    "    df = Min_Max_Scaler(df)\n",
    "    ds_train = StockDataset(df, args.x_frames, args.y_frames, '2000-01-01', '2018-01-01')\n",
    "    ds_valid = StockDataset(df, args.x_frames, args.y_frames, '2018-01-01', '2019-01-01')\n",
    "    \n",
    "    partition = {'train': ds_train, 'val':ds_valid}\n",
    "    dataset_list.append(partition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader_train = []\n",
    "\n",
    "for dataset in dataset_list:\n",
    "    trainloader = DataLoader(dataset['train'], batch_size=args.batch_size, shuffle=False, drop_last=True)\n",
    "    loader_train.append(trainloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader_valid = []\n",
    "\n",
    "for dataset in dataset_list:\n",
    "    validloader = DataLoader(dataset['val'], batch_size=args.batch_size, shuffle=False, drop_last=True)\n",
    "    loader_valid.append(validloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "partition = {'train': loader_train, 'val':loader_valid}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====== Model Capacity ===== #\n",
    "args.input_dim = 6\n",
    "args.hid_dim = 50\n",
    "args.n_layers = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====== Regularization ======= #\n",
    "args.l2 = 0.0001\n",
    "args.dropout = 0.3\n",
    "args.use_bn = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====== Optimizer & Training ====== #\n",
    "args.optim = 'Adam' #'RMSprop' #SGD, RMSprop, ADAM...\n",
    "args.lr = 0.0001\n",
    "args.epoch = 50\n",
    "args.path = './model_checkpoint/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(batch_size=16, device='cpu', dropout=0.3, epoch=50, exp_name='exp1_lr', hid_dim=10, input_dim=6, l2=0.0001, lr=0.0001, n_layers=1, optim='Adam', path='./model_checkpoint/', use_bn=True, x_frames=5, y_frames=1)\n",
      "Epoch 1, Acc(train/val): 3.21/129.13, Loss(train/val) 0.01/9.55. Took 50.48 sec\n",
      "Epoch 2, Acc(train/val): 2.51/180.34, Loss(train/val) 0.00/20.10. Took 47.83 sec\n",
      "Epoch 3, Acc(train/val): 2.02/194.41, Loss(train/val) 0.00/24.24. Took 48.41 sec\n",
      "Epoch 4, Acc(train/val): 1.79/178.19, Loss(train/val) 0.00/20.96. Took 48.64 sec\n",
      "Epoch 5, Acc(train/val): 1.72/194.17, Loss(train/val) 0.00/25.36. Took 49.23 sec\n",
      "Epoch 6, Acc(train/val): 1.69/178.30, Loss(train/val) 0.00/21.34. Took 50.98 sec\n",
      "Epoch 7, Acc(train/val): 1.66/175.02, Loss(train/val) 0.00/20.45. Took 49.39 sec\n",
      "Epoch 8, Acc(train/val): 1.64/169.43, Loss(train/val) 0.00/19.08. Took 49.96 sec\n",
      "Epoch 9, Acc(train/val): 1.63/173.30, Loss(train/val) 0.00/19.89. Took 48.81 sec\n",
      "Epoch 10, Acc(train/val): 1.62/175.46, Loss(train/val) 0.00/20.33. Took 49.88 sec\n",
      "Epoch 11, Acc(train/val): 1.60/174.66, Loss(train/val) 0.00/20.57. Took 52.58 sec\n",
      "Epoch 12, Acc(train/val): 1.59/161.79, Loss(train/val) 0.00/17.35. Took 48.22 sec\n",
      "Epoch 13, Acc(train/val): 1.58/162.89, Loss(train/val) 0.00/17.49. Took 44.28 sec\n",
      "Epoch 14, Acc(train/val): 1.57/161.48, Loss(train/val) 0.00/17.30. Took 50.81 sec\n",
      "Epoch 15, Acc(train/val): 1.55/163.95, Loss(train/val) 0.00/17.94. Took 49.71 sec\n",
      "Epoch 16, Acc(train/val): 1.55/150.94, Loss(train/val) 0.00/15.09. Took 51.53 sec\n",
      "Epoch 17, Acc(train/val): 1.52/154.51, Loss(train/val) 0.00/15.79. Took 51.69 sec\n",
      "Epoch 18, Acc(train/val): 1.52/149.11, Loss(train/val) 0.00/14.89. Took 50.62 sec\n",
      "Epoch 19, Acc(train/val): 1.49/160.17, Loss(train/val) 0.00/17.19. Took 49.43 sec\n",
      "Epoch 20, Acc(train/val): 1.47/157.44, Loss(train/val) 0.00/16.94. Took 49.60 sec\n",
      "Epoch 21, Acc(train/val): 1.45/156.64, Loss(train/val) 0.00/16.67. Took 49.41 sec\n",
      "Epoch 22, Acc(train/val): 1.45/169.73, Loss(train/val) 0.00/19.73. Took 50.21 sec\n",
      "Epoch 23, Acc(train/val): 1.43/161.26, Loss(train/val) 0.00/17.59. Took 49.86 sec\n",
      "Epoch 24, Acc(train/val): 1.42/161.02, Loss(train/val) 0.00/17.89. Took 49.84 sec\n",
      "Epoch 25, Acc(train/val): 1.41/162.54, Loss(train/val) 0.00/18.38. Took 50.00 sec\n",
      "Epoch 26, Acc(train/val): 1.40/164.82, Loss(train/val) 0.00/18.88. Took 49.77 sec\n",
      "Epoch 27, Acc(train/val): 1.38/170.14, Loss(train/val) 0.00/20.10. Took 49.71 sec\n",
      "Epoch 28, Acc(train/val): 1.37/169.60, Loss(train/val) 0.00/19.85. Took 54.51 sec\n",
      "Epoch 29, Acc(train/val): 1.38/174.37, Loss(train/val) 0.00/21.51. Took 54.64 sec\n",
      "Epoch 30, Acc(train/val): 1.35/189.76, Loss(train/val) 0.00/25.57. Took 53.65 sec\n",
      "Epoch 31, Acc(train/val): 1.32/181.70, Loss(train/val) 0.00/23.64. Took 57.43 sec\n",
      "Epoch 32, Acc(train/val): 1.31/183.43, Loss(train/val) 0.00/24.38. Took 54.40 sec\n",
      "Epoch 33, Acc(train/val): 1.30/183.39, Loss(train/val) 0.00/23.92. Took 48.23 sec\n",
      "Epoch 34, Acc(train/val): 1.28/199.81, Loss(train/val) 0.00/28.72. Took 57.47 sec\n",
      "Epoch 35, Acc(train/val): 1.27/202.83, Loss(train/val) 0.00/30.06. Took 54.12 sec\n",
      "Epoch 36, Acc(train/val): 1.26/206.64, Loss(train/val) 0.00/31.04. Took 51.44 sec\n",
      "Epoch 37, Acc(train/val): 1.27/215.16, Loss(train/val) 0.00/33.70. Took 40.71 sec\n",
      "Epoch 38, Acc(train/val): 1.25/205.25, Loss(train/val) 0.00/31.01. Took 40.47 sec\n",
      "Epoch 39, Acc(train/val): 1.24/216.05, Loss(train/val) 0.00/34.08. Took 40.07 sec\n",
      "Epoch 40, Acc(train/val): 1.23/206.22, Loss(train/val) 0.00/31.28. Took 40.04 sec\n",
      "Epoch 41, Acc(train/val): 1.24/215.07, Loss(train/val) 0.00/33.73. Took 40.77 sec\n",
      "Epoch 42, Acc(train/val): 1.22/207.99, Loss(train/val) 0.00/32.09. Took 39.55 sec\n",
      "Epoch 43, Acc(train/val): 1.22/215.42, Loss(train/val) 0.00/34.32. Took 44.36 sec\n",
      "Epoch 44, Acc(train/val): 1.21/212.71, Loss(train/val) 0.00/33.14. Took 55.64 sec\n",
      "Epoch 45, Acc(train/val): 1.22/214.83, Loss(train/val) 0.00/34.00. Took 50.99 sec\n",
      "Epoch 46, Acc(train/val): 1.21/209.63, Loss(train/val) 0.00/32.35. Took 52.77 sec\n",
      "Epoch 47, Acc(train/val): 1.20/218.24, Loss(train/val) 0.00/34.95. Took 52.77 sec\n",
      "Epoch 48, Acc(train/val): 1.20/217.17, Loss(train/val) 0.00/34.91. Took 51.54 sec\n",
      "Epoch 49, Acc(train/val): 1.20/219.38, Loss(train/val) 0.00/35.37. Took 52.85 sec\n",
      "Epoch 50, Acc(train/val): 1.20/208.77, Loss(train/val) 0.00/32.03. Took 51.93 sec\n",
      "Namespace(batch_size=16, device='cpu', dropout=0.3, epoch=50, exp_name='exp1_lr', hid_dim=10, input_dim=6, l2=0.0001, lr=0.0001, n_layers=2, optim='Adam', path='./model_checkpoint/', use_bn=True, x_frames=5, y_frames=1)\n",
      "Epoch 1, Acc(train/val): 5.03/102.46, Loss(train/val) 0.01/6.21. Took 59.17 sec\n",
      "Epoch 2, Acc(train/val): 2.89/168.26, Loss(train/val) 0.00/17.73. Took 59.85 sec\n",
      "Epoch 3, Acc(train/val): 2.23/198.29, Loss(train/val) 0.00/25.17. Took 60.86 sec\n",
      "Epoch 4, Acc(train/val): 2.00/202.14, Loss(train/val) 0.00/26.88. Took 59.84 sec\n",
      "Epoch 5, Acc(train/val): 1.78/196.26, Loss(train/val) 0.00/26.07. Took 61.71 sec\n",
      "Epoch 6, Acc(train/val): 1.66/191.19, Loss(train/val) 0.00/24.78. Took 59.94 sec\n",
      "Epoch 7, Acc(train/val): 1.58/190.77, Loss(train/val) 0.00/24.44. Took 59.53 sec\n",
      "Epoch 8, Acc(train/val): 1.53/185.29, Loss(train/val) 0.00/22.97. Took 61.00 sec\n",
      "Epoch 9, Acc(train/val): 1.51/181.40, Loss(train/val) 0.00/22.17. Took 61.05 sec\n",
      "Epoch 10, Acc(train/val): 1.48/180.75, Loss(train/val) 0.00/21.98. Took 57.01 sec\n",
      "Epoch 11, Acc(train/val): 1.46/177.61, Loss(train/val) 0.00/21.37. Took 58.27 sec\n",
      "Epoch 12, Acc(train/val): 1.44/174.33, Loss(train/val) 0.00/20.47. Took 61.82 sec\n",
      "Epoch 13, Acc(train/val): 1.42/176.01, Loss(train/val) 0.00/20.88. Took 62.68 sec\n",
      "Epoch 14, Acc(train/val): 1.42/178.45, Loss(train/val) 0.00/21.65. Took 58.98 sec\n",
      "Epoch 15, Acc(train/val): 1.41/181.88, Loss(train/val) 0.00/23.05. Took 57.21 sec\n",
      "Epoch 16, Acc(train/val): 1.39/174.31, Loss(train/val) 0.00/20.92. Took 51.99 sec\n",
      "Epoch 17, Acc(train/val): 1.38/179.37, Loss(train/val) 0.00/21.94. Took 56.98 sec\n",
      "Epoch 18, Acc(train/val): 1.37/170.75, Loss(train/val) 0.00/19.66. Took 56.35 sec\n",
      "Epoch 19, Acc(train/val): 1.36/175.08, Loss(train/val) 0.00/21.30. Took 59.12 sec\n",
      "Epoch 20, Acc(train/val): 1.35/166.30, Loss(train/val) 0.00/18.55. Took 60.12 sec\n",
      "Epoch 21, Acc(train/val): 1.33/163.06, Loss(train/val) 0.00/18.00. Took 61.92 sec\n",
      "Epoch 22, Acc(train/val): 1.33/167.25, Loss(train/val) 0.00/18.95. Took 58.83 sec\n",
      "Epoch 23, Acc(train/val): 1.32/167.72, Loss(train/val) 0.00/19.52. Took 58.18 sec\n",
      "Epoch 24, Acc(train/val): 1.32/165.92, Loss(train/val) 0.00/18.75. Took 57.80 sec\n",
      "Epoch 25, Acc(train/val): 1.31/163.14, Loss(train/val) 0.00/18.32. Took 63.50 sec\n",
      "Epoch 26, Acc(train/val): 1.30/166.72, Loss(train/val) 0.00/18.92. Took 65.36 sec\n",
      "Epoch 27, Acc(train/val): 1.28/163.96, Loss(train/val) 0.00/18.68. Took 65.86 sec\n",
      "Epoch 28, Acc(train/val): 1.28/166.63, Loss(train/val) 0.00/18.43. Took 52.77 sec\n",
      "Epoch 29, Acc(train/val): 1.28/162.93, Loss(train/val) 0.00/18.27. Took 46.41 sec\n",
      "Epoch 30, Acc(train/val): 1.28/158.60, Loss(train/val) 0.00/17.20. Took 48.30 sec\n",
      "Epoch 31, Acc(train/val): 1.26/159.67, Loss(train/val) 0.00/16.90. Took 46.27 sec\n",
      "Epoch 32, Acc(train/val): 1.27/156.80, Loss(train/val) 0.00/16.83. Took 52.39 sec\n",
      "Epoch 33, Acc(train/val): 1.25/162.97, Loss(train/val) 0.00/17.97. Took 58.64 sec\n",
      "Epoch 34, Acc(train/val): 1.25/155.33, Loss(train/val) 0.00/16.03. Took 47.05 sec\n",
      "Epoch 35, Acc(train/val): 1.24/158.04, Loss(train/val) 0.00/16.85. Took 44.29 sec\n",
      "Epoch 36, Acc(train/val): 1.23/155.14, Loss(train/val) 0.00/16.18. Took 44.21 sec\n",
      "Epoch 37, Acc(train/val): 1.23/157.06, Loss(train/val) 0.00/16.60. Took 46.75 sec\n",
      "Epoch 38, Acc(train/val): 1.21/154.85, Loss(train/val) 0.00/16.16. Took 46.41 sec\n",
      "Epoch 39, Acc(train/val): 1.22/154.83, Loss(train/val) 0.00/16.03. Took 46.87 sec\n",
      "Epoch 40, Acc(train/val): 1.21/155.80, Loss(train/val) 0.00/16.32. Took 47.21 sec\n",
      "Epoch 41, Acc(train/val): 1.20/150.43, Loss(train/val) 0.00/15.25. Took 56.15 sec\n",
      "Epoch 42, Acc(train/val): 1.20/159.79, Loss(train/val) 0.00/17.08. Took 54.18 sec\n",
      "Epoch 43, Acc(train/val): 1.20/154.27, Loss(train/val) 0.00/15.96. Took 53.56 sec\n",
      "Epoch 44, Acc(train/val): 1.19/158.82, Loss(train/val) 0.00/17.10. Took 53.19 sec\n",
      "Epoch 45, Acc(train/val): 1.19/152.01, Loss(train/val) 0.00/15.53. Took 53.29 sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46, Acc(train/val): 1.18/152.56, Loss(train/val) 0.00/15.86. Took 54.38 sec\n",
      "Epoch 47, Acc(train/val): 1.18/158.59, Loss(train/val) 0.00/16.90. Took 59.72 sec\n",
      "Epoch 48, Acc(train/val): 1.17/150.54, Loss(train/val) 0.00/15.18. Took 52.68 sec\n",
      "Epoch 49, Acc(train/val): 1.18/152.03, Loss(train/val) 0.00/15.63. Took 52.74 sec\n",
      "Epoch 50, Acc(train/val): 1.18/151.57, Loss(train/val) 0.00/15.42. Took 53.65 sec\n",
      "Namespace(batch_size=16, device='cpu', dropout=0.3, epoch=50, exp_name='exp1_lr', hid_dim=10, input_dim=6, l2=0.0001, lr=0.0001, n_layers=3, optim='Adam', path='./model_checkpoint/', use_bn=True, x_frames=5, y_frames=1)\n",
      "Epoch 1, Acc(train/val): 4.01/61.56, Loss(train/val) 0.01/2.07. Took 59.38 sec\n",
      "Epoch 2, Acc(train/val): 3.10/94.91, Loss(train/val) 0.01/5.12. Took 60.73 sec\n",
      "Epoch 3, Acc(train/val): 2.60/139.08, Loss(train/val) 0.00/11.62. Took 58.70 sec\n",
      "Epoch 4, Acc(train/val): 2.21/163.43, Loss(train/val) 0.00/16.42. Took 68.81 sec\n",
      "Epoch 5, Acc(train/val): 2.08/167.31, Loss(train/val) 0.00/17.30. Took 72.99 sec\n",
      "Epoch 6, Acc(train/val): 2.00/178.18, Loss(train/val) 0.00/19.61. Took 71.24 sec\n",
      "Epoch 7, Acc(train/val): 1.96/182.18, Loss(train/val) 0.00/20.53. Took 68.10 sec\n",
      "Epoch 8, Acc(train/val): 1.92/182.79, Loss(train/val) 0.00/20.82. Took 60.45 sec\n",
      "Epoch 9, Acc(train/val): 1.90/195.68, Loss(train/val) 0.00/23.72. Took 58.90 sec\n",
      "Epoch 10, Acc(train/val): 1.89/191.37, Loss(train/val) 0.00/22.84. Took 62.02 sec\n",
      "Epoch 11, Acc(train/val): 1.86/200.91, Loss(train/val) 0.00/25.22. Took 61.58 sec\n",
      "Epoch 12, Acc(train/val): 1.84/204.50, Loss(train/val) 0.00/26.07. Took 59.20 sec\n",
      "Epoch 13, Acc(train/val): 1.85/201.76, Loss(train/val) 0.00/25.46. Took 59.21 sec\n",
      "Epoch 14, Acc(train/val): 1.84/203.97, Loss(train/val) 0.00/26.25. Took 60.16 sec\n",
      "Epoch 15, Acc(train/val): 1.82/216.17, Loss(train/val) 0.00/29.74. Took 61.85 sec\n",
      "Epoch 16, Acc(train/val): 1.82/214.10, Loss(train/val) 0.00/29.35. Took 58.81 sec\n",
      "Epoch 17, Acc(train/val): 1.80/223.59, Loss(train/val) 0.00/31.92. Took 65.28 sec\n",
      "Epoch 18, Acc(train/val): 1.80/223.47, Loss(train/val) 0.00/32.23. Took 60.29 sec\n",
      "Epoch 19, Acc(train/val): 1.79/228.56, Loss(train/val) 0.00/33.32. Took 60.24 sec\n",
      "Epoch 20, Acc(train/val): 1.79/218.65, Loss(train/val) 0.00/30.88. Took 60.44 sec\n",
      "Epoch 21, Acc(train/val): 1.78/228.75, Loss(train/val) 0.00/33.71. Took 60.43 sec\n",
      "Epoch 22, Acc(train/val): 1.77/218.46, Loss(train/val) 0.00/31.12. Took 59.71 sec\n",
      "Epoch 23, Acc(train/val): 1.77/238.89, Loss(train/val) 0.00/36.95. Took 60.80 sec\n",
      "Epoch 24, Acc(train/val): 1.77/235.11, Loss(train/val) 0.00/35.74. Took 60.49 sec\n",
      "Epoch 25, Acc(train/val): 1.76/231.24, Loss(train/val) 0.00/35.17. Took 61.02 sec\n",
      "Epoch 26, Acc(train/val): 1.75/235.59, Loss(train/val) 0.00/36.72. Took 59.71 sec\n",
      "Epoch 27, Acc(train/val): 1.74/228.02, Loss(train/val) 0.00/34.48. Took 64.24 sec\n",
      "Epoch 28, Acc(train/val): 1.75/234.85, Loss(train/val) 0.00/36.68. Took 59.45 sec\n",
      "Epoch 29, Acc(train/val): 1.73/233.17, Loss(train/val) 0.00/36.19. Took 61.92 sec\n",
      "Epoch 30, Acc(train/val): 1.72/234.85, Loss(train/val) 0.00/36.62. Took 60.00 sec\n",
      "Epoch 31, Acc(train/val): 1.70/236.29, Loss(train/val) 0.00/37.45. Took 58.97 sec\n",
      "Epoch 32, Acc(train/val): 1.69/225.35, Loss(train/val) 0.00/34.14. Took 64.09 sec\n",
      "Epoch 33, Acc(train/val): 1.65/230.29, Loss(train/val) 0.00/35.60. Took 61.89 sec\n",
      "Epoch 34, Acc(train/val): 1.60/229.81, Loss(train/val) 0.00/35.83. Took 60.91 sec\n",
      "Epoch 35, Acc(train/val): 1.55/224.80, Loss(train/val) 0.00/34.97. Took 61.84 sec\n",
      "Epoch 36, Acc(train/val): 1.52/228.68, Loss(train/val) 0.00/36.33. Took 68.77 sec\n",
      "Epoch 37, Acc(train/val): 1.49/222.20, Loss(train/val) 0.00/34.45. Took 79.45 sec\n",
      "Epoch 38, Acc(train/val): 1.47/204.88, Loss(train/val) 0.00/28.86. Took 74.03 sec\n",
      "Epoch 39, Acc(train/val): 1.44/198.44, Loss(train/val) 0.00/26.91. Took 73.81 sec\n",
      "Epoch 40, Acc(train/val): 1.41/197.12, Loss(train/val) 0.00/26.45. Took 73.87 sec\n",
      "Epoch 41, Acc(train/val): 1.39/182.83, Loss(train/val) 0.00/22.99. Took 73.32 sec\n",
      "Epoch 42, Acc(train/val): 1.38/190.99, Loss(train/val) 0.00/25.06. Took 69.82 sec\n",
      "Epoch 43, Acc(train/val): 1.36/184.00, Loss(train/val) 0.00/23.34. Took 73.51 sec\n",
      "Epoch 44, Acc(train/val): 1.34/176.97, Loss(train/val) 0.00/21.31. Took 73.54 sec\n",
      "Epoch 45, Acc(train/val): 1.32/177.24, Loss(train/val) 0.00/21.40. Took 73.52 sec\n",
      "Epoch 46, Acc(train/val): 1.31/184.71, Loss(train/val) 0.00/23.02. Took 73.45 sec\n",
      "Epoch 47, Acc(train/val): 1.29/181.78, Loss(train/val) 0.00/22.25. Took 73.67 sec\n",
      "Epoch 48, Acc(train/val): 1.28/173.37, Loss(train/val) 0.00/20.56. Took 72.78 sec\n",
      "Epoch 49, Acc(train/val): 1.26/168.49, Loss(train/val) 0.00/19.51. Took 60.56 sec\n",
      "Epoch 50, Acc(train/val): 1.24/156.49, Loss(train/val) 0.00/16.84. Took 59.32 sec\n",
      "Namespace(batch_size=16, device='cpu', dropout=0.3, epoch=50, exp_name='exp1_lr', hid_dim=50, input_dim=6, l2=0.0001, lr=0.0001, n_layers=1, optim='Adam', path='./model_checkpoint/', use_bn=True, x_frames=5, y_frames=1)\n",
      "Epoch 1, Acc(train/val): 3.04/173.07, Loss(train/val) 0.01/17.46. Took 62.43 sec\n",
      "Epoch 2, Acc(train/val): 1.88/202.71, Loss(train/val) 0.00/27.81. Took 63.58 sec\n",
      "Epoch 3, Acc(train/val): 1.60/231.51, Loss(train/val) 0.00/37.26. Took 62.39 sec\n",
      "Epoch 4, Acc(train/val): 1.47/226.23, Loss(train/val) 0.00/35.95. Took 62.51 sec\n",
      "Epoch 5, Acc(train/val): 1.39/213.56, Loss(train/val) 0.00/32.41. Took 63.93 sec\n",
      "Epoch 6, Acc(train/val): 1.32/217.52, Loss(train/val) 0.00/33.27. Took 64.73 sec\n",
      "Epoch 7, Acc(train/val): 1.26/203.38, Loss(train/val) 0.00/29.71. Took 64.99 sec\n",
      "Epoch 8, Acc(train/val): 1.20/186.33, Loss(train/val) 0.00/25.48. Took 66.64 sec\n",
      "Epoch 9, Acc(train/val): 1.13/182.82, Loss(train/val) 0.00/24.51. Took 62.59 sec\n",
      "Epoch 10, Acc(train/val): 1.06/166.59, Loss(train/val) 0.00/20.66. Took 58.05 sec\n",
      "Epoch 11, Acc(train/val): 1.01/165.34, Loss(train/val) 0.00/20.65. Took 63.00 sec\n",
      "Epoch 12, Acc(train/val): 0.95/147.94, Loss(train/val) 0.00/16.98. Took 62.40 sec\n",
      "Epoch 13, Acc(train/val): 0.91/128.55, Loss(train/val) 0.00/13.29. Took 59.18 sec\n",
      "Epoch 14, Acc(train/val): 0.86/125.96, Loss(train/val) 0.00/12.65. Took 58.24 sec\n",
      "Epoch 15, Acc(train/val): 0.83/121.86, Loss(train/val) 0.00/11.50. Took 58.34 sec\n",
      "Epoch 16, Acc(train/val): 0.79/104.42, Loss(train/val) 0.00/8.54. Took 58.19 sec\n",
      "Epoch 17, Acc(train/val): 0.77/95.03, Loss(train/val) 0.00/7.05. Took 58.97 sec\n",
      "Epoch 18, Acc(train/val): 0.75/101.33, Loss(train/val) 0.00/7.93. Took 60.34 sec\n",
      "Epoch 19, Acc(train/val): 0.73/86.12, Loss(train/val) 0.00/5.83. Took 59.48 sec\n",
      "Epoch 20, Acc(train/val): 0.72/75.31, Loss(train/val) 0.00/4.49. Took 65.99 sec\n",
      "Epoch 21, Acc(train/val): 0.70/68.89, Loss(train/val) 0.00/3.75. Took 61.19 sec\n",
      "Epoch 22, Acc(train/val): 0.68/72.78, Loss(train/val) 0.00/4.19. Took 65.35 sec\n",
      "Epoch 23, Acc(train/val): 0.67/63.93, Loss(train/val) 0.00/3.27. Took 64.01 sec\n",
      "Epoch 24, Acc(train/val): 0.66/63.24, Loss(train/val) 0.00/3.21. Took 59.67 sec\n",
      "Epoch 25, Acc(train/val): 0.65/58.29, Loss(train/val) 0.00/2.69. Took 59.45 sec\n",
      "Epoch 26, Acc(train/val): 0.65/57.46, Loss(train/val) 0.00/2.65. Took 61.57 sec\n",
      "Epoch 27, Acc(train/val): 0.64/55.93, Loss(train/val) 0.00/2.51. Took 57.60 sec\n",
      "Epoch 28, Acc(train/val): 0.63/53.98, Loss(train/val) 0.00/2.35. Took 62.72 sec\n",
      "Epoch 29, Acc(train/val): 0.63/39.38, Loss(train/val) 0.00/1.22. Took 55.85 sec\n",
      "Epoch 30, Acc(train/val): 0.62/45.75, Loss(train/val) 0.00/1.68. Took 54.77 sec\n",
      "Epoch 31, Acc(train/val): 0.62/40.80, Loss(train/val) 0.00/1.40. Took 55.28 sec\n",
      "Epoch 32, Acc(train/val): 0.61/44.23, Loss(train/val) 0.00/1.61. Took 54.82 sec\n",
      "Epoch 33, Acc(train/val): 0.60/40.96, Loss(train/val) 0.00/1.42. Took 54.80 sec\n",
      "Epoch 34, Acc(train/val): 0.60/35.42, Loss(train/val) 0.00/1.02. Took 53.61 sec\n",
      "Epoch 35, Acc(train/val): 0.59/39.66, Loss(train/val) 0.00/1.32. Took 59.94 sec\n",
      "Epoch 36, Acc(train/val): 0.60/32.62, Loss(train/val) 0.00/0.87. Took 54.15 sec\n",
      "Epoch 37, Acc(train/val): 0.59/41.80, Loss(train/val) 0.00/1.49. Took 56.93 sec\n",
      "Epoch 38, Acc(train/val): 0.59/38.89, Loss(train/val) 0.00/1.31. Took 53.67 sec\n",
      "Epoch 39, Acc(train/val): 0.59/34.73, Loss(train/val) 0.00/1.01. Took 56.93 sec\n",
      "Epoch 40, Acc(train/val): 0.58/34.56, Loss(train/val) 0.00/0.96. Took 56.99 sec\n",
      "Epoch 41, Acc(train/val): 0.57/38.66, Loss(train/val) 0.00/1.23. Took 54.96 sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42, Acc(train/val): 0.58/32.75, Loss(train/val) 0.00/0.85. Took 55.27 sec\n",
      "Epoch 43, Acc(train/val): 0.57/26.41, Loss(train/val) 0.00/0.61. Took 64.62 sec\n",
      "Epoch 44, Acc(train/val): 0.57/24.34, Loss(train/val) 0.00/0.49. Took 65.11 sec\n",
      "Epoch 45, Acc(train/val): 0.57/26.18, Loss(train/val) 0.00/0.58. Took 66.02 sec\n",
      "Epoch 46, Acc(train/val): 0.57/25.30, Loss(train/val) 0.00/0.54. Took 66.58 sec\n",
      "Epoch 47, Acc(train/val): 0.56/31.08, Loss(train/val) 0.00/0.78. Took 73.54 sec\n",
      "Epoch 48, Acc(train/val): 0.56/23.73, Loss(train/val) 0.00/0.43. Took 67.81 sec\n",
      "Epoch 49, Acc(train/val): 0.56/22.24, Loss(train/val) 0.00/0.37. Took 72.57 sec\n",
      "Epoch 50, Acc(train/val): 0.56/20.24, Loss(train/val) 0.00/0.32. Took 70.60 sec\n",
      "Namespace(batch_size=16, device='cpu', dropout=0.3, epoch=50, exp_name='exp1_lr', hid_dim=50, input_dim=6, l2=0.0001, lr=0.0001, n_layers=2, optim='Adam', path='./model_checkpoint/', use_bn=True, x_frames=5, y_frames=1)\n",
      "Epoch 1, Acc(train/val): 2.45/164.26, Loss(train/val) 0.00/16.62. Took 110.26 sec\n",
      "Epoch 2, Acc(train/val): 1.90/197.64, Loss(train/val) 0.00/27.14. Took 121.12 sec\n",
      "Epoch 3, Acc(train/val): 1.45/181.88, Loss(train/val) 0.00/23.16. Took 118.98 sec\n",
      "Epoch 4, Acc(train/val): 1.21/164.88, Loss(train/val) 0.00/19.77. Took 110.05 sec\n",
      "Epoch 5, Acc(train/val): 1.07/147.84, Loss(train/val) 0.00/16.13. Took 114.10 sec\n",
      "Epoch 6, Acc(train/val): 0.98/116.20, Loss(train/val) 0.00/10.07. Took 98.29 sec\n",
      "Epoch 7, Acc(train/val): 0.90/117.28, Loss(train/val) 0.00/10.12. Took 119.13 sec\n",
      "Epoch 8, Acc(train/val): 0.85/97.79, Loss(train/val) 0.00/7.09. Took 116.99 sec\n",
      "Epoch 9, Acc(train/val): 0.80/82.85, Loss(train/val) 0.00/5.11. Took 115.64 sec\n",
      "Epoch 10, Acc(train/val): 0.76/68.63, Loss(train/val) 0.00/3.53. Took 99.88 sec\n",
      "Epoch 11, Acc(train/val): 0.73/75.49, Loss(train/val) 0.00/4.25. Took 93.96 sec\n",
      "Epoch 12, Acc(train/val): 0.71/65.12, Loss(train/val) 0.00/3.14. Took 111.40 sec\n",
      "Epoch 13, Acc(train/val): 0.69/58.61, Loss(train/val) 0.00/2.52. Took 113.15 sec\n",
      "Epoch 14, Acc(train/val): 0.67/50.85, Loss(train/val) 0.00/1.88. Took 116.95 sec\n",
      "Epoch 15, Acc(train/val): 0.65/51.25, Loss(train/val) 0.00/1.91. Took 109.04 sec\n",
      "Epoch 16, Acc(train/val): 0.64/42.76, Loss(train/val) 0.00/1.33. Took 115.26 sec\n",
      "Epoch 17, Acc(train/val): 0.62/40.47, Loss(train/val) 0.00/1.18. Took 66.74 sec\n",
      "Epoch 18, Acc(train/val): 0.61/40.66, Loss(train/val) 0.00/1.20. Took 59.90 sec\n",
      "Epoch 19, Acc(train/val): 0.60/34.88, Loss(train/val) 0.00/0.87. Took 58.05 sec\n",
      "Epoch 20, Acc(train/val): 0.60/30.57, Loss(train/val) 0.00/0.65. Took 57.57 sec\n",
      "Epoch 21, Acc(train/val): 0.59/27.93, Loss(train/val) 0.00/0.54. Took 58.99 sec\n",
      "Epoch 22, Acc(train/val): 0.58/34.71, Loss(train/val) 0.00/0.85. Took 59.36 sec\n",
      "Epoch 23, Acc(train/val): 0.57/26.23, Loss(train/val) 0.00/0.47. Took 77.83 sec\n",
      "Epoch 24, Acc(train/val): 0.57/26.38, Loss(train/val) 0.00/0.47. Took 73.20 sec\n",
      "Epoch 25, Acc(train/val): 0.56/26.92, Loss(train/val) 0.00/0.50. Took 79.78 sec\n",
      "Epoch 26, Acc(train/val): 0.56/24.51, Loss(train/val) 0.00/0.41. Took 80.87 sec\n",
      "Epoch 27, Acc(train/val): 0.55/27.57, Loss(train/val) 0.00/0.52. Took 76.67 sec\n",
      "Epoch 28, Acc(train/val): 0.55/23.86, Loss(train/val) 0.00/0.39. Took 77.45 sec\n",
      "Epoch 29, Acc(train/val): 0.55/20.32, Loss(train/val) 0.00/0.28. Took 81.98 sec\n",
      "Epoch 30, Acc(train/val): 0.55/19.42, Loss(train/val) 0.00/0.25. Took 71.60 sec\n",
      "Epoch 31, Acc(train/val): 0.54/22.00, Loss(train/val) 0.00/0.32. Took 66.67 sec\n",
      "Epoch 32, Acc(train/val): 0.54/18.37, Loss(train/val) 0.00/0.22. Took 66.48 sec\n",
      "Epoch 33, Acc(train/val): 0.54/18.22, Loss(train/val) 0.00/0.22. Took 66.84 sec\n",
      "Epoch 34, Acc(train/val): 0.54/16.58, Loss(train/val) 0.00/0.18. Took 66.75 sec\n",
      "Epoch 35, Acc(train/val): 0.53/19.24, Loss(train/val) 0.00/0.25. Took 66.26 sec\n",
      "Epoch 36, Acc(train/val): 0.53/16.54, Loss(train/val) 0.00/0.18. Took 66.49 sec\n",
      "Epoch 37, Acc(train/val): 0.53/20.03, Loss(train/val) 0.00/0.27. Took 70.83 sec\n",
      "Epoch 38, Acc(train/val): 0.53/14.75, Loss(train/val) 0.00/0.14. Took 68.36 sec\n",
      "Epoch 39, Acc(train/val): 0.53/15.32, Loss(train/val) 0.00/0.15. Took 67.79 sec\n",
      "Epoch 40, Acc(train/val): 0.53/19.20, Loss(train/val) 0.00/0.25. Took 81.00 sec\n",
      "Epoch 41, Acc(train/val): 0.52/12.69, Loss(train/val) 0.00/0.10. Took 105.48 sec\n",
      "Epoch 42, Acc(train/val): 0.53/11.42, Loss(train/val) 0.00/0.08. Took 106.91 sec\n",
      "Epoch 43, Acc(train/val): 0.52/12.06, Loss(train/val) 0.00/0.09. Took 106.96 sec\n",
      "Epoch 44, Acc(train/val): 0.52/11.84, Loss(train/val) 0.00/0.09. Took 106.44 sec\n",
      "Epoch 45, Acc(train/val): 0.52/13.96, Loss(train/val) 0.00/0.13. Took 88.85 sec\n",
      "Epoch 46, Acc(train/val): 0.51/11.34, Loss(train/val) 0.00/0.08. Took 84.01 sec\n",
      "Epoch 47, Acc(train/val): 0.51/10.25, Loss(train/val) 0.00/0.07. Took 87.84 sec\n",
      "Epoch 48, Acc(train/val): 0.51/9.17, Loss(train/val) 0.00/0.06. Took 89.00 sec\n",
      "Epoch 49, Acc(train/val): 0.51/8.76, Loss(train/val) 0.00/0.05. Took 84.86 sec\n",
      "Epoch 50, Acc(train/val): 0.51/8.51, Loss(train/val) 0.00/0.05. Took 84.24 sec\n",
      "Namespace(batch_size=16, device='cpu', dropout=0.3, epoch=50, exp_name='exp1_lr', hid_dim=50, input_dim=6, l2=0.0001, lr=0.0001, n_layers=3, optim='Adam', path='./model_checkpoint/', use_bn=True, x_frames=5, y_frames=1)\n",
      "Epoch 1, Acc(train/val): 2.61/162.47, Loss(train/val) 0.01/16.29. Took 105.24 sec\n",
      "Epoch 2, Acc(train/val): 2.03/177.61, Loss(train/val) 0.00/22.09. Took 116.32 sec\n",
      "Epoch 3, Acc(train/val): 1.70/110.73, Loss(train/val) 0.00/8.91. Took 114.88 sec\n",
      "Epoch 4, Acc(train/val): 1.36/105.35, Loss(train/val) 0.00/8.05. Took 134.85 sec\n",
      "Epoch 5, Acc(train/val): 1.15/113.92, Loss(train/val) 0.00/9.46. Took 114.45 sec\n",
      "Epoch 6, Acc(train/val): 1.06/99.93, Loss(train/val) 0.00/7.35. Took 109.00 sec\n",
      "Epoch 7, Acc(train/val): 0.99/90.45, Loss(train/val) 0.00/5.84. Took 86.81 sec\n",
      "Epoch 8, Acc(train/val): 0.91/78.38, Loss(train/val) 0.00/4.32. Took 97.34 sec\n",
      "Epoch 9, Acc(train/val): 0.87/70.55, Loss(train/val) 0.00/3.55. Took 88.79 sec\n",
      "Epoch 10, Acc(train/val): 0.82/55.25, Loss(train/val) 0.00/2.15. Took 83.44 sec\n",
      "Epoch 11, Acc(train/val): 0.79/64.93, Loss(train/val) 0.00/3.00. Took 82.17 sec\n",
      "Epoch 12, Acc(train/val): 0.75/53.23, Loss(train/val) 0.00/2.02. Took 79.24 sec\n",
      "Epoch 13, Acc(train/val): 0.72/53.24, Loss(train/val) 0.00/2.01. Took 78.78 sec\n",
      "Epoch 14, Acc(train/val): 0.70/48.95, Loss(train/val) 0.00/1.73. Took 78.64 sec\n",
      "Epoch 15, Acc(train/val): 0.68/46.70, Loss(train/val) 0.00/1.53. Took 79.77 sec\n",
      "Epoch 16, Acc(train/val): 0.66/44.62, Loss(train/val) 0.00/1.37. Took 77.41 sec\n",
      "Epoch 17, Acc(train/val): 0.65/47.45, Loss(train/val) 0.00/1.57. Took 79.62 sec\n",
      "Epoch 18, Acc(train/val): 0.64/43.13, Loss(train/val) 0.00/1.29. Took 78.25 sec\n",
      "Epoch 19, Acc(train/val): 0.62/34.62, Loss(train/val) 0.00/0.81. Took 77.82 sec\n",
      "Epoch 20, Acc(train/val): 0.62/32.36, Loss(train/val) 0.00/0.69. Took 77.40 sec\n",
      "Epoch 21, Acc(train/val): 0.61/38.44, Loss(train/val) 0.00/0.96. Took 78.12 sec\n",
      "Epoch 22, Acc(train/val): 0.60/36.22, Loss(train/val) 0.00/0.84. Took 77.10 sec\n",
      "Epoch 23, Acc(train/val): 0.59/36.27, Loss(train/val) 0.00/0.84. Took 76.92 sec\n",
      "Epoch 24, Acc(train/val): 0.58/28.61, Loss(train/val) 0.00/0.51. Took 78.85 sec\n",
      "Epoch 25, Acc(train/val): 0.58/26.58, Loss(train/val) 0.00/0.44. Took 78.87 sec\n",
      "Epoch 26, Acc(train/val): 0.57/27.50, Loss(train/val) 0.00/0.46. Took 78.06 sec\n",
      "Epoch 27, Acc(train/val): 0.57/34.50, Loss(train/val) 0.00/0.73. Took 75.25 sec\n",
      "Epoch 28, Acc(train/val): 0.56/31.82, Loss(train/val) 0.00/0.62. Took 82.06 sec\n",
      "Epoch 29, Acc(train/val): 0.56/32.72, Loss(train/val) 0.00/0.66. Took 85.66 sec\n",
      "Epoch 30, Acc(train/val): 0.56/32.80, Loss(train/val) 0.00/0.66. Took 78.28 sec\n",
      "Epoch 31, Acc(train/val): 0.55/28.10, Loss(train/val) 0.00/0.48. Took 78.08 sec\n",
      "Epoch 32, Acc(train/val): 0.55/25.84, Loss(train/val) 0.00/0.40. Took 79.85 sec\n",
      "Epoch 33, Acc(train/val): 0.55/22.88, Loss(train/val) 0.00/0.31. Took 87.61 sec\n",
      "Epoch 34, Acc(train/val): 0.54/28.52, Loss(train/val) 0.00/0.49. Took 85.54 sec\n",
      "Epoch 35, Acc(train/val): 0.54/29.92, Loss(train/val) 0.00/0.54. Took 85.73 sec\n",
      "Epoch 36, Acc(train/val): 0.54/28.43, Loss(train/val) 0.00/0.48. Took 74.42 sec\n",
      "Epoch 37, Acc(train/val): 0.54/29.27, Loss(train/val) 0.00/0.52. Took 65.87 sec\n",
      "Epoch 38, Acc(train/val): 0.53/28.85, Loss(train/val) 0.00/0.50. Took 65.83 sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39, Acc(train/val): 0.54/25.41, Loss(train/val) 0.00/0.39. Took 65.07 sec\n",
      "Epoch 40, Acc(train/val): 0.53/24.85, Loss(train/val) 0.00/0.37. Took 66.20 sec\n",
      "Epoch 41, Acc(train/val): 0.53/26.62, Loss(train/val) 0.00/0.42. Took 65.25 sec\n",
      "Epoch 42, Acc(train/val): 0.53/31.50, Loss(train/val) 0.00/0.60. Took 65.77 sec\n",
      "Epoch 43, Acc(train/val): 0.53/28.20, Loss(train/val) 0.00/0.47. Took 78.11 sec\n",
      "Epoch 44, Acc(train/val): 0.53/31.64, Loss(train/val) 0.00/0.60. Took 84.05 sec\n",
      "Epoch 45, Acc(train/val): 0.52/31.43, Loss(train/val) 0.00/0.59. Took 81.87 sec\n",
      "Epoch 46, Acc(train/val): 0.52/26.17, Loss(train/val) 0.00/0.41. Took 80.12 sec\n",
      "Epoch 47, Acc(train/val): 0.52/24.05, Loss(train/val) 0.00/0.34. Took 81.06 sec\n",
      "Epoch 48, Acc(train/val): 0.52/27.36, Loss(train/val) 0.00/0.44. Took 81.40 sec\n",
      "Epoch 49, Acc(train/val): 0.52/22.87, Loss(train/val) 0.00/0.31. Took 80.80 sec\n",
      "Epoch 50, Acc(train/val): 0.52/24.64, Loss(train/val) 0.00/0.36. Took 74.44 sec\n",
      "Namespace(batch_size=16, device='cpu', dropout=0.3, epoch=50, exp_name='exp1_lr', hid_dim=100, input_dim=6, l2=0.0001, lr=0.0001, n_layers=1, optim='Adam', path='./model_checkpoint/', use_bn=True, x_frames=5, y_frames=1)\n",
      "Epoch 1, Acc(train/val): 2.21/170.41, Loss(train/val) 0.00/18.00. Took 54.73 sec\n",
      "Epoch 2, Acc(train/val): 1.57/237.95, Loss(train/val) 0.00/40.40. Took 54.63 sec\n",
      "Epoch 3, Acc(train/val): 1.34/216.48, Loss(train/val) 0.00/34.35. Took 56.27 sec\n",
      "Epoch 4, Acc(train/val): 1.24/192.15, Loss(train/val) 0.00/27.49. Took 55.27 sec\n",
      "Epoch 5, Acc(train/val): 1.16/202.28, Loss(train/val) 0.00/29.96. Took 54.91 sec\n",
      "Epoch 6, Acc(train/val): 1.08/173.79, Loss(train/val) 0.00/22.48. Took 55.62 sec\n",
      "Epoch 7, Acc(train/val): 1.00/155.71, Loss(train/val) 0.00/18.00. Took 54.57 sec\n",
      "Epoch 8, Acc(train/val): 0.93/131.67, Loss(train/val) 0.00/13.08. Took 54.57 sec\n",
      "Epoch 9, Acc(train/val): 0.87/117.06, Loss(train/val) 0.00/10.44. Took 54.80 sec\n",
      "Epoch 10, Acc(train/val): 0.82/103.79, Loss(train/val) 0.00/8.03. Took 54.28 sec\n",
      "Epoch 11, Acc(train/val): 0.78/110.96, Loss(train/val) 0.00/9.18. Took 56.55 sec\n",
      "Epoch 12, Acc(train/val): 0.74/82.89, Loss(train/val) 0.00/5.24. Took 58.44 sec\n",
      "Epoch 13, Acc(train/val): 0.71/71.08, Loss(train/val) 0.00/3.83. Took 54.44 sec\n",
      "Epoch 14, Acc(train/val): 0.69/66.43, Loss(train/val) 0.00/3.29. Took 57.49 sec\n",
      "Epoch 15, Acc(train/val): 0.67/57.02, Loss(train/val) 0.00/2.38. Took 55.84 sec\n",
      "Epoch 16, Acc(train/val): 0.65/52.62, Loss(train/val) 0.00/2.00. Took 54.96 sec\n",
      "Epoch 17, Acc(train/val): 0.64/48.54, Loss(train/val) 0.00/1.71. Took 54.95 sec\n",
      "Epoch 18, Acc(train/val): 0.63/46.70, Loss(train/val) 0.00/1.57. Took 54.64 sec\n",
      "Epoch 19, Acc(train/val): 0.62/46.99, Loss(train/val) 0.00/1.57. Took 54.92 sec\n",
      "Epoch 20, Acc(train/val): 0.61/36.30, Loss(train/val) 0.00/0.91. Took 55.30 sec\n",
      "Epoch 21, Acc(train/val): 0.60/44.41, Loss(train/val) 0.00/1.38. Took 54.25 sec\n",
      "Epoch 22, Acc(train/val): 0.60/32.25, Loss(train/val) 0.00/0.70. Took 55.27 sec\n",
      "Epoch 23, Acc(train/val): 0.59/30.27, Loss(train/val) 0.00/0.62. Took 54.24 sec\n",
      "Epoch 24, Acc(train/val): 0.59/30.69, Loss(train/val) 0.00/0.62. Took 54.12 sec\n",
      "Epoch 25, Acc(train/val): 0.58/30.19, Loss(train/val) 0.00/0.60. Took 54.29 sec\n",
      "Epoch 26, Acc(train/val): 0.58/26.67, Loss(train/val) 0.00/0.47. Took 53.90 sec\n",
      "Epoch 27, Acc(train/val): 0.58/30.98, Loss(train/val) 0.00/0.66. Took 57.87 sec\n",
      "Epoch 28, Acc(train/val): 0.57/29.91, Loss(train/val) 0.00/0.60. Took 58.92 sec\n",
      "Epoch 29, Acc(train/val): 0.57/27.52, Loss(train/val) 0.00/0.50. Took 54.61 sec\n",
      "Epoch 30, Acc(train/val): 0.56/24.53, Loss(train/val) 0.00/0.39. Took 55.25 sec\n",
      "Epoch 31, Acc(train/val): 0.55/23.38, Loss(train/val) 0.00/0.35. Took 55.04 sec\n",
      "Epoch 32, Acc(train/val): 0.55/27.17, Loss(train/val) 0.00/0.49. Took 54.18 sec\n",
      "Epoch 33, Acc(train/val): 0.55/27.05, Loss(train/val) 0.00/0.48. Took 55.06 sec\n",
      "Epoch 34, Acc(train/val): 0.55/21.90, Loss(train/val) 0.00/0.30. Took 54.12 sec\n",
      "Epoch 35, Acc(train/val): 0.55/21.78, Loss(train/val) 0.00/0.31. Took 54.78 sec\n",
      "Epoch 36, Acc(train/val): 0.54/24.21, Loss(train/val) 0.00/0.39. Took 55.48 sec\n",
      "Epoch 37, Acc(train/val): 0.54/26.09, Loss(train/val) 0.00/0.45. Took 61.44 sec\n",
      "Epoch 38, Acc(train/val): 0.54/23.40, Loss(train/val) 0.00/0.36. Took 63.04 sec\n",
      "Epoch 39, Acc(train/val): 0.54/22.90, Loss(train/val) 0.00/0.35. Took 55.90 sec\n",
      "Epoch 40, Acc(train/val): 0.54/22.84, Loss(train/val) 0.00/0.34. Took 55.84 sec\n",
      "Epoch 41, Acc(train/val): 0.54/27.39, Loss(train/val) 0.00/0.51. Took 56.96 sec\n",
      "Epoch 42, Acc(train/val): 0.54/17.46, Loss(train/val) 0.00/0.20. Took 55.62 sec\n",
      "Epoch 43, Acc(train/val): 0.53/22.53, Loss(train/val) 0.00/0.34. Took 54.34 sec\n",
      "Epoch 44, Acc(train/val): 0.54/17.75, Loss(train/val) 0.00/0.21. Took 54.44 sec\n",
      "Epoch 45, Acc(train/val): 0.53/28.41, Loss(train/val) 0.00/0.55. Took 54.26 sec\n",
      "Epoch 46, Acc(train/val): 0.53/29.08, Loss(train/val) 0.00/0.59. Took 54.15 sec\n",
      "Epoch 47, Acc(train/val): 0.53/23.39, Loss(train/val) 0.00/0.36. Took 54.32 sec\n",
      "Epoch 48, Acc(train/val): 0.53/29.09, Loss(train/val) 0.00/0.58. Took 54.12 sec\n",
      "Epoch 49, Acc(train/val): 0.52/20.54, Loss(train/val) 0.00/0.29. Took 55.28 sec\n",
      "Epoch 50, Acc(train/val): 0.53/24.61, Loss(train/val) 0.00/0.41. Took 53.83 sec\n",
      "Namespace(batch_size=16, device='cpu', dropout=0.3, epoch=50, exp_name='exp1_lr', hid_dim=100, input_dim=6, l2=0.0001, lr=0.0001, n_layers=2, optim='Adam', path='./model_checkpoint/', use_bn=True, x_frames=5, y_frames=1)\n",
      "Epoch 1, Acc(train/val): 2.22/179.75, Loss(train/val) 0.00/21.66. Took 65.04 sec\n",
      "Epoch 2, Acc(train/val): 1.42/190.86, Loss(train/val) 0.00/25.64. Took 64.98 sec\n",
      "Epoch 3, Acc(train/val): 1.17/164.67, Loss(train/val) 0.00/18.94. Took 64.73 sec\n",
      "Epoch 4, Acc(train/val): 1.02/131.48, Loss(train/val) 0.00/12.02. Took 65.67 sec\n",
      "Epoch 5, Acc(train/val): 0.90/107.45, Loss(train/val) 0.00/8.10. Took 64.00 sec\n",
      "Epoch 6, Acc(train/val): 0.84/98.24, Loss(train/val) 0.00/6.96. Took 64.82 sec\n",
      "Epoch 7, Acc(train/val): 0.78/85.71, Loss(train/val) 0.00/5.26. Took 64.60 sec\n",
      "Epoch 8, Acc(train/val): 0.74/90.22, Loss(train/val) 0.00/5.65. Took 65.92 sec\n",
      "Epoch 9, Acc(train/val): 0.71/62.59, Loss(train/val) 0.00/2.71. Took 64.31 sec\n",
      "Epoch 10, Acc(train/val): 0.69/67.93, Loss(train/val) 0.00/3.25. Took 64.49 sec\n",
      "Epoch 11, Acc(train/val): 0.68/54.50, Loss(train/val) 0.00/2.08. Took 65.15 sec\n",
      "Epoch 12, Acc(train/val): 0.66/53.65, Loss(train/val) 0.00/2.03. Took 64.81 sec\n",
      "Epoch 13, Acc(train/val): 0.64/51.05, Loss(train/val) 0.00/1.78. Took 65.07 sec\n",
      "Epoch 14, Acc(train/val): 0.63/47.97, Loss(train/val) 0.00/1.62. Took 65.28 sec\n",
      "Epoch 15, Acc(train/val): 0.62/36.72, Loss(train/val) 0.00/0.94. Took 64.42 sec\n",
      "Epoch 16, Acc(train/val): 0.61/37.69, Loss(train/val) 0.00/0.98. Took 65.95 sec\n",
      "Epoch 17, Acc(train/val): 0.61/34.21, Loss(train/val) 0.00/0.80. Took 64.94 sec\n",
      "Epoch 18, Acc(train/val): 0.60/35.06, Loss(train/val) 0.00/0.86. Took 64.65 sec\n",
      "Epoch 19, Acc(train/val): 0.59/30.02, Loss(train/val) 0.00/0.61. Took 64.32 sec\n",
      "Epoch 20, Acc(train/val): 0.59/25.44, Loss(train/val) 0.00/0.44. Took 64.89 sec\n",
      "Epoch 21, Acc(train/val): 0.58/23.96, Loss(train/val) 0.00/0.39. Took 65.61 sec\n",
      "Epoch 22, Acc(train/val): 0.58/16.99, Loss(train/val) 0.00/0.20. Took 64.40 sec\n",
      "Epoch 23, Acc(train/val): 0.57/19.76, Loss(train/val) 0.00/0.26. Took 65.87 sec\n",
      "Epoch 24, Acc(train/val): 0.57/16.39, Loss(train/val) 0.00/0.18. Took 64.93 sec\n",
      "Epoch 25, Acc(train/val): 0.56/15.90, Loss(train/val) 0.00/0.17. Took 65.76 sec\n",
      "Epoch 26, Acc(train/val): 0.56/17.20, Loss(train/val) 0.00/0.20. Took 64.98 sec\n",
      "Epoch 27, Acc(train/val): 0.55/21.92, Loss(train/val) 0.00/0.31. Took 66.57 sec\n",
      "Epoch 28, Acc(train/val): 0.55/16.47, Loss(train/val) 0.00/0.17. Took 64.31 sec\n",
      "Epoch 29, Acc(train/val): 0.55/16.03, Loss(train/val) 0.00/0.17. Took 65.00 sec\n",
      "Epoch 30, Acc(train/val): 0.55/26.14, Loss(train/val) 0.00/0.43. Took 65.46 sec\n",
      "Epoch 31, Acc(train/val): 0.54/18.45, Loss(train/val) 0.00/0.22. Took 64.63 sec\n",
      "Epoch 32, Acc(train/val): 0.54/19.66, Loss(train/val) 0.00/0.25. Took 64.52 sec\n",
      "Epoch 33, Acc(train/val): 0.54/14.94, Loss(train/val) 0.00/0.14. Took 64.23 sec\n",
      "Epoch 34, Acc(train/val): 0.53/18.55, Loss(train/val) 0.00/0.22. Took 65.25 sec\n",
      "Epoch 35, Acc(train/val): 0.53/23.12, Loss(train/val) 0.00/0.33. Took 71.59 sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36, Acc(train/val): 0.53/18.16, Loss(train/val) 0.00/0.21. Took 86.40 sec\n",
      "Epoch 37, Acc(train/val): 0.53/18.13, Loss(train/val) 0.00/0.21. Took 87.55 sec\n",
      "Epoch 38, Acc(train/val): 0.53/10.65, Loss(train/val) 0.00/0.09. Took 77.75 sec\n",
      "Epoch 39, Acc(train/val): 0.52/14.55, Loss(train/val) 0.00/0.14. Took 86.35 sec\n",
      "Epoch 40, Acc(train/val): 0.52/16.18, Loss(train/val) 0.00/0.16. Took 82.59 sec\n",
      "Epoch 41, Acc(train/val): 0.52/13.06, Loss(train/val) 0.00/0.12. Took 84.82 sec\n",
      "Epoch 42, Acc(train/val): 0.52/16.64, Loss(train/val) 0.00/0.17. Took 69.26 sec\n",
      "Epoch 43, Acc(train/val): 0.51/19.59, Loss(train/val) 0.00/0.24. Took 65.14 sec\n",
      "Epoch 44, Acc(train/val): 0.51/22.08, Loss(train/val) 0.00/0.30. Took 66.00 sec\n",
      "Epoch 45, Acc(train/val): 0.51/20.46, Loss(train/val) 0.00/0.26. Took 65.67 sec\n",
      "Epoch 46, Acc(train/val): 0.51/17.21, Loss(train/val) 0.00/0.19. Took 66.00 sec\n",
      "Epoch 47, Acc(train/val): 0.51/18.25, Loss(train/val) 0.00/0.21. Took 64.70 sec\n",
      "Epoch 48, Acc(train/val): 0.51/22.45, Loss(train/val) 0.00/0.31. Took 65.55 sec\n",
      "Epoch 49, Acc(train/val): 0.51/20.19, Loss(train/val) 0.00/0.25. Took 64.54 sec\n",
      "Epoch 50, Acc(train/val): 0.51/18.85, Loss(train/val) 0.00/0.22. Took 64.61 sec\n",
      "Namespace(batch_size=16, device='cpu', dropout=0.3, epoch=50, exp_name='exp1_lr', hid_dim=100, input_dim=6, l2=0.0001, lr=0.0001, n_layers=3, optim='Adam', path='./model_checkpoint/', use_bn=True, x_frames=5, y_frames=1)\n",
      "Epoch 1, Acc(train/val): 2.25/242.50, Loss(train/val) 0.00/39.63. Took 76.04 sec\n",
      "Epoch 2, Acc(train/val): 1.49/121.70, Loss(train/val) 0.00/10.36. Took 76.04 sec\n",
      "Epoch 3, Acc(train/val): 1.11/95.83, Loss(train/val) 0.00/6.88. Took 75.19 sec\n",
      "Epoch 4, Acc(train/val): 0.94/91.39, Loss(train/val) 0.00/5.92. Took 75.56 sec\n",
      "Epoch 5, Acc(train/val): 0.87/92.70, Loss(train/val) 0.00/6.11. Took 77.26 sec\n",
      "Epoch 6, Acc(train/val): 0.81/70.19, Loss(train/val) 0.00/3.45. Took 74.57 sec\n",
      "Epoch 7, Acc(train/val): 0.78/61.18, Loss(train/val) 0.00/2.62. Took 75.88 sec\n",
      "Epoch 8, Acc(train/val): 0.75/67.82, Loss(train/val) 0.00/3.19. Took 75.45 sec\n",
      "Epoch 9, Acc(train/val): 0.73/57.77, Loss(train/val) 0.00/2.31. Took 76.13 sec\n",
      "Epoch 10, Acc(train/val): 0.72/65.18, Loss(train/val) 0.00/2.92. Took 75.41 sec\n",
      "Epoch 11, Acc(train/val): 0.70/58.40, Loss(train/val) 0.00/2.32. Took 75.52 sec\n",
      "Epoch 12, Acc(train/val): 0.68/51.71, Loss(train/val) 0.00/1.80. Took 82.37 sec\n",
      "Epoch 13, Acc(train/val): 0.67/54.24, Loss(train/val) 0.00/1.98. Took 73.56 sec\n",
      "Epoch 14, Acc(train/val): 0.65/52.10, Loss(train/val) 0.00/1.81. Took 72.32 sec\n",
      "Epoch 15, Acc(train/val): 0.63/43.12, Loss(train/val) 0.00/1.22. Took 74.56 sec\n",
      "Epoch 16, Acc(train/val): 0.62/34.71, Loss(train/val) 0.00/0.77. Took 65.89 sec\n",
      "Epoch 17, Acc(train/val): 0.61/37.11, Loss(train/val) 0.00/0.87. Took 66.80 sec\n",
      "Epoch 18, Acc(train/val): 0.60/31.66, Loss(train/val) 0.00/0.63. Took 70.11 sec\n",
      "Epoch 19, Acc(train/val): 0.59/30.48, Loss(train/val) 0.00/0.57. Took 83.52 sec\n",
      "Epoch 20, Acc(train/val): 0.58/25.27, Loss(train/val) 0.00/0.39. Took 71.98 sec\n",
      "Epoch 21, Acc(train/val): 0.57/31.51, Loss(train/val) 0.00/0.61. Took 84.68 sec\n",
      "Epoch 22, Acc(train/val): 0.57/24.76, Loss(train/val) 0.00/0.38. Took 77.43 sec\n",
      "Epoch 23, Acc(train/val): 0.56/33.42, Loss(train/val) 0.00/0.68. Took 92.11 sec\n",
      "Epoch 24, Acc(train/val): 0.56/28.66, Loss(train/val) 0.00/0.50. Took 84.81 sec\n",
      "Epoch 25, Acc(train/val): 0.56/30.12, Loss(train/val) 0.00/0.56. Took 81.24 sec\n",
      "Epoch 26, Acc(train/val): 0.55/26.49, Loss(train/val) 0.00/0.43. Took 82.58 sec\n",
      "Epoch 27, Acc(train/val): 0.55/24.75, Loss(train/val) 0.00/0.38. Took 87.16 sec\n",
      "Epoch 28, Acc(train/val): 0.55/29.67, Loss(train/val) 0.00/0.54. Took 90.80 sec\n",
      "Epoch 29, Acc(train/val): 0.54/29.07, Loss(train/val) 0.00/0.52. Took 93.53 sec\n",
      "Epoch 30, Acc(train/val): 0.54/31.10, Loss(train/val) 0.00/0.59. Took 103.81 sec\n",
      "Epoch 31, Acc(train/val): 0.54/24.46, Loss(train/val) 0.00/0.37. Took 106.18 sec\n",
      "Epoch 32, Acc(train/val): 0.54/25.93, Loss(train/val) 0.00/0.41. Took 105.47 sec\n",
      "Epoch 33, Acc(train/val): 0.54/28.39, Loss(train/val) 0.00/0.49. Took 109.45 sec\n",
      "Epoch 34, Acc(train/val): 0.53/27.59, Loss(train/val) 0.00/0.47. Took 107.15 sec\n",
      "Epoch 35, Acc(train/val): 0.53/20.97, Loss(train/val) 0.00/0.28. Took 128.59 sec\n",
      "Epoch 36, Acc(train/val): 0.53/28.40, Loss(train/val) 0.00/0.50. Took 122.74 sec\n",
      "Epoch 37, Acc(train/val): 0.53/26.64, Loss(train/val) 0.00/0.43. Took 126.39 sec\n",
      "Epoch 38, Acc(train/val): 0.53/17.02, Loss(train/val) 0.00/0.21. Took 119.03 sec\n",
      "Epoch 39, Acc(train/val): 0.52/23.68, Loss(train/val) 0.00/0.35. Took 95.00 sec\n",
      "Epoch 40, Acc(train/val): 0.52/24.02, Loss(train/val) 0.00/0.36. Took 68.21 sec\n",
      "Epoch 41, Acc(train/val): 0.52/24.48, Loss(train/val) 0.00/0.37. Took 67.91 sec\n",
      "Epoch 42, Acc(train/val): 0.52/24.01, Loss(train/val) 0.00/0.35. Took 66.78 sec\n",
      "Epoch 43, Acc(train/val): 0.52/16.82, Loss(train/val) 0.00/0.19. Took 67.45 sec\n",
      "Epoch 44, Acc(train/val): 0.52/26.70, Loss(train/val) 0.00/0.43. Took 66.24 sec\n",
      "Epoch 45, Acc(train/val): 0.52/24.44, Loss(train/val) 0.00/0.37. Took 66.00 sec\n",
      "Epoch 46, Acc(train/val): 0.52/24.38, Loss(train/val) 0.00/0.36. Took 68.03 sec\n",
      "Epoch 47, Acc(train/val): 0.51/25.33, Loss(train/val) 0.00/0.39. Took 67.48 sec\n",
      "Epoch 48, Acc(train/val): 0.51/24.65, Loss(train/val) 0.00/0.37. Took 66.09 sec\n",
      "Epoch 49, Acc(train/val): 0.51/19.62, Loss(train/val) 0.00/0.25. Took 69.48 sec\n",
      "Epoch 50, Acc(train/val): 0.51/26.58, Loss(train/val) 0.00/0.43. Took 71.29 sec\n"
     ]
    }
   ],
   "source": [
    "# ====== Experiment Variable ====== #\n",
    "name_var1 = 'hid_dim'\n",
    "name_var2 = 'n_layers'\n",
    "list_var1 = [10, 50, 100]\n",
    "list_var2 = [1,2,3]\n",
    "\n",
    "model_dict = {}\n",
    "\n",
    "for var1 in list_var1:\n",
    "    for var2 in list_var2:\n",
    "        setattr(args, name_var1, var1)\n",
    "        setattr(args, name_var2, var2)\n",
    "        print(args)\n",
    "                \n",
    "        model, setting, result = experiment(partition, deepcopy(args))\n",
    "        hash_key = hashlib.sha1(str(setting).encode()).hexdigest()[:6]\n",
    "        model_dict[hash_key] = model\n",
    "        save_exp_result(setting, result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
