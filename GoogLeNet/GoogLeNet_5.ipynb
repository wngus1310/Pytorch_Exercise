{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iIgoByVD25Be",
    "outputId": "02da7e63-bfdb-449e-f606-245209a31177"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch_optimizer\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ce/70/ca0cd259662eef5c9448d3ecf14af880bbfe76331e4eeab7b19827d6dbe6/torch_optimizer-0.0.1a17-py3-none-any.whl (69kB)\n",
      "\r",
      "\u001b[K     |████▊                           | 10kB 24.5MB/s eta 0:00:01\r",
      "\u001b[K     |█████████▌                      | 20kB 24.1MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████▏                 | 30kB 11.3MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████             | 40kB 9.9MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████▋        | 51kB 10.5MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████▍   | 61kB 11.9MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████████| 71kB 6.3MB/s \n",
      "\u001b[?25hRequirement already satisfied: torch>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from torch_optimizer) (1.7.0+cu101)\n",
      "Collecting pytorch-ranger>=0.1.1\n",
      "  Downloading https://files.pythonhosted.org/packages/0d/70/12256257d861bbc3e176130d25be1de085ce7a9e60594064888a950f2154/pytorch_ranger-0.1.1-py3-none-any.whl\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch>=1.1.0->torch_optimizer) (3.7.4.3)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch>=1.1.0->torch_optimizer) (1.19.4)\n",
      "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch>=1.1.0->torch_optimizer) (0.16.0)\n",
      "Requirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from torch>=1.1.0->torch_optimizer) (0.8)\n",
      "Installing collected packages: pytorch-ranger, torch-optimizer\n",
      "Successfully installed pytorch-ranger-0.1.1 torch-optimizer-0.0.1a17\n"
     ]
    }
   ],
   "source": [
    "!pip install torch_optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tBGYggny2_aL"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import math\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from torch.optim import Optimizer\n",
    "import torch_optimizer as optim\n",
    "\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3XUIi09H3FoD",
    "outputId": "284e7a3b-cab8-40a8-d9c4-e7c057ab79a1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "GPU: Tesla T4\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "name = torch.cuda.get_device_name(0)\n",
    "print(\"GPU: \" + name)\n",
    "\n",
    "random_seed = 0\n",
    "\n",
    "torch.manual_seed(random_seed)\n",
    "torch.cuda.manual_seed(random_seed)\n",
    "\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "np.random.seed(random_seed)\n",
    "random.seed(random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ne5GbtN_GoHF"
   },
   "outputs": [],
   "source": [
    "class GoogLeNet(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(GoogLeNet, self).__init__()        \n",
    "\n",
    "        self.conv1 = BasicConv2d(3, 64, kernel_size=7, padding=3)\n",
    "        self.conv2 = BasicConv2d(64, 64, kernel_size=1)\n",
    "        self.conv3 = BasicConv2d(64, 192, kernel_size=5)\n",
    "\n",
    "        self.inception3a = Inception(192, 64, 96, 128, 16, 32, 32, 16, 16)  # 64 + 128 + 32 + 32 + 16 = 256 + 16 = 272\n",
    "        self.inception3b = Inception(272, 128, 128, 192, 32, 96, 64, 16, 16)\n",
    "        self.maxpool3 = nn.MaxPool2d(3, stride=2, ceil_mode=True)\n",
    "\n",
    "        self.inception4a = Inception(496, 192, 96, 208, 16, 48, 64, 16, 16)\n",
    "        self.inception4b = Inception(528, 160, 112, 224, 24, 64, 64, 16, 16)\n",
    "        self.inception4c = Inception(528, 128, 128, 256, 24, 64, 64, 16, 16 )\n",
    "        self.inception4d = Inception(528, 112, 144, 288, 32, 64, 64, 16, 16)\n",
    "        self.inception4e = Inception(544, 256, 160, 320, 32, 128, 128, 16, 16)\n",
    "        self.maxpool4 = nn.MaxPool2d(2, stride=2, ceil_mode=True)\n",
    "\n",
    "        self.inception5a = Inception(848, 256, 160, 320, 32, 128, 128, 16, 16)\n",
    "        self.inception5b = Inception(848, 384, 192, 384, 48, 128, 128, 16, 16)\n",
    "\n",
    "\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.dropout = nn.Dropout()\n",
    "        self.fc = nn.Linear(1040, 10)\n",
    "        \n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):\n",
    "                torch.nn.init.xavier_uniform_(m.weight)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # N x 3 x 32 x 32\n",
    "        x = self.conv1(x)\n",
    "        # N x 64 x 32 x 32\n",
    "        x = self.conv2(x)\n",
    "        # N x 64 x 32 x 32\n",
    "        x = self.conv3(x)\n",
    "        # N x 192 x 28 x 28\n",
    "\n",
    "        # N x 192 x 28 x 28\n",
    "        x = self.inception3a(x)\n",
    "        # N x 272 x 28 x 28\n",
    "        x = self.inception3b(x)\n",
    "        # N x 496 x 28 x 28\n",
    "        x = self.maxpool3(x)\n",
    "        # N x 496 x 14 x 14\n",
    "        x = self.inception4a(x)\n",
    "        # N x 528 x 14 x 14\n",
    "        x = self.inception4b(x)\n",
    "        # N x 528 x 14 x 14\n",
    "        x = self.inception4c(x)\n",
    "        # N x 528 x 14 x 14\n",
    "        x = self.inception4d(x)\n",
    "        # N x 544 x 14 x 14\n",
    "        x = self.inception4e(x)\n",
    "        # N x 848 x 14 x 14\n",
    "        x = self.maxpool4(x)\n",
    "        # N x 848 x 7 x 7\n",
    "        x = self.inception5a(x)\n",
    "        # N x 848 x 7 x 7\n",
    "        x = self.inception5b(x)\n",
    "        # N x 1040 x 7 x 7\n",
    "        x = self.avgpool(x)\n",
    "        # N x 1040 x 1 x 1\n",
    "        x = torch.flatten(x, 1)\n",
    "        # N x 1040\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc(x)\n",
    "        # N x 10 (num_classes)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zx_azshkGvLr"
   },
   "outputs": [],
   "source": [
    "class Inception(nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels, ch1x1, ch3x3red, ch3x3, ch5x5red, ch5x5, pool_proj, ch7x7red, ch7x7):\n",
    "        super(Inception, self).__init__()\n",
    "        \n",
    "        self.branch1 = BasicConv2d(in_channels, ch1x1, kernel_size=1)\n",
    "\n",
    "        self.branch2 = nn.Sequential(\n",
    "            BasicConv2d(in_channels, ch3x3red, kernel_size=1),\n",
    "            BasicConv2d(ch3x3red, ch3x3, kernel_size=3, padding=1)\n",
    "        )\n",
    "\n",
    "        self.branch3 = nn.Sequential(\n",
    "            BasicConv2d(in_channels, ch5x5red, kernel_size=1),\n",
    "            BasicConv2d(ch5x5red, ch5x5, kernel_size=5, padding=2)\n",
    "        )\n",
    "\n",
    "        self.branch4 = nn.Sequential(\n",
    "            nn.MaxPool2d(kernel_size=3, stride=1, padding=1),\n",
    "            BasicConv2d(in_channels, pool_proj, kernel_size=1)\n",
    "        )\n",
    "\n",
    "        self.branch5 = nn.Sequential(\n",
    "            BasicConv2d(in_channels, ch7x7red, kernel_size=1),\n",
    "            BasicConv2d(ch7x7red, ch7x7, kernel_size=7, padding=3)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        branch1 = self.branch1(x)\n",
    "        branch2 = self.branch2(x)\n",
    "        branch3 = self.branch3(x)\n",
    "        branch4 = self.branch4(x)\n",
    "        branch5 = self.branch5(x)\n",
    "\n",
    "        return torch.cat([branch1, branch2, branch3, branch4, branch5], 1)\n",
    "\n",
    "\n",
    "class BasicConv2d(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, **kwargs):\n",
    "        super(BasicConv2d, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "                            nn.Conv2d(in_channels, out_channels, **kwargs),\n",
    "                            nn.BatchNorm2d(out_channels),   #Batch norm here\n",
    "                            nn.ReLU()\n",
    "                            )\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x763q4Wa3GgP"
   },
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    def __init__(self, patience=10, path='checkpoint.pt'):\n",
    "        \n",
    "        self.patience = patience\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.val_loss_min = np.Inf\n",
    "        self.early_stop = False\n",
    "\n",
    "        self.path = path\n",
    "\n",
    "\n",
    "\n",
    "    def __call__(self, val_loss, model):\n",
    "\n",
    "        score = val_loss\n",
    "\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            \n",
    "            print('Validation loss decreased ({:.4f} --> {:.4f}).  Saving model ...'.format(self.val_loss_min, val_loss))\n",
    "            torch.save(model.state_dict(), self.path)\n",
    "            self.val_loss_min = val_loss\n",
    "\n",
    "        elif score > self.best_score:\n",
    "            self.counter += 1\n",
    "            print(\"EarlyStopping counter: {} out of {}\".format(self.counter, self.patience))\n",
    "\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.counter = 0\n",
    "\n",
    "            print('Validation loss decreased --- Saving model ...')\n",
    "            torch.save(model.state_dict(), self.path)\n",
    "            self.val_loss_min = val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vO9qKi__3H1T"
   },
   "outputs": [],
   "source": [
    "def get_data_len_index(pad=4, randomcrop=32):\n",
    "    data_shuffle = []\n",
    "\n",
    "    transform = transforms.Compose([\n",
    "                                    transforms.Pad(pad),\n",
    "                                    transforms.RandomHorizontalFlip(),\n",
    "                                    transforms.RandomCrop(randomcrop),\n",
    "                                    transforms.ToTensor()\n",
    "    ])\n",
    "\n",
    "    train_dataset = datasets.CIFAR10(root='./cifar_10data/',\n",
    "                                     train=True,\n",
    "                                     transform=transform,\n",
    "                                     download=True) \n",
    "    \n",
    "    len_train = len(train_dataset)\n",
    "    index_train = list(range(len_train))\n",
    "    \n",
    "\n",
    "    data_shuffle.append(len_train)\n",
    "    data_shuffle.append(index_train)\n",
    "    data_shuffle.append(train_dataset)\n",
    "\n",
    "    return data_shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s_YxUi3m3LN6"
   },
   "outputs": [],
   "source": [
    "def test_model(model, batch_size=128):\n",
    "    model.eval()\n",
    "    test_loss, correct, total = 0, 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader :\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            output = model(images)\n",
    "            test_loss += loss_function(output, labels).item()\n",
    "\n",
    "            pred = output.max(1, keepdim=True)[1]\n",
    "            correct += pred.eq(labels.view_as(pred)).sum().item()\n",
    "\n",
    "            total += labels.size(0)\n",
    "\n",
    "    print('[Test set] Average loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)\\n'.format(\n",
    "            test_loss /total, correct, total,\n",
    "            100. * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ovm9KYar3MWA"
   },
   "outputs": [],
   "source": [
    "def train_model(model, batch_size, n_epochs, patience, loader):\n",
    "    train_loader = loader[0]\n",
    "    valid_loader = loader[1]\n",
    "    \n",
    "    train_losses = []\n",
    "    valid_losses = []\n",
    "\n",
    "    avg_train_losses = []\n",
    "    avg_valid_losses = []\n",
    "\n",
    "    early_stopping = EarlyStopping(patience=patience)\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    start = time.time()\n",
    "\n",
    "    for epoch in range(1,n_epochs+1):\n",
    "        print(\"{}th Epoch starting.\".format(epoch))\n",
    "\n",
    "        for i, (images, labels) in enumerate(train_loader):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            output = model(images)\n",
    "\n",
    "            train_loss = loss_function(output, labels)\n",
    "\n",
    "            train_loss.backward()\n",
    "\n",
    "            optimizer.step()\n",
    "\n",
    "            loss = train_loss.item()\n",
    "\n",
    "\n",
    "            train_losses.append(loss)\n",
    "\n",
    "\n",
    "        model.eval()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for images, labels in valid_loader:\n",
    "                images , labels = images.to(device), labels.to(device)\n",
    "\n",
    "                output = model(images)\n",
    "\n",
    "                valid_loss = loss_function(output, labels)\n",
    "\n",
    "                loss = valid_loss.item()\n",
    "\n",
    "                valid_losses.append(loss)\n",
    "        \n",
    "        loss_train = np.average(train_losses)\n",
    "        loss_valid = np.average(valid_losses)\n",
    "\n",
    "        avg_train_losses.append(loss_train)\n",
    "        avg_valid_losses.append(loss_valid)\n",
    "\n",
    "        print(\"Epoch [{}] Train Loss: {:.4f} & Validation Loss: {:.4f}\".format(epoch, loss_train, loss_valid))\n",
    "\n",
    "        train_losses = []\n",
    "        valid_losses = []\n",
    "\n",
    "        early_stopping(loss_valid, model)\n",
    "\n",
    "        if early_stopping.early_stop:\n",
    "            print(\"Early Stopping!!\")\n",
    "            end = time.time()\n",
    "            #print(end-start)\n",
    "            break\n",
    "\n",
    "    model.load_state_dict(torch.load('checkpoint.pt'))\n",
    "\n",
    "    return model, avg_train_losses, avg_valid_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fM2jw1HL3OWx"
   },
   "outputs": [],
   "source": [
    "def train_KFold(model, batch_size, n_epochs, patience, data_info, fold):\n",
    "        \n",
    "    train_losses = []\n",
    "    valid_losses = []\n",
    "\n",
    "    loader = []\n",
    "\n",
    "    path='checkpoint.pt'\n",
    "\n",
    "    len_train = data_info[0]\n",
    "    index_train = data_info[1]\n",
    "    train_dataset = data_info[2]\n",
    "\n",
    "    np.random.shuffle(index_train)\n",
    "\n",
    "    split_size = len_train // fold\n",
    "\n",
    "    start = time.time()\n",
    "    for i in range(fold):\n",
    "\n",
    "        valid_ind = index_train[split_size * i: split_size * (i+1)]\n",
    "                \n",
    "        if i == 0:\n",
    "            train_ind = index_train[split_size * (i+1):]\n",
    "                    \n",
    "        elif i == 4:\n",
    "            train_ind = index_train[:split_size*i]\n",
    "\n",
    "        else:\n",
    "            train_ind = index_train[:split_size * i] + index_train[split_size * (i+1):]\n",
    "\n",
    "        train_sampler = SubsetRandomSampler(train_ind)\n",
    "        valid_sampler = SubsetRandomSampler(valid_ind)    \n",
    "\n",
    "        train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                                        batch_size=batch_size,\n",
    "                                                        sampler = train_sampler,\n",
    "                                                        num_workers=0)\n",
    "                \n",
    "        valid_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                                        batch_size=batch_size,\n",
    "                                                        sampler = valid_sampler,\n",
    "                                                        num_workers=0)\n",
    "        \n",
    "        loader.append(train_loader)\n",
    "        loader.append(valid_loader)\n",
    "                \n",
    "\n",
    "        print(\"{} Fold is Training\".format(i+1))\n",
    "\n",
    "        model, avg_train_losses, avg_valid_losses = train_model(model, batch_size, n_epochs, patience, loader)\n",
    "        \n",
    "        train_losses.append(avg_train_losses)\n",
    "        valid_losses.append(avg_valid_losses)\n",
    "        \n",
    "    end = time.time()\n",
    "\n",
    "    print(end-start)\n",
    "\n",
    "    return model, train_losses, valid_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85,
     "referenced_widgets": [
      "63a5cc05f28a449cbe0aeceedcf0104d",
      "9ab4ec09717445b4b71834b58d88d4a3",
      "7f24449862fa4a1fa01bfee2498ce820",
      "f7e38560ed6e47fa8422fc65fa354aba",
      "35719a48e8dc4b7394b0229494a83751",
      "7133f9d85a344cda9057dbe15dab5da9",
      "812cfd0371514c8fb6e2295d7fd07e8d",
      "9d3ca229af3b4cbe98096f3ef77c556a"
     ]
    },
    "id": "pnhIXiLM3Qw1",
    "outputId": "e6283751-f702-4fb7-cb84-1eb80ef2ed81"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./cifar_10data/cifar-10-python.tar.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63a5cc05f28a449cbe0aeceedcf0104d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./cifar_10data/cifar-10-python.tar.gz to ./cifar_10data/\n"
     ]
    }
   ],
   "source": [
    "data_info = get_data_len_index()\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cyUPecMz3SKI"
   },
   "outputs": [],
   "source": [
    "model = GoogLeNet().to(device)\n",
    "loss_function = torch.nn.CrossEntropyLoss()\n",
    "optimizer = optim.RAdam(model.parameters(), weight_decay=5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KmQLDx1n3TBL",
    "outputId": "7f10da2a-dd2d-4e35-ff3d-48775c84c429"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Fold is Training\n",
      "1th Epoch starting.\n",
      "Epoch [1] Train Loss: 1.6563 & Validation Loss: 1.5809\n",
      "Validation loss decreased (inf --> 1.5809).  Saving model ...\n",
      "2th Epoch starting.\n",
      "Epoch [2] Train Loss: 1.9697 & Validation Loss: 1.6983\n",
      "EarlyStopping counter: 1 out of 20\n",
      "3th Epoch starting.\n",
      "Epoch [3] Train Loss: 1.6384 & Validation Loss: 1.5550\n",
      "Validation loss decreased --- Saving model ...\n",
      "4th Epoch starting.\n",
      "Epoch [4] Train Loss: 1.4807 & Validation Loss: 1.3935\n",
      "Validation loss decreased --- Saving model ...\n",
      "5th Epoch starting.\n",
      "Epoch [5] Train Loss: 1.3384 & Validation Loss: 1.3505\n",
      "Validation loss decreased --- Saving model ...\n",
      "6th Epoch starting.\n",
      "Epoch [6] Train Loss: 1.2050 & Validation Loss: 1.1456\n",
      "Validation loss decreased --- Saving model ...\n",
      "7th Epoch starting.\n",
      "Epoch [7] Train Loss: 1.0789 & Validation Loss: 1.0484\n",
      "Validation loss decreased --- Saving model ...\n",
      "8th Epoch starting.\n",
      "Epoch [8] Train Loss: 0.9500 & Validation Loss: 0.9157\n",
      "Validation loss decreased --- Saving model ...\n",
      "9th Epoch starting.\n",
      "Epoch [9] Train Loss: 0.8666 & Validation Loss: 0.8584\n",
      "Validation loss decreased --- Saving model ...\n",
      "10th Epoch starting.\n",
      "Epoch [10] Train Loss: 0.7866 & Validation Loss: 0.8153\n",
      "Validation loss decreased --- Saving model ...\n",
      "11th Epoch starting.\n",
      "Epoch [11] Train Loss: 0.7327 & Validation Loss: 0.7553\n",
      "Validation loss decreased --- Saving model ...\n",
      "12th Epoch starting.\n",
      "Epoch [12] Train Loss: 0.6772 & Validation Loss: 0.7175\n",
      "Validation loss decreased --- Saving model ...\n",
      "13th Epoch starting.\n",
      "Epoch [13] Train Loss: 0.6307 & Validation Loss: 0.7057\n",
      "Validation loss decreased --- Saving model ...\n",
      "14th Epoch starting.\n",
      "Epoch [14] Train Loss: 0.5957 & Validation Loss: 0.6629\n",
      "Validation loss decreased --- Saving model ...\n",
      "15th Epoch starting.\n",
      "Epoch [15] Train Loss: 0.5759 & Validation Loss: 0.6883\n",
      "EarlyStopping counter: 1 out of 20\n",
      "16th Epoch starting.\n",
      "Epoch [16] Train Loss: 0.5351 & Validation Loss: 0.6061\n",
      "Validation loss decreased --- Saving model ...\n",
      "17th Epoch starting.\n",
      "Epoch [17] Train Loss: 0.5176 & Validation Loss: 0.5760\n",
      "Validation loss decreased --- Saving model ...\n",
      "18th Epoch starting.\n",
      "Epoch [18] Train Loss: 0.4935 & Validation Loss: 0.6258\n",
      "EarlyStopping counter: 1 out of 20\n",
      "19th Epoch starting.\n",
      "Epoch [19] Train Loss: 0.4712 & Validation Loss: 0.5605\n",
      "Validation loss decreased --- Saving model ...\n",
      "20th Epoch starting.\n",
      "Epoch [20] Train Loss: 0.4498 & Validation Loss: 0.5371\n",
      "Validation loss decreased --- Saving model ...\n",
      "21th Epoch starting.\n",
      "Epoch [21] Train Loss: 0.4293 & Validation Loss: 0.5725\n",
      "EarlyStopping counter: 1 out of 20\n",
      "22th Epoch starting.\n",
      "Epoch [22] Train Loss: 0.4178 & Validation Loss: 0.6011\n",
      "EarlyStopping counter: 2 out of 20\n",
      "23th Epoch starting.\n",
      "Epoch [23] Train Loss: 0.4006 & Validation Loss: 0.5472\n",
      "EarlyStopping counter: 3 out of 20\n",
      "24th Epoch starting.\n",
      "Epoch [24] Train Loss: 0.3844 & Validation Loss: 0.5459\n",
      "EarlyStopping counter: 4 out of 20\n",
      "25th Epoch starting.\n",
      "Epoch [25] Train Loss: 0.3812 & Validation Loss: 0.5639\n",
      "EarlyStopping counter: 5 out of 20\n",
      "26th Epoch starting.\n",
      "Epoch [26] Train Loss: 0.3582 & Validation Loss: 0.6038\n",
      "EarlyStopping counter: 6 out of 20\n",
      "27th Epoch starting.\n",
      "Epoch [27] Train Loss: 0.3507 & Validation Loss: 0.5732\n",
      "EarlyStopping counter: 7 out of 20\n",
      "28th Epoch starting.\n",
      "Epoch [28] Train Loss: 0.3348 & Validation Loss: 0.5037\n",
      "Validation loss decreased --- Saving model ...\n",
      "29th Epoch starting.\n",
      "Epoch [29] Train Loss: 0.3206 & Validation Loss: 0.5294\n",
      "EarlyStopping counter: 1 out of 20\n",
      "30th Epoch starting.\n",
      "Epoch [30] Train Loss: 0.3048 & Validation Loss: 0.5350\n",
      "EarlyStopping counter: 2 out of 20\n",
      "31th Epoch starting.\n",
      "Epoch [31] Train Loss: 0.2989 & Validation Loss: 0.5027\n",
      "Validation loss decreased --- Saving model ...\n",
      "32th Epoch starting.\n",
      "Epoch [32] Train Loss: 0.2899 & Validation Loss: 0.5266\n",
      "EarlyStopping counter: 1 out of 20\n",
      "33th Epoch starting.\n",
      "Epoch [33] Train Loss: 0.2835 & Validation Loss: 0.5111\n",
      "EarlyStopping counter: 2 out of 20\n",
      "34th Epoch starting.\n",
      "Epoch [34] Train Loss: 0.2681 & Validation Loss: 0.5635\n",
      "EarlyStopping counter: 3 out of 20\n",
      "35th Epoch starting.\n",
      "Epoch [35] Train Loss: 0.2626 & Validation Loss: 0.5131\n",
      "EarlyStopping counter: 4 out of 20\n",
      "36th Epoch starting.\n",
      "Epoch [36] Train Loss: 0.2541 & Validation Loss: 0.5046\n",
      "EarlyStopping counter: 5 out of 20\n",
      "37th Epoch starting.\n",
      "Epoch [37] Train Loss: 0.2490 & Validation Loss: 0.5312\n",
      "EarlyStopping counter: 6 out of 20\n",
      "38th Epoch starting.\n",
      "Epoch [38] Train Loss: 0.2420 & Validation Loss: 0.5790\n",
      "EarlyStopping counter: 7 out of 20\n",
      "39th Epoch starting.\n",
      "Epoch [39] Train Loss: 0.2382 & Validation Loss: 0.5501\n",
      "EarlyStopping counter: 8 out of 20\n",
      "40th Epoch starting.\n",
      "Epoch [40] Train Loss: 0.2341 & Validation Loss: 0.5475\n",
      "EarlyStopping counter: 9 out of 20\n",
      "41th Epoch starting.\n",
      "Epoch [41] Train Loss: 0.2299 & Validation Loss: 0.5322\n",
      "EarlyStopping counter: 10 out of 20\n",
      "42th Epoch starting.\n",
      "Epoch [42] Train Loss: 0.2182 & Validation Loss: 0.5154\n",
      "EarlyStopping counter: 11 out of 20\n",
      "43th Epoch starting.\n",
      "Epoch [43] Train Loss: 0.2082 & Validation Loss: 0.5361\n",
      "EarlyStopping counter: 12 out of 20\n",
      "44th Epoch starting.\n",
      "Epoch [44] Train Loss: 0.2143 & Validation Loss: 0.5445\n",
      "EarlyStopping counter: 13 out of 20\n",
      "45th Epoch starting.\n",
      "Epoch [45] Train Loss: 0.1989 & Validation Loss: 0.5409\n",
      "EarlyStopping counter: 14 out of 20\n",
      "46th Epoch starting.\n",
      "Epoch [46] Train Loss: 0.1946 & Validation Loss: 0.5663\n",
      "EarlyStopping counter: 15 out of 20\n",
      "47th Epoch starting.\n",
      "Epoch [47] Train Loss: 0.1960 & Validation Loss: 0.5120\n",
      "EarlyStopping counter: 16 out of 20\n",
      "48th Epoch starting.\n",
      "Epoch [48] Train Loss: 0.1832 & Validation Loss: 0.5321\n",
      "EarlyStopping counter: 17 out of 20\n",
      "49th Epoch starting.\n",
      "Epoch [49] Train Loss: 0.1751 & Validation Loss: 0.5886\n",
      "EarlyStopping counter: 18 out of 20\n",
      "50th Epoch starting.\n",
      "Epoch [50] Train Loss: 0.1780 & Validation Loss: 0.5473\n",
      "EarlyStopping counter: 19 out of 20\n",
      "51th Epoch starting.\n",
      "Epoch [51] Train Loss: 0.1753 & Validation Loss: 0.5323\n",
      "EarlyStopping counter: 20 out of 20\n",
      "Early Stopping!!\n",
      "2 Fold is Training\n",
      "1th Epoch starting.\n",
      "Epoch [1] Train Loss: 1.1992 & Validation Loss: 0.6841\n",
      "Validation loss decreased (inf --> 0.6841).  Saving model ...\n",
      "2th Epoch starting.\n",
      "Epoch [2] Train Loss: 0.6509 & Validation Loss: 0.5777\n",
      "Validation loss decreased --- Saving model ...\n",
      "3th Epoch starting.\n",
      "Epoch [3] Train Loss: 0.4673 & Validation Loss: 0.4845\n",
      "Validation loss decreased --- Saving model ...\n",
      "4th Epoch starting.\n",
      "Epoch [4] Train Loss: 0.4084 & Validation Loss: 0.4559\n",
      "Validation loss decreased --- Saving model ...\n",
      "5th Epoch starting.\n",
      "Epoch [5] Train Loss: 0.3585 & Validation Loss: 0.4527\n",
      "Validation loss decreased --- Saving model ...\n",
      "6th Epoch starting.\n",
      "Epoch [6] Train Loss: 0.3145 & Validation Loss: 0.4459\n",
      "Validation loss decreased --- Saving model ...\n",
      "7th Epoch starting.\n",
      "Epoch [7] Train Loss: 0.2827 & Validation Loss: 0.4257\n",
      "Validation loss decreased --- Saving model ...\n",
      "8th Epoch starting.\n",
      "Epoch [8] Train Loss: 0.2650 & Validation Loss: 0.4370\n",
      "EarlyStopping counter: 1 out of 20\n",
      "9th Epoch starting.\n",
      "Epoch [9] Train Loss: 0.2371 & Validation Loss: 0.4357\n",
      "EarlyStopping counter: 2 out of 20\n",
      "10th Epoch starting.\n",
      "Epoch [10] Train Loss: 0.2227 & Validation Loss: 0.4242\n",
      "Validation loss decreased --- Saving model ...\n",
      "11th Epoch starting.\n",
      "Epoch [11] Train Loss: 0.2013 & Validation Loss: 0.4224\n",
      "Validation loss decreased --- Saving model ...\n",
      "12th Epoch starting.\n",
      "Epoch [12] Train Loss: 0.1908 & Validation Loss: 0.4593\n",
      "EarlyStopping counter: 1 out of 20\n",
      "13th Epoch starting.\n",
      "Epoch [13] Train Loss: 0.1707 & Validation Loss: 0.4295\n",
      "EarlyStopping counter: 2 out of 20\n",
      "14th Epoch starting.\n",
      "Epoch [14] Train Loss: 0.1679 & Validation Loss: 0.5072\n",
      "EarlyStopping counter: 3 out of 20\n",
      "15th Epoch starting.\n",
      "Epoch [15] Train Loss: 0.1480 & Validation Loss: 0.4569\n",
      "EarlyStopping counter: 4 out of 20\n",
      "16th Epoch starting.\n",
      "Epoch [16] Train Loss: 0.1411 & Validation Loss: 0.4859\n",
      "EarlyStopping counter: 5 out of 20\n",
      "17th Epoch starting.\n",
      "Epoch [17] Train Loss: 0.1318 & Validation Loss: 0.4277\n",
      "EarlyStopping counter: 6 out of 20\n",
      "18th Epoch starting.\n",
      "Epoch [18] Train Loss: 0.1279 & Validation Loss: 0.4656\n",
      "EarlyStopping counter: 7 out of 20\n",
      "19th Epoch starting.\n",
      "Epoch [19] Train Loss: 0.1174 & Validation Loss: 0.4580\n",
      "EarlyStopping counter: 8 out of 20\n",
      "20th Epoch starting.\n",
      "Epoch [20] Train Loss: 0.1155 & Validation Loss: 0.4743\n",
      "EarlyStopping counter: 9 out of 20\n",
      "21th Epoch starting.\n",
      "Epoch [21] Train Loss: 0.1116 & Validation Loss: 0.4829\n",
      "EarlyStopping counter: 10 out of 20\n",
      "22th Epoch starting.\n",
      "Epoch [22] Train Loss: 0.1033 & Validation Loss: 0.4952\n",
      "EarlyStopping counter: 11 out of 20\n",
      "23th Epoch starting.\n",
      "Epoch [23] Train Loss: 0.1003 & Validation Loss: 0.5273\n",
      "EarlyStopping counter: 12 out of 20\n",
      "24th Epoch starting.\n",
      "Epoch [24] Train Loss: 0.0944 & Validation Loss: 0.4819\n",
      "EarlyStopping counter: 13 out of 20\n",
      "25th Epoch starting.\n",
      "Epoch [25] Train Loss: 0.0886 & Validation Loss: 0.4993\n",
      "EarlyStopping counter: 14 out of 20\n",
      "26th Epoch starting.\n",
      "Epoch [26] Train Loss: 0.0909 & Validation Loss: 0.5052\n",
      "EarlyStopping counter: 15 out of 20\n",
      "27th Epoch starting.\n",
      "Epoch [27] Train Loss: 0.0906 & Validation Loss: 0.4687\n",
      "EarlyStopping counter: 16 out of 20\n",
      "28th Epoch starting.\n",
      "Epoch [28] Train Loss: 0.0777 & Validation Loss: 0.5237\n",
      "EarlyStopping counter: 17 out of 20\n",
      "29th Epoch starting.\n",
      "Epoch [29] Train Loss: 0.0821 & Validation Loss: 0.5807\n",
      "EarlyStopping counter: 18 out of 20\n",
      "30th Epoch starting.\n",
      "Epoch [30] Train Loss: 0.0765 & Validation Loss: 0.5032\n",
      "EarlyStopping counter: 19 out of 20\n",
      "31th Epoch starting.\n",
      "Epoch [31] Train Loss: 0.0780 & Validation Loss: 0.5166\n",
      "EarlyStopping counter: 20 out of 20\n",
      "Early Stopping!!\n",
      "3 Fold is Training\n",
      "1th Epoch starting.\n",
      "Epoch [1] Train Loss: 0.5098 & Validation Loss: 0.4205\n",
      "Validation loss decreased (inf --> 0.4205).  Saving model ...\n",
      "2th Epoch starting.\n",
      "Epoch [2] Train Loss: 0.3039 & Validation Loss: 0.3893\n",
      "Validation loss decreased --- Saving model ...\n",
      "3th Epoch starting.\n",
      "Epoch [3] Train Loss: 0.2277 & Validation Loss: 0.3858\n",
      "Validation loss decreased --- Saving model ...\n",
      "4th Epoch starting.\n",
      "Epoch [4] Train Loss: 0.2008 & Validation Loss: 0.4013\n",
      "EarlyStopping counter: 1 out of 20\n",
      "5th Epoch starting.\n",
      "Epoch [5] Train Loss: 0.1818 & Validation Loss: 0.3862\n",
      "EarlyStopping counter: 2 out of 20\n",
      "6th Epoch starting.\n",
      "Epoch [6] Train Loss: 0.1677 & Validation Loss: 0.3849\n",
      "Validation loss decreased --- Saving model ...\n",
      "7th Epoch starting.\n",
      "Epoch [7] Train Loss: 0.1580 & Validation Loss: 0.4215\n",
      "EarlyStopping counter: 1 out of 20\n",
      "8th Epoch starting.\n",
      "Epoch [8] Train Loss: 0.1452 & Validation Loss: 0.4634\n",
      "EarlyStopping counter: 2 out of 20\n",
      "9th Epoch starting.\n",
      "Epoch [9] Train Loss: 0.1364 & Validation Loss: 0.4393\n",
      "EarlyStopping counter: 3 out of 20\n",
      "10th Epoch starting.\n",
      "Epoch [10] Train Loss: 0.1235 & Validation Loss: 0.4677\n",
      "EarlyStopping counter: 4 out of 20\n",
      "11th Epoch starting.\n",
      "Epoch [11] Train Loss: 0.1149 & Validation Loss: 0.4427\n",
      "EarlyStopping counter: 5 out of 20\n",
      "12th Epoch starting.\n",
      "Epoch [12] Train Loss: 0.1116 & Validation Loss: 0.4270\n",
      "EarlyStopping counter: 6 out of 20\n",
      "13th Epoch starting.\n",
      "Epoch [13] Train Loss: 0.1037 & Validation Loss: 0.4585\n",
      "EarlyStopping counter: 7 out of 20\n",
      "14th Epoch starting.\n",
      "Epoch [14] Train Loss: 0.0971 & Validation Loss: 0.4311\n",
      "EarlyStopping counter: 8 out of 20\n",
      "15th Epoch starting.\n",
      "Epoch [15] Train Loss: 0.0896 & Validation Loss: 0.3964\n",
      "EarlyStopping counter: 9 out of 20\n",
      "16th Epoch starting.\n",
      "Epoch [16] Train Loss: 0.0928 & Validation Loss: 0.4512\n",
      "EarlyStopping counter: 10 out of 20\n",
      "17th Epoch starting.\n",
      "Epoch [17] Train Loss: 0.0848 & Validation Loss: 0.4886\n",
      "EarlyStopping counter: 11 out of 20\n",
      "18th Epoch starting.\n",
      "Epoch [18] Train Loss: 0.0797 & Validation Loss: 0.5355\n",
      "EarlyStopping counter: 12 out of 20\n",
      "19th Epoch starting.\n",
      "Epoch [19] Train Loss: 0.0804 & Validation Loss: 0.4722\n",
      "EarlyStopping counter: 13 out of 20\n",
      "20th Epoch starting.\n",
      "Epoch [20] Train Loss: 0.0776 & Validation Loss: 0.5242\n",
      "EarlyStopping counter: 14 out of 20\n",
      "21th Epoch starting.\n",
      "Epoch [21] Train Loss: 0.0744 & Validation Loss: 0.4815\n",
      "EarlyStopping counter: 15 out of 20\n",
      "22th Epoch starting.\n",
      "Epoch [22] Train Loss: 0.0675 & Validation Loss: 0.5036\n",
      "EarlyStopping counter: 16 out of 20\n",
      "23th Epoch starting.\n",
      "Epoch [23] Train Loss: 0.0702 & Validation Loss: 0.4904\n",
      "EarlyStopping counter: 17 out of 20\n",
      "24th Epoch starting.\n",
      "Epoch [24] Train Loss: 0.0648 & Validation Loss: 0.4713\n",
      "EarlyStopping counter: 18 out of 20\n",
      "25th Epoch starting.\n",
      "Epoch [25] Train Loss: 0.0646 & Validation Loss: 0.5063\n",
      "EarlyStopping counter: 19 out of 20\n",
      "26th Epoch starting.\n",
      "Epoch [26] Train Loss: 0.0676 & Validation Loss: 0.4952\n",
      "EarlyStopping counter: 20 out of 20\n",
      "Early Stopping!!\n",
      "4 Fold is Training\n",
      "1th Epoch starting.\n",
      "Epoch [1] Train Loss: 0.3097 & Validation Loss: 0.3639\n",
      "Validation loss decreased (inf --> 0.3639).  Saving model ...\n",
      "2th Epoch starting.\n",
      "Epoch [2] Train Loss: 0.2106 & Validation Loss: 0.4016\n",
      "EarlyStopping counter: 1 out of 20\n",
      "3th Epoch starting.\n",
      "Epoch [3] Train Loss: 0.1608 & Validation Loss: 0.3984\n",
      "EarlyStopping counter: 2 out of 20\n",
      "4th Epoch starting.\n",
      "Epoch [4] Train Loss: 0.1506 & Validation Loss: 0.4013\n",
      "EarlyStopping counter: 3 out of 20\n",
      "5th Epoch starting.\n",
      "Epoch [5] Train Loss: 0.1344 & Validation Loss: 0.4057\n",
      "EarlyStopping counter: 4 out of 20\n",
      "6th Epoch starting.\n",
      "Epoch [6] Train Loss: 0.1290 & Validation Loss: 0.4051\n",
      "EarlyStopping counter: 5 out of 20\n",
      "7th Epoch starting.\n",
      "Epoch [7] Train Loss: 0.1143 & Validation Loss: 0.4131\n",
      "EarlyStopping counter: 6 out of 20\n",
      "8th Epoch starting.\n",
      "Epoch [8] Train Loss: 0.1128 & Validation Loss: 0.3901\n",
      "EarlyStopping counter: 7 out of 20\n",
      "9th Epoch starting.\n",
      "Epoch [9] Train Loss: 0.1021 & Validation Loss: 0.4436\n",
      "EarlyStopping counter: 8 out of 20\n",
      "10th Epoch starting.\n",
      "Epoch [10] Train Loss: 0.0991 & Validation Loss: 0.4120\n",
      "EarlyStopping counter: 9 out of 20\n",
      "11th Epoch starting.\n",
      "Epoch [11] Train Loss: 0.0866 & Validation Loss: 0.4247\n",
      "EarlyStopping counter: 10 out of 20\n",
      "12th Epoch starting.\n",
      "Epoch [12] Train Loss: 0.0910 & Validation Loss: 0.4559\n",
      "EarlyStopping counter: 11 out of 20\n",
      "13th Epoch starting.\n",
      "Epoch [13] Train Loss: 0.0849 & Validation Loss: 0.4360\n",
      "EarlyStopping counter: 12 out of 20\n",
      "14th Epoch starting.\n",
      "Epoch [14] Train Loss: 0.0811 & Validation Loss: 0.4426\n",
      "EarlyStopping counter: 13 out of 20\n",
      "15th Epoch starting.\n",
      "Epoch [15] Train Loss: 0.0745 & Validation Loss: 0.5471\n",
      "EarlyStopping counter: 14 out of 20\n",
      "16th Epoch starting.\n",
      "Epoch [16] Train Loss: 0.0748 & Validation Loss: 0.4508\n",
      "EarlyStopping counter: 15 out of 20\n",
      "17th Epoch starting.\n",
      "Epoch [17] Train Loss: 0.0702 & Validation Loss: 0.4515\n",
      "EarlyStopping counter: 16 out of 20\n",
      "18th Epoch starting.\n",
      "Epoch [18] Train Loss: 0.0679 & Validation Loss: 0.4685\n",
      "EarlyStopping counter: 17 out of 20\n",
      "19th Epoch starting.\n",
      "Epoch [19] Train Loss: 0.0654 & Validation Loss: 0.4452\n",
      "EarlyStopping counter: 18 out of 20\n",
      "20th Epoch starting.\n",
      "Epoch [20] Train Loss: 0.0660 & Validation Loss: 0.4760\n",
      "EarlyStopping counter: 19 out of 20\n",
      "21th Epoch starting.\n",
      "Epoch [21] Train Loss: 0.0605 & Validation Loss: 0.5009\n",
      "EarlyStopping counter: 20 out of 20\n",
      "Early Stopping!!\n",
      "5 Fold is Training\n",
      "1th Epoch starting.\n",
      "Epoch [1] Train Loss: 0.2497 & Validation Loss: 0.3530\n",
      "Validation loss decreased (inf --> 0.3530).  Saving model ...\n",
      "2th Epoch starting.\n",
      "Epoch [2] Train Loss: 0.2035 & Validation Loss: 0.3891\n",
      "EarlyStopping counter: 1 out of 20\n",
      "3th Epoch starting.\n",
      "Epoch [3] Train Loss: 0.1555 & Validation Loss: 0.3542\n",
      "EarlyStopping counter: 2 out of 20\n",
      "4th Epoch starting.\n",
      "Epoch [4] Train Loss: 0.1387 & Validation Loss: 0.3829\n",
      "EarlyStopping counter: 3 out of 20\n",
      "5th Epoch starting.\n",
      "Epoch [5] Train Loss: 0.1246 & Validation Loss: 0.4483\n",
      "EarlyStopping counter: 4 out of 20\n",
      "6th Epoch starting.\n",
      "Epoch [6] Train Loss: 0.1202 & Validation Loss: 0.4270\n",
      "EarlyStopping counter: 5 out of 20\n",
      "7th Epoch starting.\n",
      "Epoch [7] Train Loss: 0.1147 & Validation Loss: 0.4433\n",
      "EarlyStopping counter: 6 out of 20\n",
      "8th Epoch starting.\n",
      "Epoch [8] Train Loss: 0.1085 & Validation Loss: 0.4227\n",
      "EarlyStopping counter: 7 out of 20\n",
      "9th Epoch starting.\n",
      "Epoch [9] Train Loss: 0.1002 & Validation Loss: 0.4185\n",
      "EarlyStopping counter: 8 out of 20\n",
      "10th Epoch starting.\n",
      "Epoch [10] Train Loss: 0.0937 & Validation Loss: 0.4145\n",
      "EarlyStopping counter: 9 out of 20\n",
      "11th Epoch starting.\n",
      "Epoch [11] Train Loss: 0.0958 & Validation Loss: 0.4565\n",
      "EarlyStopping counter: 10 out of 20\n",
      "12th Epoch starting.\n",
      "Epoch [12] Train Loss: 0.0838 & Validation Loss: 0.4648\n",
      "EarlyStopping counter: 11 out of 20\n",
      "13th Epoch starting.\n",
      "Epoch [13] Train Loss: 0.0805 & Validation Loss: 0.4901\n",
      "EarlyStopping counter: 12 out of 20\n",
      "14th Epoch starting.\n",
      "Epoch [14] Train Loss: 0.0783 & Validation Loss: 0.4674\n",
      "EarlyStopping counter: 13 out of 20\n",
      "15th Epoch starting.\n",
      "Epoch [15] Train Loss: 0.0732 & Validation Loss: 0.4489\n",
      "EarlyStopping counter: 14 out of 20\n",
      "16th Epoch starting.\n",
      "Epoch [16] Train Loss: 0.0733 & Validation Loss: 0.5332\n",
      "EarlyStopping counter: 15 out of 20\n",
      "17th Epoch starting.\n",
      "Epoch [17] Train Loss: 0.0722 & Validation Loss: 0.4571\n",
      "EarlyStopping counter: 16 out of 20\n",
      "18th Epoch starting.\n",
      "Epoch [18] Train Loss: 0.0648 & Validation Loss: 0.4693\n",
      "EarlyStopping counter: 17 out of 20\n",
      "19th Epoch starting.\n",
      "Epoch [19] Train Loss: 0.0653 & Validation Loss: 0.4900\n",
      "EarlyStopping counter: 18 out of 20\n",
      "20th Epoch starting.\n",
      "Epoch [20] Train Loss: 0.0648 & Validation Loss: 0.5131\n",
      "EarlyStopping counter: 19 out of 20\n",
      "21th Epoch starting.\n",
      "Epoch [21] Train Loss: 0.0629 & Validation Loss: 0.4903\n",
      "EarlyStopping counter: 20 out of 20\n",
      "Early Stopping!!\n",
      "28343.59582924843\n"
     ]
    }
   ],
   "source": [
    "model, train_losses, valid_losses = train_KFold(model, batch_size=batch_size, n_epochs=250, patience=20, data_info=data_info, fold=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bZTnSk-m3VA1",
    "outputId": "9fc64bd0-2801-4784-8be5-d05b5c68723d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "test_dataset = datasets.CIFAR10(root='./cifar_10data/',\n",
    "                                train=False,\n",
    "                                transform=transforms.ToTensor(),\n",
    "                                download=True) \n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset,\n",
    "                                          batch_size=batch_size,\n",
    "                                          num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Oukopvrl3Xmb",
    "outputId": "4493ac14-4a3f-4bb0-8b54-b0cc7aae78f4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test set] Average loss: 0.0056, Accuracy: 8870/10000 (88.70%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pyIZz6RaDdBd"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "GoogLeNet-5.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "35719a48e8dc4b7394b0229494a83751": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "63a5cc05f28a449cbe0aeceedcf0104d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_7f24449862fa4a1fa01bfee2498ce820",
       "IPY_MODEL_f7e38560ed6e47fa8422fc65fa354aba"
      ],
      "layout": "IPY_MODEL_9ab4ec09717445b4b71834b58d88d4a3"
     }
    },
    "7133f9d85a344cda9057dbe15dab5da9": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7f24449862fa4a1fa01bfee2498ce820": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "info",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7133f9d85a344cda9057dbe15dab5da9",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_35719a48e8dc4b7394b0229494a83751",
      "value": 1
     }
    },
    "812cfd0371514c8fb6e2295d7fd07e8d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9ab4ec09717445b4b71834b58d88d4a3": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9d3ca229af3b4cbe98096f3ef77c556a": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f7e38560ed6e47fa8422fc65fa354aba": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9d3ca229af3b4cbe98096f3ef77c556a",
      "placeholder": "​",
      "style": "IPY_MODEL_812cfd0371514c8fb6e2295d7fd07e8d",
      "value": " 170500096/? [00:20&lt;00:00, 96391462.35it/s]"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
