{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "F6X3GaAKID98",
    "outputId": "03ca83c1-96ae-4615-8b2f-92d372f4aef1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch_optimizer\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ce/70/ca0cd259662eef5c9448d3ecf14af880bbfe76331e4eeab7b19827d6dbe6/torch_optimizer-0.0.1a17-py3-none-any.whl (69kB)\n",
      "\r",
      "\u001b[K     |████▊                           | 10kB 17.6MB/s eta 0:00:01\r",
      "\u001b[K     |█████████▌                      | 20kB 23.1MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████▏                 | 30kB 20.8MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████             | 40kB 18.0MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████▋        | 51kB 17.2MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████▍   | 61kB 17.7MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████████| 71kB 3.6MB/s \n",
      "\u001b[?25hRequirement already satisfied: torch>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from torch_optimizer) (1.7.0+cu101)\n",
      "Collecting pytorch-ranger>=0.1.1\n",
      "  Downloading https://files.pythonhosted.org/packages/0d/70/12256257d861bbc3e176130d25be1de085ce7a9e60594064888a950f2154/pytorch_ranger-0.1.1-py3-none-any.whl\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch>=1.1.0->torch_optimizer) (3.7.4.3)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch>=1.1.0->torch_optimizer) (1.19.4)\n",
      "Requirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from torch>=1.1.0->torch_optimizer) (0.8)\n",
      "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch>=1.1.0->torch_optimizer) (0.16.0)\n",
      "Installing collected packages: pytorch-ranger, torch-optimizer\n",
      "Successfully installed pytorch-ranger-0.1.1 torch-optimizer-0.0.1a17\n"
     ]
    }
   ],
   "source": [
    "!pip install torch_optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rb6NVwvMkejv"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import math\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from torch.optim import Optimizer\n",
    "import torch_optimizer as optim\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import transforms\n",
    "\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "31G1krZelCtv"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "name = torch.cuda.get_device_name(0)\n",
    "print(\"GPU: \" + name)\n",
    "\n",
    "random_seed = 0\n",
    "\n",
    "torch.manual_seed(random_seed)\n",
    "torch.cuda.manual_seed(random_seed)\n",
    "\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "np.random.seed(random_seed)\n",
    "random.seed(random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s4XiQ-gW2Jrl"
   },
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    def __init__(self, patience=10, path='checkpoint.pt'):\n",
    "        \n",
    "        self.patience = patience\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.val_loss_min = np.Inf\n",
    "        self.early_stop = False\n",
    "\n",
    "        self.path = path\n",
    "\n",
    "\n",
    "\n",
    "    def __call__(self, val_loss, model):\n",
    "\n",
    "        score = val_loss\n",
    "\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            \n",
    "            print('Validation loss decreased ({:.4f} --> {:.4f}).  Saving model ...'.format(self.val_loss_min, val_loss))\n",
    "            torch.save(model.state_dict(), self.path)\n",
    "            self.val_loss_min = val_loss\n",
    "\n",
    "        elif score > self.best_score:\n",
    "            self.counter += 1\n",
    "            print(\"EarlyStopping counter: {} out of {}\".format(self.counter, self.patience))\n",
    "\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.counter = 0\n",
    "\n",
    "            print('Validation loss decreased --- Saving model ...')\n",
    "            torch.save(model.state_dict(), self.path)\n",
    "            self.val_loss_min = val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hQ1ME49U2LfX"
   },
   "outputs": [],
   "source": [
    "def get_data_len_index(pad=4, randomcrop=32):\n",
    "    data_shuffle = []\n",
    "\n",
    "    transform = transforms.Compose([\n",
    "                                    transforms.Pad(pad),\n",
    "                                    transforms.RandomHorizontalFlip(),\n",
    "                                    transforms.RandomCrop(randomcrop),\n",
    "                                    transforms.ToTensor()\n",
    "    ])\n",
    "\n",
    "    train_dataset = datasets.CIFAR10(root='./cifar_10data/',\n",
    "                                     train=True,\n",
    "                                     transform=transform,\n",
    "                                     download=True) \n",
    "    \n",
    "    len_train = len(train_dataset)\n",
    "    index_train = list(range(len_train))\n",
    "    \n",
    "\n",
    "    data_shuffle.append(len_train)\n",
    "    data_shuffle.append(index_train)\n",
    "    data_shuffle.append(train_dataset)\n",
    "\n",
    "    return data_shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a6mJ0iil2OKK"
   },
   "outputs": [],
   "source": [
    "def test_model(model, batch_size=128):\n",
    "    model.eval()\n",
    "    test_loss, correct, total = 0, 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader :\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            output = model(images)\n",
    "            test_loss += loss_function(output, labels).item()\n",
    "\n",
    "            pred = output.max(1, keepdim=True)[1]\n",
    "            correct += pred.eq(labels.view_as(pred)).sum().item()\n",
    "\n",
    "            total += labels.size(0)\n",
    "\n",
    "    print('[Test set] Average loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)\\n'.format(\n",
    "            test_loss /total, correct, total,\n",
    "            100. * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TKzv-xPE2P8x"
   },
   "outputs": [],
   "source": [
    "def train_model(model, batch_size, n_epochs, patience, loader):\n",
    "    train_loader = loader[0]\n",
    "    valid_loader = loader[1]\n",
    "    \n",
    "    train_losses = []\n",
    "    valid_losses = []\n",
    "\n",
    "    avg_train_losses = []\n",
    "    avg_valid_losses = []\n",
    "\n",
    "    early_stopping = EarlyStopping(patience=patience)\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    start = time.time()\n",
    "\n",
    "    for epoch in range(1,n_epochs+1):\n",
    "        print(\"{}th Epoch starting.\".format(epoch))\n",
    "\n",
    "        for i, (images, labels) in enumerate(train_loader):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            output = model(images)\n",
    "\n",
    "            train_loss = loss_function(output, labels)\n",
    "\n",
    "            train_loss.backward()\n",
    "\n",
    "            optimizer.step()\n",
    "\n",
    "            loss = train_loss.item()\n",
    "\n",
    "\n",
    "            train_losses.append(loss)\n",
    "\n",
    "\n",
    "        model.eval()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for images, labels in valid_loader:\n",
    "                images , labels = images.to(device), labels.to(device)\n",
    "\n",
    "                output = model(images)\n",
    "\n",
    "                valid_loss = loss_function(output, labels)\n",
    "\n",
    "                loss = valid_loss.item()\n",
    "\n",
    "                valid_losses.append(loss)\n",
    "        \n",
    "        loss_train = np.average(train_losses)\n",
    "        loss_valid = np.average(valid_losses)\n",
    "\n",
    "        avg_train_losses.append(loss_train)\n",
    "        avg_valid_losses.append(loss_valid)\n",
    "\n",
    "        print(\"Epoch [{}] Train Loss: {:.4f} & Validation Loss: {:.4f}\".format(epoch, loss_train, loss_valid))\n",
    "\n",
    "        train_losses = []\n",
    "        valid_losses = []\n",
    "\n",
    "        early_stopping(loss_valid, model)\n",
    "\n",
    "        if early_stopping.early_stop:\n",
    "            print(\"Early Stopping!!\")\n",
    "            end = time.time()\n",
    "            #print(end-start)\n",
    "            break\n",
    "\n",
    "    model.load_state_dict(torch.load('checkpoint.pt'))\n",
    "\n",
    "    return model, avg_train_losses, avg_valid_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zLR9K7IP2Sa-"
   },
   "outputs": [],
   "source": [
    "def train_KFold(model, batch_size, n_epochs, patience, data_info, fold):\n",
    "        \n",
    "    train_losses = []\n",
    "    valid_losses = []\n",
    "\n",
    "    loader = []\n",
    "\n",
    "    path='checkpoint.pt'\n",
    "\n",
    "    len_train = data_info[0]\n",
    "    index_train = data_info[1]\n",
    "    train_dataset = data_info[2]\n",
    "\n",
    "    np.random.shuffle(index_train)\n",
    "\n",
    "    split_size = len_train // fold\n",
    "\n",
    "    start = time.time()\n",
    "    for i in range(fold):\n",
    "\n",
    "        valid_ind = index_train[split_size * i: split_size * (i+1)]\n",
    "                \n",
    "        if i == 0:\n",
    "            train_ind = index_train[split_size * (i+1):]\n",
    "                    \n",
    "        elif i == 4:\n",
    "            train_ind = index_train[:split_size*i]\n",
    "\n",
    "        else:\n",
    "            train_ind = index_train[:split_size * i] + index_train[split_size * (i+1):]\n",
    "\n",
    "        train_sampler = SubsetRandomSampler(train_ind)\n",
    "        valid_sampler = SubsetRandomSampler(valid_ind)    \n",
    "\n",
    "        train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                                        batch_size=batch_size,\n",
    "                                                        sampler = train_sampler,\n",
    "                                                        num_workers=0)\n",
    "                \n",
    "        valid_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                                        batch_size=batch_size,\n",
    "                                                        sampler = valid_sampler,\n",
    "                                                        num_workers=0)\n",
    "        \n",
    "        loader.append(train_loader)\n",
    "        loader.append(valid_loader)\n",
    "                \n",
    "\n",
    "        print(\"{} Fold is Training\".format(i+1))\n",
    "\n",
    "        model, avg_train_losses, avg_valid_losses = train_model(model, batch_size, n_epochs, patience, loader)\n",
    "        \n",
    "        train_losses.append(avg_train_losses)\n",
    "        valid_losses.append(avg_valid_losses)\n",
    "        \n",
    "    end = time.time()\n",
    "\n",
    "    print(end-start)\n",
    "\n",
    "    return model, train_losses, valid_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "E8HJNjn-lD5a"
   },
   "outputs": [],
   "source": [
    "class BasicBlock_New(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super(BasicBlock_New, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            in_planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.ds = nn.Sequential(\n",
    "            nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(planes)\n",
    "        )\n",
    "\n",
    "        if stride != 1 or in_planes != self.expansion*planes:\n",
    "            self.ds = nn.Sequential(\n",
    "                nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "                nn.BatchNorm2d(planes),\n",
    "                nn.Conv2d(planes, planes, kernel_size=1, stride=2, bias=False),\n",
    "                nn.BatchNorm2d(planes)\n",
    "            )\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != self.expansion*planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, self.expansion*planes,\n",
    "                          kernel_size=1, stride=1, bias=False),\n",
    "                nn.BatchNorm2d(self.expansion*planes),\n",
    "                nn.MaxPool2d(kernel_size=2, stride=2, ceil_mode=True)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.ds(out)\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wc0JU6chlFkM"
   },
   "outputs": [],
   "source": [
    "class Bottleneck(nn.Module):\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=1, stride=stride, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.conv3 = nn.Conv2d(planes, self.expansion *\n",
    "                               planes, kernel_size=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(self.expansion*planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != self.expansion*planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, self.expansion*planes,\n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(self.expansion*planes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = F.relu(self.bn2(self.conv2(out)))\n",
    "        out = self.bn3(self.conv3(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rTrPjySNlIhL"
   },
   "outputs": [],
   "source": [
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, num_blocks, num_classes=10):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.in_planes = 64\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3,stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3,stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "\n",
    "        self.pool1 = nn.MaxPool2d(2, stride=2, ceil_mode=True)\n",
    "\n",
    "        self.conv3 = nn.Conv2d(64, 64, kernel_size=1,stride=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(64)\n",
    "        \n",
    "        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n",
    "        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n",
    "        self.linear = nn.Linear(512*block.expansion, num_classes)\n",
    "\n",
    "    def _make_layer(self, block, planes, num_blocks, stride):\n",
    "        strides = [stride] + [1]*(num_blocks-1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_planes, planes, stride))\n",
    "            self.in_planes = planes * block.expansion\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = F.relu(self.bn2(self.conv2(out)))\n",
    "        out = self.pool1(out)\n",
    "        out = F.relu(self.bn3(self.conv3(out)))\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = F.avg_pool2d(out, 2)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.linear(out)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "02OQ6hTSlKKT"
   },
   "outputs": [],
   "source": [
    "def ResNet18():\n",
    "    return ResNet(BasicBlock, [2, 2, 2, 2])\n",
    "\n",
    "\n",
    "def ResNet34():\n",
    "    return ResNet(BasicBlock, [3, 4, 6, 3])\n",
    "\n",
    "\n",
    "def ResNet50():\n",
    "    return ResNet(Bottleneck, [3, 4, 6, 3])\n",
    "\n",
    "\n",
    "def ResNet101():\n",
    "    return ResNet(Bottleneck, [3, 4, 23, 3])\n",
    "\n",
    "\n",
    "def ResNet152():\n",
    "    return ResNet(Bottleneck, [3, 8, 36, 3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q2M8c5PrEmkr"
   },
   "outputs": [],
   "source": [
    "def ResNet34():\n",
    "    return ResNet(BasicBlock_New, [3, 4, 6, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s0hi-kZu2Wlj"
   },
   "outputs": [],
   "source": [
    "data_info = get_data_len_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iAW6EekslLd_"
   },
   "outputs": [],
   "source": [
    "model = ResNet34().to(device)\n",
    "loss_function = torch.nn.CrossEntropyLoss()\n",
    "optimizer = optim.RAdam(model.parameters(), weight_decay=5e-4)\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oagLwRzwUSke",
    "outputId": "c81f738f-4622-41c9-fd96-4b31076caf2c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Fold is Training\n",
      "1th Epoch starting.\n",
      "Epoch [1] Train Loss: 1.5684 & Validation Loss: 1.2340\n",
      "Validation loss decreased (inf --> 1.2340).  Saving model ...\n",
      "2th Epoch starting.\n",
      "Epoch [2] Train Loss: 1.9119 & Validation Loss: 1.6364\n",
      "EarlyStopping counter: 1 out of 20\n",
      "3th Epoch starting.\n",
      "Epoch [3] Train Loss: 1.5286 & Validation Loss: 1.4017\n",
      "EarlyStopping counter: 2 out of 20\n",
      "4th Epoch starting.\n",
      "Epoch [4] Train Loss: 1.3031 & Validation Loss: 1.2302\n",
      "Validation loss decreased --- Saving model ...\n",
      "5th Epoch starting.\n",
      "Epoch [5] Train Loss: 1.1456 & Validation Loss: 1.0773\n",
      "Validation loss decreased --- Saving model ...\n",
      "6th Epoch starting.\n",
      "Epoch [6] Train Loss: 1.0256 & Validation Loss: 0.9820\n",
      "Validation loss decreased --- Saving model ...\n",
      "7th Epoch starting.\n",
      "Epoch [7] Train Loss: 0.9379 & Validation Loss: 0.9208\n",
      "Validation loss decreased --- Saving model ...\n",
      "8th Epoch starting.\n",
      "Epoch [8] Train Loss: 0.8626 & Validation Loss: 0.8844\n",
      "Validation loss decreased --- Saving model ...\n",
      "9th Epoch starting.\n",
      "Epoch [9] Train Loss: 0.8098 & Validation Loss: 0.7774\n",
      "Validation loss decreased --- Saving model ...\n",
      "10th Epoch starting.\n",
      "Epoch [10] Train Loss: 0.7610 & Validation Loss: 0.7328\n",
      "Validation loss decreased --- Saving model ...\n",
      "11th Epoch starting.\n",
      "Epoch [11] Train Loss: 0.7214 & Validation Loss: 0.7812\n",
      "EarlyStopping counter: 1 out of 20\n",
      "12th Epoch starting.\n",
      "Epoch [12] Train Loss: 0.6940 & Validation Loss: 0.7069\n",
      "Validation loss decreased --- Saving model ...\n",
      "13th Epoch starting.\n",
      "Epoch [13] Train Loss: 0.6668 & Validation Loss: 0.7563\n",
      "EarlyStopping counter: 1 out of 20\n",
      "14th Epoch starting.\n",
      "Epoch [14] Train Loss: 0.6461 & Validation Loss: 0.6695\n",
      "Validation loss decreased --- Saving model ...\n",
      "15th Epoch starting.\n",
      "Epoch [15] Train Loss: 0.6172 & Validation Loss: 0.6650\n",
      "Validation loss decreased --- Saving model ...\n",
      "16th Epoch starting.\n",
      "Epoch [16] Train Loss: 0.6056 & Validation Loss: 0.6421\n",
      "Validation loss decreased --- Saving model ...\n",
      "17th Epoch starting.\n",
      "Epoch [17] Train Loss: 0.5828 & Validation Loss: 0.6350\n",
      "Validation loss decreased --- Saving model ...\n",
      "18th Epoch starting.\n",
      "Epoch [18] Train Loss: 0.5590 & Validation Loss: 0.6021\n",
      "Validation loss decreased --- Saving model ...\n",
      "19th Epoch starting.\n",
      "Epoch [19] Train Loss: 0.5432 & Validation Loss: 0.5767\n",
      "Validation loss decreased --- Saving model ...\n",
      "20th Epoch starting.\n",
      "Epoch [20] Train Loss: 0.5370 & Validation Loss: 0.6191\n",
      "EarlyStopping counter: 1 out of 20\n",
      "21th Epoch starting.\n",
      "Epoch [21] Train Loss: 0.5263 & Validation Loss: 0.6168\n",
      "EarlyStopping counter: 2 out of 20\n",
      "22th Epoch starting.\n",
      "Epoch [22] Train Loss: 0.5038 & Validation Loss: 0.5728\n",
      "Validation loss decreased --- Saving model ...\n",
      "23th Epoch starting.\n",
      "Epoch [23] Train Loss: 0.4992 & Validation Loss: 0.5738\n",
      "EarlyStopping counter: 1 out of 20\n",
      "24th Epoch starting.\n",
      "Epoch [24] Train Loss: 0.4846 & Validation Loss: 0.5896\n",
      "EarlyStopping counter: 2 out of 20\n",
      "25th Epoch starting.\n",
      "Epoch [25] Train Loss: 0.4729 & Validation Loss: 0.5530\n",
      "Validation loss decreased --- Saving model ...\n",
      "26th Epoch starting.\n",
      "Epoch [26] Train Loss: 0.4630 & Validation Loss: 0.5654\n",
      "EarlyStopping counter: 1 out of 20\n",
      "27th Epoch starting.\n",
      "Epoch [27] Train Loss: 0.4592 & Validation Loss: 0.5726\n",
      "EarlyStopping counter: 2 out of 20\n",
      "28th Epoch starting.\n",
      "Epoch [28] Train Loss: 0.4490 & Validation Loss: 0.5659\n",
      "EarlyStopping counter: 3 out of 20\n",
      "29th Epoch starting.\n",
      "Epoch [29] Train Loss: 0.4377 & Validation Loss: 0.6166\n",
      "EarlyStopping counter: 4 out of 20\n",
      "30th Epoch starting.\n",
      "Epoch [30] Train Loss: 0.4279 & Validation Loss: 0.5524\n",
      "Validation loss decreased --- Saving model ...\n",
      "31th Epoch starting.\n",
      "Epoch [31] Train Loss: 0.4118 & Validation Loss: 0.5697\n",
      "EarlyStopping counter: 1 out of 20\n",
      "32th Epoch starting.\n",
      "Epoch [32] Train Loss: 0.4093 & Validation Loss: 0.5512\n",
      "Validation loss decreased --- Saving model ...\n",
      "33th Epoch starting.\n",
      "Epoch [33] Train Loss: 0.3983 & Validation Loss: 0.5360\n",
      "Validation loss decreased --- Saving model ...\n",
      "34th Epoch starting.\n",
      "Epoch [34] Train Loss: 0.4026 & Validation Loss: 0.5296\n",
      "Validation loss decreased --- Saving model ...\n",
      "35th Epoch starting.\n",
      "Epoch [35] Train Loss: 0.3861 & Validation Loss: 0.5157\n",
      "Validation loss decreased --- Saving model ...\n",
      "36th Epoch starting.\n",
      "Epoch [36] Train Loss: 0.3792 & Validation Loss: 0.5693\n",
      "EarlyStopping counter: 1 out of 20\n",
      "37th Epoch starting.\n",
      "Epoch [37] Train Loss: 0.3737 & Validation Loss: 0.5222\n",
      "EarlyStopping counter: 2 out of 20\n",
      "38th Epoch starting.\n",
      "Epoch [38] Train Loss: 0.3703 & Validation Loss: 0.5011\n",
      "Validation loss decreased --- Saving model ...\n",
      "39th Epoch starting.\n",
      "Epoch [39] Train Loss: 0.3636 & Validation Loss: 0.4944\n",
      "Validation loss decreased --- Saving model ...\n",
      "40th Epoch starting.\n",
      "Epoch [40] Train Loss: 0.3472 & Validation Loss: 0.4704\n",
      "Validation loss decreased --- Saving model ...\n",
      "41th Epoch starting.\n",
      "Epoch [41] Train Loss: 0.3452 & Validation Loss: 0.5002\n",
      "EarlyStopping counter: 1 out of 20\n",
      "42th Epoch starting.\n",
      "Epoch [42] Train Loss: 0.3369 & Validation Loss: 0.5003\n",
      "EarlyStopping counter: 2 out of 20\n",
      "43th Epoch starting.\n",
      "Epoch [43] Train Loss: 0.3404 & Validation Loss: 0.4995\n",
      "EarlyStopping counter: 3 out of 20\n",
      "44th Epoch starting.\n",
      "Epoch [44] Train Loss: 0.3330 & Validation Loss: 0.5299\n",
      "EarlyStopping counter: 4 out of 20\n",
      "45th Epoch starting.\n",
      "Epoch [45] Train Loss: 0.3276 & Validation Loss: 0.5050\n",
      "EarlyStopping counter: 5 out of 20\n",
      "46th Epoch starting.\n",
      "Epoch [46] Train Loss: 0.3196 & Validation Loss: 0.4911\n",
      "EarlyStopping counter: 6 out of 20\n",
      "47th Epoch starting.\n",
      "Epoch [47] Train Loss: 0.3187 & Validation Loss: 0.4627\n",
      "Validation loss decreased --- Saving model ...\n",
      "48th Epoch starting.\n",
      "Epoch [48] Train Loss: 0.3077 & Validation Loss: 0.4754\n",
      "EarlyStopping counter: 1 out of 20\n",
      "49th Epoch starting.\n",
      "Epoch [49] Train Loss: 0.2989 & Validation Loss: 0.4801\n",
      "EarlyStopping counter: 2 out of 20\n",
      "50th Epoch starting.\n",
      "Epoch [50] Train Loss: 0.2956 & Validation Loss: 0.4618\n",
      "Validation loss decreased --- Saving model ...\n",
      "51th Epoch starting.\n",
      "Epoch [51] Train Loss: 0.2884 & Validation Loss: 0.4565\n",
      "Validation loss decreased --- Saving model ...\n",
      "52th Epoch starting.\n",
      "Epoch [52] Train Loss: 0.2910 & Validation Loss: 0.4708\n",
      "EarlyStopping counter: 1 out of 20\n",
      "53th Epoch starting.\n",
      "Epoch [53] Train Loss: 0.2866 & Validation Loss: 0.4678\n",
      "EarlyStopping counter: 2 out of 20\n",
      "54th Epoch starting.\n",
      "Epoch [54] Train Loss: 0.2734 & Validation Loss: 0.4742\n",
      "EarlyStopping counter: 3 out of 20\n",
      "55th Epoch starting.\n",
      "Epoch [55] Train Loss: 0.2696 & Validation Loss: 0.4486\n",
      "Validation loss decreased --- Saving model ...\n",
      "56th Epoch starting.\n",
      "Epoch [56] Train Loss: 0.2713 & Validation Loss: 0.4728\n",
      "EarlyStopping counter: 1 out of 20\n",
      "57th Epoch starting.\n",
      "Epoch [57] Train Loss: 0.2656 & Validation Loss: 0.4833\n",
      "EarlyStopping counter: 2 out of 20\n",
      "58th Epoch starting.\n",
      "Epoch [58] Train Loss: 0.2583 & Validation Loss: 0.4587\n",
      "EarlyStopping counter: 3 out of 20\n",
      "59th Epoch starting.\n",
      "Epoch [59] Train Loss: 0.2546 & Validation Loss: 0.4799\n",
      "EarlyStopping counter: 4 out of 20\n",
      "60th Epoch starting.\n",
      "Epoch [60] Train Loss: 0.2478 & Validation Loss: 0.4836\n",
      "EarlyStopping counter: 5 out of 20\n",
      "61th Epoch starting.\n",
      "Epoch [61] Train Loss: 0.2520 & Validation Loss: 0.4849\n",
      "EarlyStopping counter: 6 out of 20\n",
      "62th Epoch starting.\n",
      "Epoch [62] Train Loss: 0.2445 & Validation Loss: 0.4555\n",
      "EarlyStopping counter: 7 out of 20\n",
      "63th Epoch starting.\n",
      "Epoch [63] Train Loss: 0.2413 & Validation Loss: 0.5038\n",
      "EarlyStopping counter: 8 out of 20\n",
      "64th Epoch starting.\n",
      "Epoch [64] Train Loss: 0.2353 & Validation Loss: 0.4858\n",
      "EarlyStopping counter: 9 out of 20\n",
      "65th Epoch starting.\n",
      "Epoch [65] Train Loss: 0.2327 & Validation Loss: 0.4522\n",
      "EarlyStopping counter: 10 out of 20\n",
      "66th Epoch starting.\n",
      "Epoch [66] Train Loss: 0.2332 & Validation Loss: 0.4974\n",
      "EarlyStopping counter: 11 out of 20\n",
      "67th Epoch starting.\n",
      "Epoch [67] Train Loss: 0.2279 & Validation Loss: 0.4708\n",
      "EarlyStopping counter: 12 out of 20\n",
      "68th Epoch starting.\n",
      "Epoch [68] Train Loss: 0.2233 & Validation Loss: 0.4793\n",
      "EarlyStopping counter: 13 out of 20\n",
      "69th Epoch starting.\n",
      "Epoch [69] Train Loss: 0.2175 & Validation Loss: 0.4587\n",
      "EarlyStopping counter: 14 out of 20\n",
      "70th Epoch starting.\n",
      "Epoch [70] Train Loss: 0.2137 & Validation Loss: 0.4594\n",
      "EarlyStopping counter: 15 out of 20\n",
      "71th Epoch starting.\n",
      "Epoch [71] Train Loss: 0.2153 & Validation Loss: 0.4503\n",
      "EarlyStopping counter: 16 out of 20\n",
      "72th Epoch starting.\n",
      "Epoch [72] Train Loss: 0.2091 & Validation Loss: 0.4702\n",
      "EarlyStopping counter: 17 out of 20\n",
      "73th Epoch starting.\n",
      "Epoch [73] Train Loss: 0.2044 & Validation Loss: 0.4632\n",
      "EarlyStopping counter: 18 out of 20\n",
      "74th Epoch starting.\n",
      "Epoch [74] Train Loss: 0.2022 & Validation Loss: 0.4815\n",
      "EarlyStopping counter: 19 out of 20\n",
      "75th Epoch starting.\n",
      "Epoch [75] Train Loss: 0.2061 & Validation Loss: 0.4935\n",
      "EarlyStopping counter: 20 out of 20\n",
      "Early Stopping!!\n",
      "2 Fold is Training\n",
      "1th Epoch starting.\n",
      "Epoch [1] Train Loss: 1.3116 & Validation Loss: 0.8985\n",
      "Validation loss decreased (inf --> 0.8985).  Saving model ...\n",
      "2th Epoch starting.\n",
      "Epoch [2] Train Loss: 0.7601 & Validation Loss: 0.6998\n",
      "Validation loss decreased --- Saving model ...\n",
      "3th Epoch starting.\n",
      "Epoch [3] Train Loss: 0.5638 & Validation Loss: 0.5323\n",
      "Validation loss decreased --- Saving model ...\n",
      "4th Epoch starting.\n",
      "Epoch [4] Train Loss: 0.4974 & Validation Loss: 0.4943\n",
      "Validation loss decreased --- Saving model ...\n",
      "5th Epoch starting.\n",
      "Epoch [5] Train Loss: 0.4407 & Validation Loss: 0.4863\n",
      "Validation loss decreased --- Saving model ...\n",
      "6th Epoch starting.\n",
      "Epoch [6] Train Loss: 0.4085 & Validation Loss: 0.4529\n",
      "Validation loss decreased --- Saving model ...\n",
      "7th Epoch starting.\n",
      "Epoch [7] Train Loss: 0.3800 & Validation Loss: 0.4920\n",
      "EarlyStopping counter: 1 out of 20\n",
      "8th Epoch starting.\n",
      "Epoch [8] Train Loss: 0.3475 & Validation Loss: 0.4088\n",
      "Validation loss decreased --- Saving model ...\n",
      "9th Epoch starting.\n",
      "Epoch [9] Train Loss: 0.3311 & Validation Loss: 0.4323\n",
      "EarlyStopping counter: 1 out of 20\n",
      "10th Epoch starting.\n",
      "Epoch [10] Train Loss: 0.3117 & Validation Loss: 0.3887\n",
      "Validation loss decreased --- Saving model ...\n",
      "11th Epoch starting.\n",
      "Epoch [11] Train Loss: 0.2947 & Validation Loss: 0.4136\n",
      "EarlyStopping counter: 1 out of 20\n",
      "12th Epoch starting.\n",
      "Epoch [12] Train Loss: 0.2765 & Validation Loss: 0.4148\n",
      "EarlyStopping counter: 2 out of 20\n",
      "13th Epoch starting.\n",
      "Epoch [13] Train Loss: 0.2683 & Validation Loss: 0.3923\n",
      "EarlyStopping counter: 3 out of 20\n",
      "14th Epoch starting.\n",
      "Epoch [14] Train Loss: 0.2561 & Validation Loss: 0.3959\n",
      "EarlyStopping counter: 4 out of 20\n",
      "15th Epoch starting.\n",
      "Epoch [15] Train Loss: 0.2365 & Validation Loss: 0.3813\n",
      "Validation loss decreased --- Saving model ...\n",
      "16th Epoch starting.\n",
      "Epoch [16] Train Loss: 0.2272 & Validation Loss: 0.3859\n",
      "EarlyStopping counter: 1 out of 20\n",
      "17th Epoch starting.\n",
      "Epoch [17] Train Loss: 0.2184 & Validation Loss: 0.3924\n",
      "EarlyStopping counter: 2 out of 20\n",
      "18th Epoch starting.\n",
      "Epoch [18] Train Loss: 0.2062 & Validation Loss: 0.3950\n",
      "EarlyStopping counter: 3 out of 20\n",
      "19th Epoch starting.\n",
      "Epoch [19] Train Loss: 0.1983 & Validation Loss: 0.3717\n",
      "Validation loss decreased --- Saving model ...\n",
      "20th Epoch starting.\n",
      "Epoch [20] Train Loss: 0.1909 & Validation Loss: 0.3977\n",
      "EarlyStopping counter: 1 out of 20\n",
      "21th Epoch starting.\n",
      "Epoch [21] Train Loss: 0.1809 & Validation Loss: 0.4308\n",
      "EarlyStopping counter: 2 out of 20\n",
      "22th Epoch starting.\n",
      "Epoch [22] Train Loss: 0.1773 & Validation Loss: 0.4170\n",
      "EarlyStopping counter: 3 out of 20\n",
      "23th Epoch starting.\n",
      "Epoch [23] Train Loss: 0.1710 & Validation Loss: 0.3885\n",
      "EarlyStopping counter: 4 out of 20\n",
      "24th Epoch starting.\n",
      "Epoch [24] Train Loss: 0.1583 & Validation Loss: 0.4145\n",
      "EarlyStopping counter: 5 out of 20\n",
      "25th Epoch starting.\n",
      "Epoch [25] Train Loss: 0.1564 & Validation Loss: 0.4157\n",
      "EarlyStopping counter: 6 out of 20\n",
      "26th Epoch starting.\n",
      "Epoch [26] Train Loss: 0.1507 & Validation Loss: 0.4211\n",
      "EarlyStopping counter: 7 out of 20\n",
      "27th Epoch starting.\n",
      "Epoch [27] Train Loss: 0.1419 & Validation Loss: 0.3913\n",
      "EarlyStopping counter: 8 out of 20\n",
      "28th Epoch starting.\n",
      "Epoch [28] Train Loss: 0.1358 & Validation Loss: 0.4581\n",
      "EarlyStopping counter: 9 out of 20\n",
      "29th Epoch starting.\n",
      "Epoch [29] Train Loss: 0.1399 & Validation Loss: 0.4333\n",
      "EarlyStopping counter: 10 out of 20\n",
      "30th Epoch starting.\n",
      "Epoch [30] Train Loss: 0.1321 & Validation Loss: 0.4380\n",
      "EarlyStopping counter: 11 out of 20\n",
      "31th Epoch starting.\n",
      "Epoch [31] Train Loss: 0.1264 & Validation Loss: 0.4254\n",
      "EarlyStopping counter: 12 out of 20\n",
      "32th Epoch starting.\n",
      "Epoch [32] Train Loss: 0.1283 & Validation Loss: 0.4037\n",
      "EarlyStopping counter: 13 out of 20\n",
      "33th Epoch starting.\n",
      "Epoch [33] Train Loss: 0.1230 & Validation Loss: 0.4048\n",
      "EarlyStopping counter: 14 out of 20\n",
      "34th Epoch starting.\n",
      "Epoch [34] Train Loss: 0.1156 & Validation Loss: 0.4174\n",
      "EarlyStopping counter: 15 out of 20\n",
      "35th Epoch starting.\n",
      "Epoch [35] Train Loss: 0.1133 & Validation Loss: 0.4442\n",
      "EarlyStopping counter: 16 out of 20\n",
      "36th Epoch starting.\n",
      "Epoch [36] Train Loss: 0.1137 & Validation Loss: 0.4098\n",
      "EarlyStopping counter: 17 out of 20\n",
      "37th Epoch starting.\n",
      "Epoch [37] Train Loss: 0.1080 & Validation Loss: 0.4423\n",
      "EarlyStopping counter: 18 out of 20\n",
      "38th Epoch starting.\n",
      "Epoch [38] Train Loss: 0.1066 & Validation Loss: 0.4159\n",
      "EarlyStopping counter: 19 out of 20\n",
      "39th Epoch starting.\n",
      "Epoch [39] Train Loss: 0.1045 & Validation Loss: 0.4587\n",
      "EarlyStopping counter: 20 out of 20\n",
      "Early Stopping!!\n",
      "3 Fold is Training\n",
      "1th Epoch starting.\n",
      "Epoch [1] Train Loss: 0.4369 & Validation Loss: 0.4012\n",
      "Validation loss decreased (inf --> 0.4012).  Saving model ...\n",
      "2th Epoch starting.\n",
      "Epoch [2] Train Loss: 0.3000 & Validation Loss: 0.4370\n",
      "EarlyStopping counter: 1 out of 20\n",
      "3th Epoch starting.\n",
      "Epoch [3] Train Loss: 0.2354 & Validation Loss: 0.3976\n",
      "Validation loss decreased --- Saving model ...\n",
      "4th Epoch starting.\n",
      "Epoch [4] Train Loss: 0.2076 & Validation Loss: 0.3816\n",
      "Validation loss decreased --- Saving model ...\n",
      "5th Epoch starting.\n",
      "Epoch [5] Train Loss: 0.1926 & Validation Loss: 0.4259\n",
      "EarlyStopping counter: 1 out of 20\n",
      "6th Epoch starting.\n",
      "Epoch [6] Train Loss: 0.1857 & Validation Loss: 0.3859\n",
      "EarlyStopping counter: 2 out of 20\n",
      "7th Epoch starting.\n",
      "Epoch [7] Train Loss: 0.1746 & Validation Loss: 0.3981\n",
      "EarlyStopping counter: 3 out of 20\n",
      "8th Epoch starting.\n",
      "Epoch [8] Train Loss: 0.1690 & Validation Loss: 0.3851\n",
      "EarlyStopping counter: 4 out of 20\n",
      "9th Epoch starting.\n",
      "Epoch [9] Train Loss: 0.1597 & Validation Loss: 0.3939\n",
      "EarlyStopping counter: 5 out of 20\n",
      "10th Epoch starting.\n",
      "Epoch [10] Train Loss: 0.1547 & Validation Loss: 0.3899\n",
      "EarlyStopping counter: 6 out of 20\n",
      "11th Epoch starting.\n",
      "Epoch [11] Train Loss: 0.1479 & Validation Loss: 0.3843\n",
      "EarlyStopping counter: 7 out of 20\n",
      "12th Epoch starting.\n",
      "Epoch [12] Train Loss: 0.1371 & Validation Loss: 0.3822\n",
      "EarlyStopping counter: 8 out of 20\n",
      "13th Epoch starting.\n",
      "Epoch [13] Train Loss: 0.1328 & Validation Loss: 0.3984\n",
      "EarlyStopping counter: 9 out of 20\n",
      "14th Epoch starting.\n",
      "Epoch [14] Train Loss: 0.1302 & Validation Loss: 0.4093\n",
      "EarlyStopping counter: 10 out of 20\n",
      "15th Epoch starting.\n",
      "Epoch [15] Train Loss: 0.1276 & Validation Loss: 0.4263\n",
      "EarlyStopping counter: 11 out of 20\n",
      "16th Epoch starting.\n",
      "Epoch [16] Train Loss: 0.1200 & Validation Loss: 0.3914\n",
      "EarlyStopping counter: 12 out of 20\n",
      "17th Epoch starting.\n",
      "Epoch [17] Train Loss: 0.1171 & Validation Loss: 0.3957\n",
      "EarlyStopping counter: 13 out of 20\n",
      "18th Epoch starting.\n",
      "Epoch [18] Train Loss: 0.1179 & Validation Loss: 0.4034\n",
      "EarlyStopping counter: 14 out of 20\n",
      "19th Epoch starting.\n",
      "Epoch [19] Train Loss: 0.1083 & Validation Loss: 0.3806\n",
      "Validation loss decreased --- Saving model ...\n",
      "20th Epoch starting.\n",
      "Epoch [20] Train Loss: 0.0993 & Validation Loss: 0.4190\n",
      "EarlyStopping counter: 1 out of 20\n",
      "21th Epoch starting.\n",
      "Epoch [21] Train Loss: 0.1007 & Validation Loss: 0.4251\n",
      "EarlyStopping counter: 2 out of 20\n",
      "22th Epoch starting.\n",
      "Epoch [22] Train Loss: 0.0977 & Validation Loss: 0.4552\n",
      "EarlyStopping counter: 3 out of 20\n",
      "23th Epoch starting.\n",
      "Epoch [23] Train Loss: 0.0931 & Validation Loss: 0.4480\n",
      "EarlyStopping counter: 4 out of 20\n",
      "24th Epoch starting.\n",
      "Epoch [24] Train Loss: 0.0978 & Validation Loss: 0.4487\n",
      "EarlyStopping counter: 5 out of 20\n",
      "25th Epoch starting.\n",
      "Epoch [25] Train Loss: 0.0916 & Validation Loss: 0.4362\n",
      "EarlyStopping counter: 6 out of 20\n",
      "26th Epoch starting.\n",
      "Epoch [26] Train Loss: 0.0866 & Validation Loss: 0.4757\n",
      "EarlyStopping counter: 7 out of 20\n",
      "27th Epoch starting.\n",
      "Epoch [27] Train Loss: 0.0851 & Validation Loss: 0.4416\n",
      "EarlyStopping counter: 8 out of 20\n",
      "28th Epoch starting.\n",
      "Epoch [28] Train Loss: 0.0829 & Validation Loss: 0.4137\n",
      "EarlyStopping counter: 9 out of 20\n",
      "29th Epoch starting.\n",
      "Epoch [29] Train Loss: 0.0851 & Validation Loss: 0.4598\n",
      "EarlyStopping counter: 10 out of 20\n",
      "30th Epoch starting.\n",
      "Epoch [30] Train Loss: 0.0747 & Validation Loss: 0.4394\n",
      "EarlyStopping counter: 11 out of 20\n",
      "31th Epoch starting.\n",
      "Epoch [31] Train Loss: 0.0768 & Validation Loss: 0.4649\n",
      "EarlyStopping counter: 12 out of 20\n",
      "32th Epoch starting.\n",
      "Epoch [32] Train Loss: 0.0760 & Validation Loss: 0.4641\n",
      "EarlyStopping counter: 13 out of 20\n",
      "33th Epoch starting.\n",
      "Epoch [33] Train Loss: 0.0728 & Validation Loss: 0.4694\n",
      "EarlyStopping counter: 14 out of 20\n",
      "34th Epoch starting.\n",
      "Epoch [34] Train Loss: 0.0767 & Validation Loss: 0.4984\n",
      "EarlyStopping counter: 15 out of 20\n",
      "35th Epoch starting.\n",
      "Epoch [35] Train Loss: 0.0683 & Validation Loss: 0.4902\n",
      "EarlyStopping counter: 16 out of 20\n",
      "36th Epoch starting.\n",
      "Epoch [36] Train Loss: 0.0742 & Validation Loss: 0.5066\n",
      "EarlyStopping counter: 17 out of 20\n",
      "37th Epoch starting.\n",
      "Epoch [37] Train Loss: 0.0693 & Validation Loss: 0.4922\n",
      "EarlyStopping counter: 18 out of 20\n",
      "38th Epoch starting.\n",
      "Epoch [38] Train Loss: 0.0666 & Validation Loss: 0.4764\n",
      "EarlyStopping counter: 19 out of 20\n",
      "39th Epoch starting.\n",
      "Epoch [39] Train Loss: 0.0667 & Validation Loss: 0.5088\n",
      "EarlyStopping counter: 20 out of 20\n",
      "Early Stopping!!\n",
      "4 Fold is Training\n",
      "1th Epoch starting.\n",
      "Epoch [1] Train Loss: 0.2656 & Validation Loss: 0.3674\n",
      "Validation loss decreased (inf --> 0.3674).  Saving model ...\n",
      "2th Epoch starting.\n",
      "Epoch [2] Train Loss: 0.1797 & Validation Loss: 0.4243\n",
      "EarlyStopping counter: 1 out of 20\n",
      "3th Epoch starting.\n",
      "Epoch [3] Train Loss: 0.1324 & Validation Loss: 0.3695\n",
      "EarlyStopping counter: 2 out of 20\n",
      "4th Epoch starting.\n",
      "Epoch [4] Train Loss: 0.1161 & Validation Loss: 0.3816\n",
      "EarlyStopping counter: 3 out of 20\n",
      "5th Epoch starting.\n",
      "Epoch [5] Train Loss: 0.1065 & Validation Loss: 0.4654\n",
      "EarlyStopping counter: 4 out of 20\n",
      "6th Epoch starting.\n",
      "Epoch [6] Train Loss: 0.1066 & Validation Loss: 0.3831\n",
      "EarlyStopping counter: 5 out of 20\n",
      "7th Epoch starting.\n",
      "Epoch [7] Train Loss: 0.0972 & Validation Loss: 0.3787\n",
      "EarlyStopping counter: 6 out of 20\n",
      "8th Epoch starting.\n",
      "Epoch [8] Train Loss: 0.0950 & Validation Loss: 0.3951\n",
      "EarlyStopping counter: 7 out of 20\n",
      "9th Epoch starting.\n",
      "Epoch [9] Train Loss: 0.0921 & Validation Loss: 0.4019\n",
      "EarlyStopping counter: 8 out of 20\n",
      "10th Epoch starting.\n",
      "Epoch [10] Train Loss: 0.0893 & Validation Loss: 0.4018\n",
      "EarlyStopping counter: 9 out of 20\n",
      "11th Epoch starting.\n",
      "Epoch [11] Train Loss: 0.0839 & Validation Loss: 0.4409\n",
      "EarlyStopping counter: 10 out of 20\n",
      "12th Epoch starting.\n",
      "Epoch [12] Train Loss: 0.0799 & Validation Loss: 0.4236\n",
      "EarlyStopping counter: 11 out of 20\n",
      "13th Epoch starting.\n",
      "Epoch [13] Train Loss: 0.0787 & Validation Loss: 0.4061\n",
      "EarlyStopping counter: 12 out of 20\n",
      "14th Epoch starting.\n",
      "Epoch [14] Train Loss: 0.0765 & Validation Loss: 0.4126\n",
      "EarlyStopping counter: 13 out of 20\n",
      "15th Epoch starting.\n",
      "Epoch [15] Train Loss: 0.0755 & Validation Loss: 0.4556\n",
      "EarlyStopping counter: 14 out of 20\n",
      "16th Epoch starting.\n",
      "Epoch [16] Train Loss: 0.0711 & Validation Loss: 0.4809\n",
      "EarlyStopping counter: 15 out of 20\n",
      "17th Epoch starting.\n",
      "Epoch [17] Train Loss: 0.0746 & Validation Loss: 0.4391\n",
      "EarlyStopping counter: 16 out of 20\n",
      "18th Epoch starting.\n",
      "Epoch [18] Train Loss: 0.0651 & Validation Loss: 0.5235\n",
      "EarlyStopping counter: 17 out of 20\n",
      "19th Epoch starting.\n",
      "Epoch [19] Train Loss: 0.0702 & Validation Loss: 0.4854\n",
      "EarlyStopping counter: 18 out of 20\n",
      "20th Epoch starting.\n",
      "Epoch [20] Train Loss: 0.0668 & Validation Loss: 0.4975\n",
      "EarlyStopping counter: 19 out of 20\n",
      "21th Epoch starting.\n",
      "Epoch [21] Train Loss: 0.0650 & Validation Loss: 0.4688\n",
      "EarlyStopping counter: 20 out of 20\n",
      "Early Stopping!!\n",
      "5 Fold is Training\n",
      "1th Epoch starting.\n",
      "Epoch [1] Train Loss: 0.1943 & Validation Loss: 0.3579\n",
      "Validation loss decreased (inf --> 0.3579).  Saving model ...\n",
      "2th Epoch starting.\n",
      "Epoch [2] Train Loss: 0.1672 & Validation Loss: 0.4192\n",
      "EarlyStopping counter: 1 out of 20\n",
      "3th Epoch starting.\n",
      "Epoch [3] Train Loss: 0.1247 & Validation Loss: 0.3885\n",
      "EarlyStopping counter: 2 out of 20\n",
      "4th Epoch starting.\n",
      "Epoch [4] Train Loss: 0.1158 & Validation Loss: 0.3585\n",
      "EarlyStopping counter: 3 out of 20\n",
      "5th Epoch starting.\n",
      "Epoch [5] Train Loss: 0.0967 & Validation Loss: 0.4081\n",
      "EarlyStopping counter: 4 out of 20\n",
      "6th Epoch starting.\n",
      "Epoch [6] Train Loss: 0.1016 & Validation Loss: 0.4044\n",
      "EarlyStopping counter: 5 out of 20\n",
      "7th Epoch starting.\n",
      "Epoch [7] Train Loss: 0.0919 & Validation Loss: 0.4002\n",
      "EarlyStopping counter: 6 out of 20\n",
      "8th Epoch starting.\n",
      "Epoch [8] Train Loss: 0.0881 & Validation Loss: 0.4194\n",
      "EarlyStopping counter: 7 out of 20\n",
      "9th Epoch starting.\n",
      "Epoch [9] Train Loss: 0.0913 & Validation Loss: 0.4061\n",
      "EarlyStopping counter: 8 out of 20\n",
      "10th Epoch starting.\n",
      "Epoch [10] Train Loss: 0.0901 & Validation Loss: 0.3922\n",
      "EarlyStopping counter: 9 out of 20\n",
      "11th Epoch starting.\n",
      "Epoch [11] Train Loss: 0.0777 & Validation Loss: 0.4330\n",
      "EarlyStopping counter: 10 out of 20\n",
      "12th Epoch starting.\n",
      "Epoch [12] Train Loss: 0.0791 & Validation Loss: 0.4291\n",
      "EarlyStopping counter: 11 out of 20\n",
      "13th Epoch starting.\n",
      "Epoch [13] Train Loss: 0.0779 & Validation Loss: 0.4444\n",
      "EarlyStopping counter: 12 out of 20\n",
      "14th Epoch starting.\n",
      "Epoch [14] Train Loss: 0.0708 & Validation Loss: 0.4405\n",
      "EarlyStopping counter: 13 out of 20\n",
      "15th Epoch starting.\n",
      "Epoch [15] Train Loss: 0.0739 & Validation Loss: 0.4479\n",
      "EarlyStopping counter: 14 out of 20\n",
      "16th Epoch starting.\n",
      "Epoch [16] Train Loss: 0.0725 & Validation Loss: 0.4473\n",
      "EarlyStopping counter: 15 out of 20\n",
      "17th Epoch starting.\n",
      "Epoch [17] Train Loss: 0.0681 & Validation Loss: 0.4518\n",
      "EarlyStopping counter: 16 out of 20\n",
      "18th Epoch starting.\n",
      "Epoch [18] Train Loss: 0.0675 & Validation Loss: 0.5060\n",
      "EarlyStopping counter: 17 out of 20\n",
      "19th Epoch starting.\n",
      "Epoch [19] Train Loss: 0.0620 & Validation Loss: 0.4618\n",
      "EarlyStopping counter: 18 out of 20\n",
      "20th Epoch starting.\n",
      "Epoch [20] Train Loss: 0.0672 & Validation Loss: 0.4680\n",
      "EarlyStopping counter: 19 out of 20\n",
      "21th Epoch starting.\n",
      "Epoch [21] Train Loss: 0.0601 & Validation Loss: 0.4742\n",
      "EarlyStopping counter: 20 out of 20\n",
      "Early Stopping!!\n",
      "12673.449650764465\n"
     ]
    }
   ],
   "source": [
    "model, train_losses, valid_losses = train_KFold(model, batch_size=batch_size, n_epochs=200, patience=20, data_info=data_info, fold=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tARyafai2gIV",
    "outputId": "cd3c1915-6ea6-4f01-b625-92e7e8cf6990"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    " test_dataset = datasets.CIFAR10(root='./cifar_10data/',\n",
    "                                train=False,\n",
    "                                transform=transforms.ToTensor(),\n",
    "                                download=True) \n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset,\n",
    "                                          batch_size=batch_size,\n",
    "                                          num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mDnQTsCh2h0d",
    "outputId": "2a4a73e2-c8be-408c-8632-3100bf8fb88b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test set] Average loss: 0.0057, Accuracy: 8896/10000 (88.96%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EXcP98-ND4YT"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "ResNet34-6.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
