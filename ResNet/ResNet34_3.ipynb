{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aDqo_10lRgjG",
    "outputId": "04fdae76-503b-495a-cfaa-7a26f88fa333"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch_optimizer\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ce/70/ca0cd259662eef5c9448d3ecf14af880bbfe76331e4eeab7b19827d6dbe6/torch_optimizer-0.0.1a17-py3-none-any.whl (69kB)\n",
      "\r",
      "\u001b[K     |████▊                           | 10kB 29.1MB/s eta 0:00:01\r",
      "\u001b[K     |█████████▌                      | 20kB 33.7MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████▏                 | 30kB 38.0MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████             | 40kB 28.5MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████▋        | 51kB 31.3MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████▍   | 61kB 33.9MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████████| 71kB 8.4MB/s \n",
      "\u001b[?25hRequirement already satisfied: torch>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from torch_optimizer) (1.7.0+cu101)\n",
      "Collecting pytorch-ranger>=0.1.1\n",
      "  Downloading https://files.pythonhosted.org/packages/0d/70/12256257d861bbc3e176130d25be1de085ce7a9e60594064888a950f2154/pytorch_ranger-0.1.1-py3-none-any.whl\n",
      "Requirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from torch>=1.1.0->torch_optimizer) (0.8)\n",
      "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch>=1.1.0->torch_optimizer) (0.16.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch>=1.1.0->torch_optimizer) (1.19.4)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch>=1.1.0->torch_optimizer) (3.7.4.3)\n",
      "Installing collected packages: pytorch-ranger, torch-optimizer\n",
      "Successfully installed pytorch-ranger-0.1.1 torch-optimizer-0.0.1a17\n",
      "cuda:0\n",
      "GPU: Tesla T4\n"
     ]
    }
   ],
   "source": [
    "!pip install torch_optimizer\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "import math\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from torch.optim import Optimizer\n",
    "import torch_optimizer as optim\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import transforms\n",
    "\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "name = torch.cuda.get_device_name(0)\n",
    "print(\"GPU: \" + name)\n",
    "\n",
    "random_seed = 0\n",
    "\n",
    "torch.manual_seed(random_seed)\n",
    "torch.cuda.manual_seed(random_seed)\n",
    "\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "np.random.seed(random_seed)\n",
    "random.seed(random_seed)\n",
    "\n",
    "\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience=10, path='checkpoint.pt'):\n",
    "        \n",
    "        self.patience = patience\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.val_loss_min = np.Inf\n",
    "        self.early_stop = False\n",
    "\n",
    "        self.path = path\n",
    "\n",
    "\n",
    "\n",
    "    def __call__(self, val_loss, model):\n",
    "\n",
    "        score = val_loss\n",
    "\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            \n",
    "            print('Validation loss decreased ({:.4f} --> {:.4f}).  Saving model ...'.format(self.val_loss_min, val_loss))\n",
    "            torch.save(model.state_dict(), self.path)\n",
    "            self.val_loss_min = val_loss\n",
    "\n",
    "        elif score > self.best_score:\n",
    "            self.counter += 1\n",
    "            print(\"EarlyStopping counter: {} out of {}\".format(self.counter, self.patience))\n",
    "\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.counter = 0\n",
    "\n",
    "            print('Validation loss decreased --- Saving model ...')\n",
    "            torch.save(model.state_dict(), self.path)\n",
    "            self.val_loss_min = val_loss\n",
    "\n",
    "\n",
    "\n",
    "def get_data_len_index(pad=4, randomcrop=32):\n",
    "    data_shuffle = []\n",
    "\n",
    "    transform = transforms.Compose([\n",
    "                                    transforms.Pad(pad),\n",
    "                                    transforms.RandomHorizontalFlip(),\n",
    "                                    transforms.RandomCrop(randomcrop),\n",
    "                                    transforms.ToTensor()\n",
    "    ])\n",
    "\n",
    "    train_dataset = datasets.CIFAR10(root='./cifar_10data/',\n",
    "                                     train=True,\n",
    "                                     transform=transform,\n",
    "                                     download=True) \n",
    "    \n",
    "    len_train = len(train_dataset)\n",
    "    index_train = list(range(len_train))\n",
    "    \n",
    "\n",
    "    data_shuffle.append(len_train)\n",
    "    data_shuffle.append(index_train)\n",
    "    data_shuffle.append(train_dataset)\n",
    "\n",
    "    return data_shuffle\n",
    "\n",
    "\n",
    "\n",
    "def test_model(model, batch_size=128):\n",
    "    model.eval()\n",
    "    test_loss, correct, total = 0, 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader :\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            output = model(images)\n",
    "            test_loss += loss_function(output, labels).item()\n",
    "\n",
    "            pred = output.max(1, keepdim=True)[1]\n",
    "            correct += pred.eq(labels.view_as(pred)).sum().item()\n",
    "\n",
    "            total += labels.size(0)\n",
    "\n",
    "    print('[Test set] Average loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)\\n'.format(\n",
    "            test_loss /total, correct, total,\n",
    "            100. * correct / total))\n",
    "    \n",
    "\n",
    "def train_model(model, batch_size, n_epochs, patience, loader):\n",
    "    train_loader = loader[0]\n",
    "    valid_loader = loader[1]\n",
    "    \n",
    "    train_losses = []\n",
    "    valid_losses = []\n",
    "\n",
    "    avg_train_losses = []\n",
    "    avg_valid_losses = []\n",
    "\n",
    "    early_stopping = EarlyStopping(patience=patience)\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    start = time.time()\n",
    "\n",
    "    for epoch in range(1,n_epochs+1):\n",
    "        print(\"{}th Epoch starting.\".format(epoch))\n",
    "\n",
    "        for i, (images, labels) in enumerate(train_loader):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            output = model(images)\n",
    "\n",
    "            train_loss = loss_function(output, labels)\n",
    "\n",
    "            train_loss.backward()\n",
    "\n",
    "            optimizer.step()\n",
    "\n",
    "            loss = train_loss.item()\n",
    "\n",
    "\n",
    "            train_losses.append(loss)\n",
    "\n",
    "\n",
    "        model.eval()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for images, labels in valid_loader:\n",
    "                images , labels = images.to(device), labels.to(device)\n",
    "\n",
    "                output = model(images)\n",
    "\n",
    "                valid_loss = loss_function(output, labels)\n",
    "\n",
    "                loss = valid_loss.item()\n",
    "\n",
    "                valid_losses.append(loss)\n",
    "        \n",
    "        loss_train = np.average(train_losses)\n",
    "        loss_valid = np.average(valid_losses)\n",
    "\n",
    "        avg_train_losses.append(loss_train)\n",
    "        avg_valid_losses.append(loss_valid)\n",
    "\n",
    "        print(\"Epoch [{}] Train Loss: {:.4f} & Validation Loss: {:.4f}\".format(epoch, loss_train, loss_valid))\n",
    "\n",
    "        train_losses = []\n",
    "        valid_losses = []\n",
    "\n",
    "        early_stopping(loss_valid, model)\n",
    "\n",
    "        if early_stopping.early_stop:\n",
    "            print(\"Early Stopping!!\")\n",
    "            end = time.time()\n",
    "            #print(end-start)\n",
    "            break\n",
    "\n",
    "    model.load_state_dict(torch.load('checkpoint.pt'))\n",
    "\n",
    "    return model, avg_train_losses, avg_valid_losses\n",
    "\n",
    "\n",
    "\n",
    "def train_KFold(model, batch_size, n_epochs, patience, data_info, fold):\n",
    "        \n",
    "    train_losses = []\n",
    "    valid_losses = []\n",
    "\n",
    "    loader = []\n",
    "\n",
    "    path='checkpoint.pt'\n",
    "\n",
    "    len_train = data_info[0]\n",
    "    index_train = data_info[1]\n",
    "    train_dataset = data_info[2]\n",
    "\n",
    "    np.random.shuffle(index_train)\n",
    "\n",
    "    split_size = len_train // fold\n",
    "\n",
    "    start = time.time()\n",
    "    for i in range(fold):\n",
    "\n",
    "        valid_ind = index_train[split_size * i: split_size * (i+1)]\n",
    "                \n",
    "        if i == 0:\n",
    "            train_ind = index_train[split_size * (i+1):]\n",
    "                    \n",
    "        elif i == 4:\n",
    "            train_ind = index_train[:split_size*i]\n",
    "\n",
    "        else:\n",
    "            train_ind = index_train[:split_size * i] + index_train[split_size * (i+1):]\n",
    "\n",
    "        train_sampler = SubsetRandomSampler(train_ind)\n",
    "        valid_sampler = SubsetRandomSampler(valid_ind)    \n",
    "\n",
    "        train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                                        batch_size=batch_size,\n",
    "                                                        sampler = train_sampler,\n",
    "                                                        num_workers=0)\n",
    "                \n",
    "        valid_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                                        batch_size=batch_size,\n",
    "                                                        sampler = valid_sampler,\n",
    "                                                        num_workers=0)\n",
    "        \n",
    "        loader.append(train_loader)\n",
    "        loader.append(valid_loader)\n",
    "                \n",
    "\n",
    "        print(\"{} Fold is Training\".format(i+1))\n",
    "\n",
    "        model, avg_train_losses, avg_valid_losses = train_model(model, batch_size, n_epochs, patience, loader)\n",
    "        \n",
    "        train_losses.append(avg_train_losses)\n",
    "        valid_losses.append(avg_valid_losses)\n",
    "        \n",
    "    end = time.time()\n",
    "\n",
    "    print(end-start)\n",
    "\n",
    "    return model, train_losses, valid_losses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dEmN8UaBRsMn"
   },
   "outputs": [],
   "source": [
    "import torch.nn.init as init\n",
    "\n",
    "def weight_init(m):\n",
    "  if isinstance(m, nn.Conv2d):\n",
    "    init.kaiming_uniform_(m.weight.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lYrJE2CnXUJI"
   },
   "source": [
    "### He Uniform Initialization\n",
    "\n",
    "### Batch_size 63 --> 256  \n",
    "### Weight_decay 5e-4 --> 5e-5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c5NKIvIARuWW"
   },
   "outputs": [],
   "source": [
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3,\n",
    "                               stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != self.expansion*planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, self.expansion*planes,\n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(self.expansion*planes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EzM8jER4XmmF"
   },
   "outputs": [],
   "source": [
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, num_blocks, num_classes=10):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.in_planes = 64\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3,\n",
    "                               stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n",
    "        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n",
    "        self.linear = nn.Linear(512*block.expansion, num_classes)\n",
    "\n",
    "    def _make_layer(self, block, planes, num_blocks, stride):\n",
    "        strides = [stride] + [1]*(num_blocks-1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_planes, planes, stride))\n",
    "            self.in_planes = planes * block.expansion\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = F.avg_pool2d(out, 4)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.linear(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NOwOECplXo-W"
   },
   "outputs": [],
   "source": [
    "def ResNet34():\n",
    "    return ResNet(BasicBlock, [3, 4, 6, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85,
     "referenced_widgets": [
      "5ae6706d9a1940d593343133f78cc924",
      "4a6340de48954a878f04c2907e5320a1",
      "1f02028cf0994b40aba2137d710804cd",
      "11eb5d4d8dce47a09dd100a72d8d703c",
      "98dfa2a3b7c54791aaeaebc6c7adadfc",
      "f4e1dfcc0685492db9a88f50eaa02a1f",
      "b6109007eecf476693a2f567babe43a4",
      "f708822d267e479395e7c17bfecc1ea8"
     ]
    },
    "id": "iXoW0CwQRuhA",
    "outputId": "6b3b1669-fcbd-449d-cde0-ae09d1133ae0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./cifar_10data/cifar-10-python.tar.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ae6706d9a1940d593343133f78cc924",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./cifar_10data/cifar-10-python.tar.gz to ./cifar_10data/\n"
     ]
    }
   ],
   "source": [
    "data_info = get_data_len_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q3whrv19RvmE"
   },
   "outputs": [],
   "source": [
    "model = ResNet34().to(device)\n",
    "loss_function = torch.nn.CrossEntropyLoss()\n",
    "optimizer = optim.RAdam(model.parameters(), weight_decay=5e-5)\n",
    "batch_size = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kuK2VtzKRwdx",
    "outputId": "dcc73184-b8b7-40ec-9242-197122a5b610"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Fold is Training\n",
      "1th Epoch starting.\n",
      "Epoch [1] Train Loss: 1.6782 & Validation Loss: 1.5393\n",
      "Validation loss decreased (inf --> 1.5393).  Saving model ...\n",
      "2th Epoch starting.\n",
      "Epoch [2] Train Loss: 2.2616 & Validation Loss: 1.9003\n",
      "EarlyStopping counter: 1 out of 20\n",
      "3th Epoch starting.\n",
      "Epoch [3] Train Loss: 1.8087 & Validation Loss: 1.7220\n",
      "EarlyStopping counter: 2 out of 20\n",
      "4th Epoch starting.\n",
      "Epoch [4] Train Loss: 1.6918 & Validation Loss: 1.6073\n",
      "EarlyStopping counter: 3 out of 20\n",
      "5th Epoch starting.\n",
      "Epoch [5] Train Loss: 1.5836 & Validation Loss: 1.5316\n",
      "Validation loss decreased --- Saving model ...\n",
      "6th Epoch starting.\n",
      "Epoch [6] Train Loss: 1.4910 & Validation Loss: 1.4638\n",
      "Validation loss decreased --- Saving model ...\n",
      "7th Epoch starting.\n",
      "Epoch [7] Train Loss: 1.4099 & Validation Loss: 1.3713\n",
      "Validation loss decreased --- Saving model ...\n",
      "8th Epoch starting.\n",
      "Epoch [8] Train Loss: 1.3209 & Validation Loss: 1.2982\n",
      "Validation loss decreased --- Saving model ...\n",
      "9th Epoch starting.\n",
      "Epoch [9] Train Loss: 1.2211 & Validation Loss: 1.2129\n",
      "Validation loss decreased --- Saving model ...\n",
      "10th Epoch starting.\n",
      "Epoch [10] Train Loss: 1.1333 & Validation Loss: 1.0975\n",
      "Validation loss decreased --- Saving model ...\n",
      "11th Epoch starting.\n",
      "Epoch [11] Train Loss: 1.0543 & Validation Loss: 1.0455\n",
      "Validation loss decreased --- Saving model ...\n",
      "12th Epoch starting.\n",
      "Epoch [12] Train Loss: 0.9802 & Validation Loss: 1.0222\n",
      "Validation loss decreased --- Saving model ...\n",
      "13th Epoch starting.\n",
      "Epoch [13] Train Loss: 0.9209 & Validation Loss: 0.9659\n",
      "Validation loss decreased --- Saving model ...\n",
      "14th Epoch starting.\n",
      "Epoch [14] Train Loss: 0.8620 & Validation Loss: 0.8584\n",
      "Validation loss decreased --- Saving model ...\n",
      "15th Epoch starting.\n",
      "Epoch [15] Train Loss: 0.8161 & Validation Loss: 0.9479\n",
      "EarlyStopping counter: 1 out of 20\n",
      "16th Epoch starting.\n",
      "Epoch [16] Train Loss: 0.7767 & Validation Loss: 0.7840\n",
      "Validation loss decreased --- Saving model ...\n",
      "17th Epoch starting.\n",
      "Epoch [17] Train Loss: 0.7215 & Validation Loss: 0.7972\n",
      "EarlyStopping counter: 1 out of 20\n",
      "18th Epoch starting.\n",
      "Epoch [18] Train Loss: 0.6849 & Validation Loss: 0.7862\n",
      "EarlyStopping counter: 2 out of 20\n",
      "19th Epoch starting.\n",
      "Epoch [19] Train Loss: 0.6747 & Validation Loss: 0.8192\n",
      "EarlyStopping counter: 3 out of 20\n",
      "20th Epoch starting.\n",
      "Epoch [20] Train Loss: 0.6406 & Validation Loss: 0.7150\n",
      "Validation loss decreased --- Saving model ...\n",
      "21th Epoch starting.\n",
      "Epoch [21] Train Loss: 0.6018 & Validation Loss: 0.6773\n",
      "Validation loss decreased --- Saving model ...\n",
      "22th Epoch starting.\n",
      "Epoch [22] Train Loss: 0.5929 & Validation Loss: 0.7220\n",
      "EarlyStopping counter: 1 out of 20\n",
      "23th Epoch starting.\n",
      "Epoch [23] Train Loss: 0.5664 & Validation Loss: 0.7376\n",
      "EarlyStopping counter: 2 out of 20\n",
      "24th Epoch starting.\n",
      "Epoch [24] Train Loss: 0.5459 & Validation Loss: 0.6639\n",
      "Validation loss decreased --- Saving model ...\n",
      "25th Epoch starting.\n",
      "Epoch [25] Train Loss: 0.5272 & Validation Loss: 0.6239\n",
      "Validation loss decreased --- Saving model ...\n",
      "26th Epoch starting.\n",
      "Epoch [26] Train Loss: 0.5104 & Validation Loss: 0.7159\n",
      "EarlyStopping counter: 1 out of 20\n",
      "27th Epoch starting.\n",
      "Epoch [27] Train Loss: 0.4961 & Validation Loss: 0.6518\n",
      "EarlyStopping counter: 2 out of 20\n",
      "28th Epoch starting.\n",
      "Epoch [28] Train Loss: 0.4856 & Validation Loss: 0.5936\n",
      "Validation loss decreased --- Saving model ...\n",
      "29th Epoch starting.\n",
      "Epoch [29] Train Loss: 0.4732 & Validation Loss: 0.6518\n",
      "EarlyStopping counter: 1 out of 20\n",
      "30th Epoch starting.\n",
      "Epoch [30] Train Loss: 0.4689 & Validation Loss: 0.5931\n",
      "Validation loss decreased --- Saving model ...\n",
      "31th Epoch starting.\n",
      "Epoch [31] Train Loss: 0.4438 & Validation Loss: 0.6420\n",
      "EarlyStopping counter: 1 out of 20\n",
      "32th Epoch starting.\n",
      "Epoch [32] Train Loss: 0.4294 & Validation Loss: 0.5988\n",
      "EarlyStopping counter: 2 out of 20\n",
      "33th Epoch starting.\n",
      "Epoch [33] Train Loss: 0.4265 & Validation Loss: 0.6418\n",
      "EarlyStopping counter: 3 out of 20\n",
      "34th Epoch starting.\n",
      "Epoch [34] Train Loss: 0.4095 & Validation Loss: 0.5557\n",
      "Validation loss decreased --- Saving model ...\n",
      "35th Epoch starting.\n",
      "Epoch [35] Train Loss: 0.4029 & Validation Loss: 0.6386\n",
      "EarlyStopping counter: 1 out of 20\n",
      "36th Epoch starting.\n",
      "Epoch [36] Train Loss: 0.3858 & Validation Loss: 0.5774\n",
      "EarlyStopping counter: 2 out of 20\n",
      "37th Epoch starting.\n",
      "Epoch [37] Train Loss: 0.3756 & Validation Loss: 0.6048\n",
      "EarlyStopping counter: 3 out of 20\n",
      "38th Epoch starting.\n",
      "Epoch [38] Train Loss: 0.3790 & Validation Loss: 0.5911\n",
      "EarlyStopping counter: 4 out of 20\n",
      "39th Epoch starting.\n",
      "Epoch [39] Train Loss: 0.3679 & Validation Loss: 0.5516\n",
      "Validation loss decreased --- Saving model ...\n",
      "40th Epoch starting.\n",
      "Epoch [40] Train Loss: 0.3572 & Validation Loss: 0.5482\n",
      "Validation loss decreased --- Saving model ...\n",
      "41th Epoch starting.\n",
      "Epoch [41] Train Loss: 0.3496 & Validation Loss: 0.5798\n",
      "EarlyStopping counter: 1 out of 20\n",
      "42th Epoch starting.\n",
      "Epoch [42] Train Loss: 0.3482 & Validation Loss: 0.6729\n",
      "EarlyStopping counter: 2 out of 20\n",
      "43th Epoch starting.\n",
      "Epoch [43] Train Loss: 0.3501 & Validation Loss: 0.5536\n",
      "EarlyStopping counter: 3 out of 20\n",
      "44th Epoch starting.\n",
      "Epoch [44] Train Loss: 0.3355 & Validation Loss: 0.6013\n",
      "EarlyStopping counter: 4 out of 20\n",
      "45th Epoch starting.\n",
      "Epoch [45] Train Loss: 0.3270 & Validation Loss: 0.5944\n",
      "EarlyStopping counter: 5 out of 20\n",
      "46th Epoch starting.\n",
      "Epoch [46] Train Loss: 0.3268 & Validation Loss: 0.5739\n",
      "EarlyStopping counter: 6 out of 20\n",
      "47th Epoch starting.\n",
      "Epoch [47] Train Loss: 0.3090 & Validation Loss: 0.5947\n",
      "EarlyStopping counter: 7 out of 20\n",
      "48th Epoch starting.\n",
      "Epoch [48] Train Loss: 0.2972 & Validation Loss: 0.6137\n",
      "EarlyStopping counter: 8 out of 20\n",
      "49th Epoch starting.\n",
      "Epoch [49] Train Loss: 0.3060 & Validation Loss: 0.5644\n",
      "EarlyStopping counter: 9 out of 20\n",
      "50th Epoch starting.\n",
      "Epoch [50] Train Loss: 0.3076 & Validation Loss: 0.5491\n",
      "EarlyStopping counter: 10 out of 20\n",
      "51th Epoch starting.\n",
      "Epoch [51] Train Loss: 0.2932 & Validation Loss: 0.5369\n",
      "Validation loss decreased --- Saving model ...\n",
      "52th Epoch starting.\n",
      "Epoch [52] Train Loss: 0.2756 & Validation Loss: 0.5726\n",
      "EarlyStopping counter: 1 out of 20\n",
      "53th Epoch starting.\n",
      "Epoch [53] Train Loss: 0.2852 & Validation Loss: 0.5405\n",
      "EarlyStopping counter: 2 out of 20\n",
      "54th Epoch starting.\n",
      "Epoch [54] Train Loss: 0.2701 & Validation Loss: 0.5441\n",
      "EarlyStopping counter: 3 out of 20\n",
      "55th Epoch starting.\n",
      "Epoch [55] Train Loss: 0.2670 & Validation Loss: 0.5522\n",
      "EarlyStopping counter: 4 out of 20\n",
      "56th Epoch starting.\n",
      "Epoch [56] Train Loss: 0.2639 & Validation Loss: 0.5854\n",
      "EarlyStopping counter: 5 out of 20\n",
      "57th Epoch starting.\n",
      "Epoch [57] Train Loss: 0.2591 & Validation Loss: 0.5352\n",
      "Validation loss decreased --- Saving model ...\n",
      "58th Epoch starting.\n",
      "Epoch [58] Train Loss: 0.2587 & Validation Loss: 0.5881\n",
      "EarlyStopping counter: 1 out of 20\n",
      "59th Epoch starting.\n",
      "Epoch [59] Train Loss: 0.2601 & Validation Loss: 0.5675\n",
      "EarlyStopping counter: 2 out of 20\n",
      "60th Epoch starting.\n",
      "Epoch [60] Train Loss: 0.2496 & Validation Loss: 0.5911\n",
      "EarlyStopping counter: 3 out of 20\n",
      "61th Epoch starting.\n",
      "Epoch [61] Train Loss: 0.2429 & Validation Loss: 0.5757\n",
      "EarlyStopping counter: 4 out of 20\n",
      "62th Epoch starting.\n",
      "Epoch [62] Train Loss: 0.2402 & Validation Loss: 0.5327\n",
      "Validation loss decreased --- Saving model ...\n",
      "63th Epoch starting.\n",
      "Epoch [63] Train Loss: 0.2305 & Validation Loss: 0.5294\n",
      "Validation loss decreased --- Saving model ...\n",
      "64th Epoch starting.\n",
      "Epoch [64] Train Loss: 0.2269 & Validation Loss: 0.5509\n",
      "EarlyStopping counter: 1 out of 20\n",
      "65th Epoch starting.\n",
      "Epoch [65] Train Loss: 0.2209 & Validation Loss: 0.5534\n",
      "EarlyStopping counter: 2 out of 20\n",
      "66th Epoch starting.\n",
      "Epoch [66] Train Loss: 0.2289 & Validation Loss: 0.5498\n",
      "EarlyStopping counter: 3 out of 20\n",
      "67th Epoch starting.\n",
      "Epoch [67] Train Loss: 0.2237 & Validation Loss: 0.5827\n",
      "EarlyStopping counter: 4 out of 20\n",
      "68th Epoch starting.\n",
      "Epoch [68] Train Loss: 0.2135 & Validation Loss: 0.5440\n",
      "EarlyStopping counter: 5 out of 20\n",
      "69th Epoch starting.\n",
      "Epoch [69] Train Loss: 0.1985 & Validation Loss: 0.5870\n",
      "EarlyStopping counter: 6 out of 20\n",
      "70th Epoch starting.\n",
      "Epoch [70] Train Loss: 0.2016 & Validation Loss: 0.5772\n",
      "EarlyStopping counter: 7 out of 20\n",
      "71th Epoch starting.\n",
      "Epoch [71] Train Loss: 0.2066 & Validation Loss: 0.5758\n",
      "EarlyStopping counter: 8 out of 20\n",
      "72th Epoch starting.\n",
      "Epoch [72] Train Loss: 0.2151 & Validation Loss: 0.5490\n",
      "EarlyStopping counter: 9 out of 20\n",
      "73th Epoch starting.\n",
      "Epoch [73] Train Loss: 0.2011 & Validation Loss: 0.6148\n",
      "EarlyStopping counter: 10 out of 20\n",
      "74th Epoch starting.\n",
      "Epoch [74] Train Loss: 0.1987 & Validation Loss: 0.5818\n",
      "EarlyStopping counter: 11 out of 20\n",
      "75th Epoch starting.\n",
      "Epoch [75] Train Loss: 0.1923 & Validation Loss: 0.5465\n",
      "EarlyStopping counter: 12 out of 20\n",
      "76th Epoch starting.\n",
      "Epoch [76] Train Loss: 0.1818 & Validation Loss: 0.5887\n",
      "EarlyStopping counter: 13 out of 20\n",
      "77th Epoch starting.\n",
      "Epoch [77] Train Loss: 0.1908 & Validation Loss: 0.5603\n",
      "EarlyStopping counter: 14 out of 20\n",
      "78th Epoch starting.\n",
      "Epoch [78] Train Loss: 0.1839 & Validation Loss: 0.5827\n",
      "EarlyStopping counter: 15 out of 20\n",
      "79th Epoch starting.\n",
      "Epoch [79] Train Loss: 0.1824 & Validation Loss: 0.5691\n",
      "EarlyStopping counter: 16 out of 20\n",
      "80th Epoch starting.\n",
      "Epoch [80] Train Loss: 0.1830 & Validation Loss: 0.5937\n",
      "EarlyStopping counter: 17 out of 20\n",
      "81th Epoch starting.\n",
      "Epoch [81] Train Loss: 0.1718 & Validation Loss: 0.6576\n",
      "EarlyStopping counter: 18 out of 20\n",
      "82th Epoch starting.\n",
      "Epoch [82] Train Loss: 0.1725 & Validation Loss: 0.5725\n",
      "EarlyStopping counter: 19 out of 20\n",
      "83th Epoch starting.\n",
      "Epoch [83] Train Loss: 0.1606 & Validation Loss: 0.5726\n",
      "EarlyStopping counter: 20 out of 20\n",
      "Early Stopping!!\n",
      "2 Fold is Training\n",
      "1th Epoch starting.\n",
      "Epoch [1] Train Loss: 1.7209 & Validation Loss: 1.5510\n",
      "Validation loss decreased (inf --> 1.5510).  Saving model ...\n",
      "2th Epoch starting.\n",
      "Epoch [2] Train Loss: 1.9873 & Validation Loss: 1.7045\n",
      "EarlyStopping counter: 1 out of 20\n",
      "3th Epoch starting.\n",
      "Epoch [3] Train Loss: 1.5893 & Validation Loss: 1.5069\n",
      "Validation loss decreased --- Saving model ...\n",
      "4th Epoch starting.\n",
      "Epoch [4] Train Loss: 1.3973 & Validation Loss: 1.3340\n",
      "Validation loss decreased --- Saving model ...\n",
      "5th Epoch starting.\n",
      "Epoch [5] Train Loss: 1.2780 & Validation Loss: 1.2201\n",
      "Validation loss decreased --- Saving model ...\n",
      "6th Epoch starting.\n",
      "Epoch [6] Train Loss: 1.1909 & Validation Loss: 1.1215\n",
      "Validation loss decreased --- Saving model ...\n",
      "7th Epoch starting.\n",
      "Epoch [7] Train Loss: 1.0948 & Validation Loss: 1.0392\n",
      "Validation loss decreased --- Saving model ...\n",
      "8th Epoch starting.\n",
      "Epoch [8] Train Loss: 1.0360 & Validation Loss: 1.0007\n",
      "Validation loss decreased --- Saving model ...\n",
      "9th Epoch starting.\n",
      "Epoch [9] Train Loss: 0.9729 & Validation Loss: 0.9162\n",
      "Validation loss decreased --- Saving model ...\n",
      "10th Epoch starting.\n",
      "Epoch [10] Train Loss: 0.9245 & Validation Loss: 0.9286\n",
      "EarlyStopping counter: 1 out of 20\n",
      "11th Epoch starting.\n",
      "Epoch [11] Train Loss: 0.8767 & Validation Loss: 0.8794\n",
      "Validation loss decreased --- Saving model ...\n",
      "12th Epoch starting.\n",
      "Epoch [12] Train Loss: 0.8172 & Validation Loss: 0.8423\n",
      "Validation loss decreased --- Saving model ...\n",
      "13th Epoch starting.\n",
      "Epoch [13] Train Loss: 0.7821 & Validation Loss: 0.8292\n",
      "Validation loss decreased --- Saving model ...\n",
      "14th Epoch starting.\n",
      "Epoch [14] Train Loss: 0.7476 & Validation Loss: 0.8089\n",
      "Validation loss decreased --- Saving model ...\n",
      "15th Epoch starting.\n",
      "Epoch [15] Train Loss: 0.6957 & Validation Loss: 0.7096\n",
      "Validation loss decreased --- Saving model ...\n",
      "16th Epoch starting.\n",
      "Epoch [16] Train Loss: 0.6612 & Validation Loss: 0.7070\n",
      "Validation loss decreased --- Saving model ...\n",
      "17th Epoch starting.\n",
      "Epoch [17] Train Loss: 0.6360 & Validation Loss: 0.6512\n",
      "Validation loss decreased --- Saving model ...\n",
      "18th Epoch starting.\n",
      "Epoch [18] Train Loss: 0.5839 & Validation Loss: 0.6226\n",
      "Validation loss decreased --- Saving model ...\n",
      "19th Epoch starting.\n",
      "Epoch [19] Train Loss: 0.5491 & Validation Loss: 0.5697\n",
      "Validation loss decreased --- Saving model ...\n",
      "20th Epoch starting.\n",
      "Epoch [20] Train Loss: 0.5213 & Validation Loss: 0.5993\n",
      "EarlyStopping counter: 1 out of 20\n",
      "21th Epoch starting.\n",
      "Epoch [21] Train Loss: 0.4949 & Validation Loss: 0.6097\n",
      "EarlyStopping counter: 2 out of 20\n",
      "22th Epoch starting.\n",
      "Epoch [22] Train Loss: 0.4890 & Validation Loss: 0.5693\n",
      "Validation loss decreased --- Saving model ...\n",
      "23th Epoch starting.\n",
      "Epoch [23] Train Loss: 0.4527 & Validation Loss: 0.5370\n",
      "Validation loss decreased --- Saving model ...\n",
      "24th Epoch starting.\n",
      "Epoch [24] Train Loss: 0.4260 & Validation Loss: 0.5482\n",
      "EarlyStopping counter: 1 out of 20\n",
      "25th Epoch starting.\n",
      "Epoch [25] Train Loss: 0.4066 & Validation Loss: 0.6207\n",
      "EarlyStopping counter: 2 out of 20\n",
      "26th Epoch starting.\n",
      "Epoch [26] Train Loss: 0.3932 & Validation Loss: 0.5276\n",
      "Validation loss decreased --- Saving model ...\n",
      "27th Epoch starting.\n",
      "Epoch [27] Train Loss: 0.3754 & Validation Loss: 0.4911\n",
      "Validation loss decreased --- Saving model ...\n",
      "28th Epoch starting.\n",
      "Epoch [28] Train Loss: 0.3574 & Validation Loss: 0.4688\n",
      "Validation loss decreased --- Saving model ...\n",
      "29th Epoch starting.\n",
      "Epoch [29] Train Loss: 0.3424 & Validation Loss: 0.4598\n",
      "Validation loss decreased --- Saving model ...\n",
      "30th Epoch starting.\n",
      "Epoch [30] Train Loss: 0.3228 & Validation Loss: 0.4532\n",
      "Validation loss decreased --- Saving model ...\n",
      "31th Epoch starting.\n",
      "Epoch [31] Train Loss: 0.3072 & Validation Loss: 0.4457\n",
      "Validation loss decreased --- Saving model ...\n",
      "32th Epoch starting.\n",
      "Epoch [32] Train Loss: 0.2932 & Validation Loss: 0.4514\n",
      "EarlyStopping counter: 1 out of 20\n",
      "33th Epoch starting.\n",
      "Epoch [33] Train Loss: 0.2917 & Validation Loss: 0.4673\n",
      "EarlyStopping counter: 2 out of 20\n",
      "34th Epoch starting.\n",
      "Epoch [34] Train Loss: 0.2688 & Validation Loss: 0.4550\n",
      "EarlyStopping counter: 3 out of 20\n",
      "35th Epoch starting.\n",
      "Epoch [35] Train Loss: 0.2532 & Validation Loss: 0.4185\n",
      "Validation loss decreased --- Saving model ...\n",
      "36th Epoch starting.\n",
      "Epoch [36] Train Loss: 0.2499 & Validation Loss: 0.4932\n",
      "EarlyStopping counter: 1 out of 20\n",
      "37th Epoch starting.\n",
      "Epoch [37] Train Loss: 0.2363 & Validation Loss: 0.4184\n",
      "Validation loss decreased --- Saving model ...\n",
      "38th Epoch starting.\n",
      "Epoch [38] Train Loss: 0.2125 & Validation Loss: 0.4686\n",
      "EarlyStopping counter: 1 out of 20\n",
      "39th Epoch starting.\n",
      "Epoch [39] Train Loss: 0.2157 & Validation Loss: 0.4130\n",
      "Validation loss decreased --- Saving model ...\n",
      "40th Epoch starting.\n",
      "Epoch [40] Train Loss: 0.1980 & Validation Loss: 0.4435\n",
      "EarlyStopping counter: 1 out of 20\n",
      "41th Epoch starting.\n",
      "Epoch [41] Train Loss: 0.1988 & Validation Loss: 0.4547\n",
      "EarlyStopping counter: 2 out of 20\n",
      "42th Epoch starting.\n",
      "Epoch [42] Train Loss: 0.1788 & Validation Loss: 0.4331\n",
      "EarlyStopping counter: 3 out of 20\n",
      "43th Epoch starting.\n",
      "Epoch [43] Train Loss: 0.1750 & Validation Loss: 0.4499\n",
      "EarlyStopping counter: 4 out of 20\n",
      "44th Epoch starting.\n",
      "Epoch [44] Train Loss: 0.1683 & Validation Loss: 0.4378\n",
      "EarlyStopping counter: 5 out of 20\n",
      "45th Epoch starting.\n",
      "Epoch [45] Train Loss: 0.1536 & Validation Loss: 0.4382\n",
      "EarlyStopping counter: 6 out of 20\n",
      "46th Epoch starting.\n",
      "Epoch [46] Train Loss: 0.1602 & Validation Loss: 0.4423\n",
      "EarlyStopping counter: 7 out of 20\n",
      "47th Epoch starting.\n",
      "Epoch [47] Train Loss: 0.1394 & Validation Loss: 0.4826\n",
      "EarlyStopping counter: 8 out of 20\n",
      "48th Epoch starting.\n",
      "Epoch [48] Train Loss: 0.1313 & Validation Loss: 0.4595\n",
      "EarlyStopping counter: 9 out of 20\n",
      "49th Epoch starting.\n",
      "Epoch [49] Train Loss: 0.1355 & Validation Loss: 0.4415\n",
      "EarlyStopping counter: 10 out of 20\n",
      "50th Epoch starting.\n",
      "Epoch [50] Train Loss: 0.1225 & Validation Loss: 0.4674\n",
      "EarlyStopping counter: 11 out of 20\n",
      "51th Epoch starting.\n",
      "Epoch [51] Train Loss: 0.1265 & Validation Loss: 0.4563\n",
      "EarlyStopping counter: 12 out of 20\n",
      "52th Epoch starting.\n",
      "Epoch [52] Train Loss: 0.1150 & Validation Loss: 0.4581\n",
      "EarlyStopping counter: 13 out of 20\n",
      "53th Epoch starting.\n",
      "Epoch [53] Train Loss: 0.1079 & Validation Loss: 0.4819\n",
      "EarlyStopping counter: 14 out of 20\n",
      "54th Epoch starting.\n",
      "Epoch [54] Train Loss: 0.1065 & Validation Loss: 0.5126\n",
      "EarlyStopping counter: 15 out of 20\n",
      "55th Epoch starting.\n",
      "Epoch [55] Train Loss: 0.0983 & Validation Loss: 0.4608\n",
      "EarlyStopping counter: 16 out of 20\n",
      "56th Epoch starting.\n",
      "Epoch [56] Train Loss: 0.0938 & Validation Loss: 0.4985\n",
      "EarlyStopping counter: 17 out of 20\n",
      "57th Epoch starting.\n",
      "Epoch [57] Train Loss: 0.0858 & Validation Loss: 0.5242\n",
      "EarlyStopping counter: 18 out of 20\n",
      "58th Epoch starting.\n",
      "Epoch [58] Train Loss: 0.0915 & Validation Loss: 0.5079\n",
      "EarlyStopping counter: 19 out of 20\n",
      "59th Epoch starting.\n",
      "Epoch [59] Train Loss: 0.0853 & Validation Loss: 0.4692\n",
      "EarlyStopping counter: 20 out of 20\n",
      "Early Stopping!!\n",
      "3 Fold is Training\n",
      "1th Epoch starting.\n",
      "Epoch [1] Train Loss: 0.5800 & Validation Loss: 0.4735\n",
      "Validation loss decreased (inf --> 0.4735).  Saving model ...\n",
      "2th Epoch starting.\n",
      "Epoch [2] Train Loss: 0.4348 & Validation Loss: 0.5638\n",
      "EarlyStopping counter: 1 out of 20\n",
      "3th Epoch starting.\n",
      "Epoch [3] Train Loss: 0.3135 & Validation Loss: 0.4840\n",
      "EarlyStopping counter: 2 out of 20\n",
      "4th Epoch starting.\n",
      "Epoch [4] Train Loss: 0.2692 & Validation Loss: 0.4632\n",
      "Validation loss decreased --- Saving model ...\n",
      "5th Epoch starting.\n",
      "Epoch [5] Train Loss: 0.2422 & Validation Loss: 0.4271\n",
      "Validation loss decreased --- Saving model ...\n",
      "6th Epoch starting.\n",
      "Epoch [6] Train Loss: 0.2350 & Validation Loss: 0.4296\n",
      "EarlyStopping counter: 1 out of 20\n",
      "7th Epoch starting.\n",
      "Epoch [7] Train Loss: 0.2154 & Validation Loss: 0.4004\n",
      "Validation loss decreased --- Saving model ...\n",
      "8th Epoch starting.\n",
      "Epoch [8] Train Loss: 0.2122 & Validation Loss: 0.4101\n",
      "EarlyStopping counter: 1 out of 20\n",
      "9th Epoch starting.\n",
      "Epoch [9] Train Loss: 0.1990 & Validation Loss: 0.3957\n",
      "Validation loss decreased --- Saving model ...\n",
      "10th Epoch starting.\n",
      "Epoch [10] Train Loss: 0.1828 & Validation Loss: 0.4356\n",
      "EarlyStopping counter: 1 out of 20\n",
      "11th Epoch starting.\n",
      "Epoch [11] Train Loss: 0.1710 & Validation Loss: 0.4079\n",
      "EarlyStopping counter: 2 out of 20\n",
      "12th Epoch starting.\n",
      "Epoch [12] Train Loss: 0.1697 & Validation Loss: 0.4067\n",
      "EarlyStopping counter: 3 out of 20\n",
      "13th Epoch starting.\n",
      "Epoch [13] Train Loss: 0.1592 & Validation Loss: 0.4202\n",
      "EarlyStopping counter: 4 out of 20\n",
      "14th Epoch starting.\n",
      "Epoch [14] Train Loss: 0.1540 & Validation Loss: 0.4167\n",
      "EarlyStopping counter: 5 out of 20\n",
      "15th Epoch starting.\n",
      "Epoch [15] Train Loss: 0.1481 & Validation Loss: 0.4189\n",
      "EarlyStopping counter: 6 out of 20\n",
      "16th Epoch starting.\n",
      "Epoch [16] Train Loss: 0.1386 & Validation Loss: 0.4230\n",
      "EarlyStopping counter: 7 out of 20\n",
      "17th Epoch starting.\n",
      "Epoch [17] Train Loss: 0.1301 & Validation Loss: 0.4567\n",
      "EarlyStopping counter: 8 out of 20\n",
      "18th Epoch starting.\n",
      "Epoch [18] Train Loss: 0.1259 & Validation Loss: 0.4269\n",
      "EarlyStopping counter: 9 out of 20\n",
      "19th Epoch starting.\n",
      "Epoch [19] Train Loss: 0.1298 & Validation Loss: 0.4298\n",
      "EarlyStopping counter: 10 out of 20\n",
      "20th Epoch starting.\n",
      "Epoch [20] Train Loss: 0.1080 & Validation Loss: 0.4831\n",
      "EarlyStopping counter: 11 out of 20\n",
      "21th Epoch starting.\n",
      "Epoch [21] Train Loss: 0.1159 & Validation Loss: 0.4612\n",
      "EarlyStopping counter: 12 out of 20\n",
      "22th Epoch starting.\n",
      "Epoch [22] Train Loss: 0.1062 & Validation Loss: 0.5464\n",
      "EarlyStopping counter: 13 out of 20\n",
      "23th Epoch starting.\n",
      "Epoch [23] Train Loss: 0.1138 & Validation Loss: 0.4377\n",
      "EarlyStopping counter: 14 out of 20\n",
      "24th Epoch starting.\n",
      "Epoch [24] Train Loss: 0.0963 & Validation Loss: 0.4770\n",
      "EarlyStopping counter: 15 out of 20\n",
      "25th Epoch starting.\n",
      "Epoch [25] Train Loss: 0.0984 & Validation Loss: 0.4640\n",
      "EarlyStopping counter: 16 out of 20\n",
      "26th Epoch starting.\n",
      "Epoch [26] Train Loss: 0.0922 & Validation Loss: 0.5005\n",
      "EarlyStopping counter: 17 out of 20\n",
      "27th Epoch starting.\n",
      "Epoch [27] Train Loss: 0.0834 & Validation Loss: 0.4381\n",
      "EarlyStopping counter: 18 out of 20\n",
      "28th Epoch starting.\n",
      "Epoch [28] Train Loss: 0.0864 & Validation Loss: 0.5132\n",
      "EarlyStopping counter: 19 out of 20\n",
      "29th Epoch starting.\n",
      "Epoch [29] Train Loss: 0.0882 & Validation Loss: 0.4586\n",
      "EarlyStopping counter: 20 out of 20\n",
      "Early Stopping!!\n",
      "4 Fold is Training\n",
      "1th Epoch starting.\n",
      "Epoch [1] Train Loss: 0.3184 & Validation Loss: 0.4380\n",
      "Validation loss decreased (inf --> 0.4380).  Saving model ...\n",
      "2th Epoch starting.\n",
      "Epoch [2] Train Loss: 0.2906 & Validation Loss: 0.4452\n",
      "EarlyStopping counter: 1 out of 20\n",
      "3th Epoch starting.\n",
      "Epoch [3] Train Loss: 0.2262 & Validation Loss: 0.4357\n",
      "Validation loss decreased --- Saving model ...\n",
      "4th Epoch starting.\n",
      "Epoch [4] Train Loss: 0.2063 & Validation Loss: 0.4650\n",
      "EarlyStopping counter: 1 out of 20\n",
      "5th Epoch starting.\n",
      "Epoch [5] Train Loss: 0.1954 & Validation Loss: 0.4011\n",
      "Validation loss decreased --- Saving model ...\n",
      "6th Epoch starting.\n",
      "Epoch [6] Train Loss: 0.1759 & Validation Loss: 0.4161\n",
      "EarlyStopping counter: 1 out of 20\n",
      "7th Epoch starting.\n",
      "Epoch [7] Train Loss: 0.1696 & Validation Loss: 0.4382\n",
      "EarlyStopping counter: 2 out of 20\n",
      "8th Epoch starting.\n",
      "Epoch [8] Train Loss: 0.1714 & Validation Loss: 0.4134\n",
      "EarlyStopping counter: 3 out of 20\n",
      "9th Epoch starting.\n",
      "Epoch [9] Train Loss: 0.1511 & Validation Loss: 0.4212\n",
      "EarlyStopping counter: 4 out of 20\n",
      "10th Epoch starting.\n",
      "Epoch [10] Train Loss: 0.1427 & Validation Loss: 0.4391\n",
      "EarlyStopping counter: 5 out of 20\n",
      "11th Epoch starting.\n",
      "Epoch [11] Train Loss: 0.1327 & Validation Loss: 0.4684\n",
      "EarlyStopping counter: 6 out of 20\n",
      "12th Epoch starting.\n",
      "Epoch [12] Train Loss: 0.1373 & Validation Loss: 0.4339\n",
      "EarlyStopping counter: 7 out of 20\n",
      "13th Epoch starting.\n",
      "Epoch [13] Train Loss: 0.1263 & Validation Loss: 0.4275\n",
      "EarlyStopping counter: 8 out of 20\n",
      "14th Epoch starting.\n",
      "Epoch [14] Train Loss: 0.1257 & Validation Loss: 0.4224\n",
      "EarlyStopping counter: 9 out of 20\n",
      "15th Epoch starting.\n",
      "Epoch [15] Train Loss: 0.1140 & Validation Loss: 0.4469\n",
      "EarlyStopping counter: 10 out of 20\n",
      "16th Epoch starting.\n",
      "Epoch [16] Train Loss: 0.1076 & Validation Loss: 0.4334\n",
      "EarlyStopping counter: 11 out of 20\n",
      "17th Epoch starting.\n",
      "Epoch [17] Train Loss: 0.1082 & Validation Loss: 0.4978\n",
      "EarlyStopping counter: 12 out of 20\n",
      "18th Epoch starting.\n",
      "Epoch [18] Train Loss: 0.0987 & Validation Loss: 0.4723\n",
      "EarlyStopping counter: 13 out of 20\n",
      "19th Epoch starting.\n",
      "Epoch [19] Train Loss: 0.1103 & Validation Loss: 0.4474\n",
      "EarlyStopping counter: 14 out of 20\n",
      "20th Epoch starting.\n",
      "Epoch [20] Train Loss: 0.0952 & Validation Loss: 0.4180\n",
      "EarlyStopping counter: 15 out of 20\n",
      "21th Epoch starting.\n",
      "Epoch [21] Train Loss: 0.0844 & Validation Loss: 0.4623\n",
      "EarlyStopping counter: 16 out of 20\n",
      "22th Epoch starting.\n",
      "Epoch [22] Train Loss: 0.0843 & Validation Loss: 0.4821\n",
      "EarlyStopping counter: 17 out of 20\n",
      "23th Epoch starting.\n",
      "Epoch [23] Train Loss: 0.0813 & Validation Loss: 0.4835\n",
      "EarlyStopping counter: 18 out of 20\n",
      "24th Epoch starting.\n",
      "Epoch [24] Train Loss: 0.0796 & Validation Loss: 0.4999\n",
      "EarlyStopping counter: 19 out of 20\n",
      "25th Epoch starting.\n",
      "Epoch [25] Train Loss: 0.0829 & Validation Loss: 0.5225\n",
      "EarlyStopping counter: 20 out of 20\n",
      "Early Stopping!!\n",
      "5 Fold is Training\n",
      "1th Epoch starting.\n",
      "Epoch [1] Train Loss: 0.2421 & Validation Loss: 0.4233\n",
      "Validation loss decreased (inf --> 0.4233).  Saving model ...\n",
      "2th Epoch starting.\n",
      "Epoch [2] Train Loss: 0.2461 & Validation Loss: 0.4090\n",
      "Validation loss decreased --- Saving model ...\n",
      "3th Epoch starting.\n",
      "Epoch [3] Train Loss: 0.2017 & Validation Loss: 0.4042\n",
      "Validation loss decreased --- Saving model ...\n",
      "4th Epoch starting.\n",
      "Epoch [4] Train Loss: 0.1863 & Validation Loss: 0.5101\n",
      "EarlyStopping counter: 1 out of 20\n",
      "5th Epoch starting.\n",
      "Epoch [5] Train Loss: 0.1738 & Validation Loss: 0.4093\n",
      "EarlyStopping counter: 2 out of 20\n",
      "6th Epoch starting.\n",
      "Epoch [6] Train Loss: 0.1663 & Validation Loss: 0.4538\n",
      "EarlyStopping counter: 3 out of 20\n",
      "7th Epoch starting.\n",
      "Epoch [7] Train Loss: 0.1458 & Validation Loss: 0.3782\n",
      "Validation loss decreased --- Saving model ...\n",
      "8th Epoch starting.\n",
      "Epoch [8] Train Loss: 0.1426 & Validation Loss: 0.4449\n",
      "EarlyStopping counter: 1 out of 20\n",
      "9th Epoch starting.\n",
      "Epoch [9] Train Loss: 0.1344 & Validation Loss: 0.4787\n",
      "EarlyStopping counter: 2 out of 20\n",
      "10th Epoch starting.\n",
      "Epoch [10] Train Loss: 0.1263 & Validation Loss: 0.4213\n",
      "EarlyStopping counter: 3 out of 20\n",
      "11th Epoch starting.\n",
      "Epoch [11] Train Loss: 0.1246 & Validation Loss: 0.4170\n",
      "EarlyStopping counter: 4 out of 20\n",
      "12th Epoch starting.\n",
      "Epoch [12] Train Loss: 0.1145 & Validation Loss: 0.4683\n",
      "EarlyStopping counter: 5 out of 20\n",
      "13th Epoch starting.\n",
      "Epoch [13] Train Loss: 0.1199 & Validation Loss: 0.4278\n",
      "EarlyStopping counter: 6 out of 20\n",
      "14th Epoch starting.\n",
      "Epoch [14] Train Loss: 0.1117 & Validation Loss: 0.4306\n",
      "EarlyStopping counter: 7 out of 20\n",
      "15th Epoch starting.\n",
      "Epoch [15] Train Loss: 0.1113 & Validation Loss: 0.4296\n",
      "EarlyStopping counter: 8 out of 20\n",
      "16th Epoch starting.\n",
      "Epoch [16] Train Loss: 0.1096 & Validation Loss: 0.4392\n",
      "EarlyStopping counter: 9 out of 20\n",
      "17th Epoch starting.\n",
      "Epoch [17] Train Loss: 0.0972 & Validation Loss: 0.4269\n",
      "EarlyStopping counter: 10 out of 20\n",
      "18th Epoch starting.\n",
      "Epoch [18] Train Loss: 0.0906 & Validation Loss: 0.4342\n",
      "EarlyStopping counter: 11 out of 20\n",
      "19th Epoch starting.\n",
      "Epoch [19] Train Loss: 0.0872 & Validation Loss: 0.4803\n",
      "EarlyStopping counter: 12 out of 20\n",
      "20th Epoch starting.\n",
      "Epoch [20] Train Loss: 0.0868 & Validation Loss: 0.4916\n",
      "EarlyStopping counter: 13 out of 20\n",
      "21th Epoch starting.\n",
      "Epoch [21] Train Loss: 0.0913 & Validation Loss: 0.4293\n",
      "EarlyStopping counter: 14 out of 20\n",
      "22th Epoch starting.\n",
      "Epoch [22] Train Loss: 0.0754 & Validation Loss: 0.5273\n",
      "EarlyStopping counter: 15 out of 20\n",
      "23th Epoch starting.\n",
      "Epoch [23] Train Loss: 0.0787 & Validation Loss: 0.4696\n",
      "EarlyStopping counter: 16 out of 20\n",
      "24th Epoch starting.\n",
      "Epoch [24] Train Loss: 0.0766 & Validation Loss: 0.5046\n",
      "EarlyStopping counter: 17 out of 20\n",
      "25th Epoch starting.\n",
      "Epoch [25] Train Loss: 0.0740 & Validation Loss: 0.5045\n",
      "EarlyStopping counter: 18 out of 20\n",
      "26th Epoch starting.\n",
      "Epoch [26] Train Loss: 0.0697 & Validation Loss: 0.4947\n",
      "EarlyStopping counter: 19 out of 20\n",
      "27th Epoch starting.\n",
      "Epoch [27] Train Loss: 0.0695 & Validation Loss: 0.5012\n",
      "EarlyStopping counter: 20 out of 20\n",
      "Early Stopping!!\n",
      "21671.850882291794\n"
     ]
    }
   ],
   "source": [
    "model, train_losses, valid_losses = train_KFold(model, batch_size=batch_size, n_epochs=250, patience=20, data_info=data_info, fold=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DOBivEHqRykr",
    "outputId": "775cf59d-68fd-4d94-8239-419b0d33f0ef"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    " test_dataset = datasets.CIFAR10(root='./cifar_10data/',\n",
    "                                train=False,\n",
    "                                transform=transforms.ToTensor(),\n",
    "                                download=True) \n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset,\n",
    "                                          batch_size=batch_size,\n",
    "                                          num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bjS9hXoGRzGA",
    "outputId": "f1831d07-1643-4fca-d0d7-3699e348f8c8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test set] Average loss: 0.0016, Accuracy: 8853/10000 (88.53%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Z8ASz1WCYLrJ"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "ResNet34-3.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "11eb5d4d8dce47a09dd100a72d8d703c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f708822d267e479395e7c17bfecc1ea8",
      "placeholder": "​",
      "style": "IPY_MODEL_b6109007eecf476693a2f567babe43a4",
      "value": " 170500096/? [00:20&lt;00:00, 99228882.68it/s]"
     }
    },
    "1f02028cf0994b40aba2137d710804cd": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "info",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f4e1dfcc0685492db9a88f50eaa02a1f",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_98dfa2a3b7c54791aaeaebc6c7adadfc",
      "value": 1
     }
    },
    "4a6340de48954a878f04c2907e5320a1": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5ae6706d9a1940d593343133f78cc924": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_1f02028cf0994b40aba2137d710804cd",
       "IPY_MODEL_11eb5d4d8dce47a09dd100a72d8d703c"
      ],
      "layout": "IPY_MODEL_4a6340de48954a878f04c2907e5320a1"
     }
    },
    "98dfa2a3b7c54791aaeaebc6c7adadfc": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "b6109007eecf476693a2f567babe43a4": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f4e1dfcc0685492db9a88f50eaa02a1f": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f708822d267e479395e7c17bfecc1ea8": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
